{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example notebook for the ATOM pipeline\n",
    "---------------------------------\n",
    "\n",
    "Load the data with one of the three imported datasets before running the\n",
    "ATOM function. These datasets are provided by sklearn and are very small\n",
    "and easy to learn. You can learn more about these datasets\n",
    "at https://scikit-learn.org/stable/datasets/index.html.\n",
    "\n",
    "    load_breast_cancer: binary classification\n",
    "    load_wine: multi-class classification\n",
    "    load_boston: regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston, load_wine, load_breast_cancer\n",
    "from atom import ATOM\n",
    "\n",
    "# Load the dataset and transform to a pd.DataFrame\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "data = np.c_[dataset.data, dataset.target]\n",
    "columns = np.append(dataset.feature_names, [\"target\"])\n",
    "data = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<=============== ATOM ===============>>\n",
      "Algorithm task: binary classification.\n",
      "\n",
      "Data stats =====================>\n",
      "Number of features: 30\n",
      "Number of instances: 569\n",
      "Size of training set: 398\n",
      "Size of test set: 171\n",
      "\n",
      "Performing oversampling...\n",
      "Handling outliers...\n",
      "Performing feature selection...\n"
     ]
    }
   ],
   "source": [
    "# Call new ATOM class for ML task exploration\n",
    "atom = ATOM(data,\n",
    "            target='target',\n",
    "            n_jobs=1,\n",
    "            verbose=2)\n",
    "\n",
    "# Perform some data cleaning steps\n",
    "atom.balance(oversample=1.)\n",
    "atom.outliers(max_sigma=5)\n",
    "\n",
    "# Select the 10 best features according to a F-test\n",
    "atom.feature_selection(strategy='univariate', max_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running pipeline =================>\n",
      "Models in pipeline: ['LDA', 'RF', 'LGBM']\n",
      "\n",
      "\n",
      "Running BO for Linear Discriminant Analysis...\n",
      "Final statistics for Linear Discriminant Analysis:         \n",
      "Best hyperparameters: {'solver': 'svd', 'n_components': 1, 'tol': 0.0689}\n",
      "Best Accuracy on the BO: 0.9739\n",
      "Accuracy on the test set: 0.9474\n",
      "Elapsed time: 5.6 seconds\n",
      "--------------------------------------------------\n",
      "Bagging Accuracy score --> Mean: 0.9532   Std: 0.0064\n",
      "Elapsed time: 0.1 seconds\n",
      "\n",
      "\n",
      "Running BO for Random Forest...\n",
      "Final statistics for Random Forest:         \n",
      "Best hyperparameters: {'n_estimators': 100, 'max_features': 0.8, 'criterion': 'entropy', 'bootstrap': True, 'min_samples_split': 12, 'min_samples_leaf': 2}\n",
      "Best Accuracy on the BO: 0.9558\n",
      "Accuracy on the test set: 0.9415\n",
      "Elapsed time: 15.3 seconds\n",
      "--------------------------------------------------\n",
      "Bagging Accuracy score --> Mean: 0.9392   Std: 0.0070\n",
      "Elapsed time: 1.8 seconds\n",
      "\n",
      "\n",
      "Running BO for Light GBM...\n",
      "Final statistics for Light GBM:         \n",
      "Best hyperparameters: {'n_estimators': 58, 'learning_rate': 0.83, 'min_child_samples': 10, 'reg_alpha': 1.4, 'reg_lambda': 80.0, 'subsample': 0.3, 'max_depth': 10, 'colsample_bytree': 0.3, 'num_leaves': 40}\n",
      "Best Accuracy on the BO: 0.9598\n",
      "Accuracy on the test set: 0.9649\n",
      "Elapsed time: 4.7 seconds\n",
      "--------------------------------------------------\n",
      "Bagging Accuracy score --> Mean: 0.9567   Std: 0.0102\n",
      "Elapsed time: 0.2 seconds\n",
      "\n",
      "\n",
      "Final stats ================>>\n",
      "Duration: 00h:00m:27s\n",
      "Target metric: Accuracy\n",
      "--------------------------------\n",
      "Linear Discriminant Analysis --> 0.953 ± 0.006\n",
      "Random Forest                --> 0.939 ± 0.007\n",
      "Light GBM                    --> 0.957 ± 0.010 !!\n"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline with the selected models\n",
    "atom.fit(models=['LDA','RF', 'LGBM'],\n",
    "         metric='accuracy',\n",
    "         max_iter=10,\n",
    "         init_points=3,\n",
    "         cv=3,\n",
    "         bagging=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
