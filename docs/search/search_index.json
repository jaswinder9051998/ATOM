{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Automated Tool for Optimized Modelling (ATOM) is a python package designed for fast exploration and experimentation of supervised machine learning tasks. With just a few lines of code, you can perform basic data cleaning steps, feature selection and compare the performance of multiple models on a given dataset. ATOM should be able to provide quick insights on which algorithms perform best for the task at hand and provide an indication of the feasibility of the ML solution. This package supports binary classification, multiclass classification, and regression tasks. Note A data scientist with domain knowledge can outperform ATOM if he applies usecase-specific feature engineering or data cleaning steps! Possible steps taken by the ATOM pipeline: Data Cleaning Handle missing values Encode categorical features Balance the dataset Remove outliers Perform feature selection Remove features with too high collinearity Remove features with too low variance Select best features according to a chosen strategy Fit all selected models (either direct or via successive halving) Select hyperparameters using a Bayesian Optimization approach Perform bagging to assess the robustness of the model Analyze the results using the provided plotting functions!","title":"Home"},{"location":"api/","text":"ATOM class atom. ATOM (X, y=None, percentage=100, test_size=0.3, log=None, n_jobs=1, warnings=False, verbose=0, random_state=None, verbose=0) [source] Main class of the package. The ATOM class is a parent class of the ATOMClassifier and ATOMRegressor classes. These will inherit all methods and attributes described in this page. Note that contrary to scikit-learn's API, the ATOM object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. Warning Don't call the ATOM class directly! Use ATOMClassifier or ATOMRegressor depending on the task at hand. Click here for an example. The class initializer will label-encode the target column if its labels are not ordered integers. It will also apply some standard data cleaning steps unto the dataset. These steps include: Transforming the input data into a pd.DataFrame (if it wasn't one already) that can be accessed through the class' data attributes. Removing columns with prohibited data types ('datetime64', 'datetime64[ns]', 'timedelta[ns]'). Removing categorical columns with maximal cardinality (the number of unique values is equal to the number of instances. Usually the case for names, IDs, etc...). Removing columns with minimum cardinality (all values are the same). Removing rows with missing values in the target column. Parameters: X: dict, sequence, np.array or pd.DataFrame Dataset containing the features, with shape=(n_samples, n_features). y: string, sequence, np.array or pd.Series, optional (default=None) If None: the last column of X is selected as target column If string: name of the target column in X Else: data target column with shape=(n_samples,) percentage: int or float, optional (default=100) Percentage of the provided dataset to use. test_size: float, optional (default=0.3) Split fraction of the train and test set. log: string or None, optional (default=None) Name of the logging file. 'auto' for default name with date and time. None to not save any log. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If -1, use all available cores If < -1, use available_cores - 1 + n_jobs Beware that using multiple processes on the same machine may cause memory issues for large datasets. warnings: bool, optional (default=False) If False, it supresses all warnings. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything 1 to print minimum information 2 to print average information 3 to print maximum information random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by np.random. Data attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. Attributes: mapping: dict Dictionary of the target values mapped to their respective encoded integer. Only for classification tasks. errors: dict Dictionary of the encountered exceptions (if any) while fitting the models. winner: callable Model subclass that performed best on the test set. scores: pd.DataFrame Dataframe (or list of dataframes if successive_halving=True) of the results. Columns can include: model: model's name (acronym) total_time: time spent on this model score_train: metric score on the training set score_test: metric score on the test set fit_time: time spent fitting and predicting bagging_mean: mean score of the bagging's results bagging_std: standard deviation score of the bagging's results bagging_time: time spent on the bagging algorithm Utilities The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. stats Print out a list of basic statistics on the dataset. scale Scale all the features to mean=1 and std=0. update Update all data attributes. report Get an extensive profile analysis of the data. results Print final results for a specific metric. save Save the ATOM class to a pickle file. function atom.ATOM. stats () [source] Print out a list of basic statistics on the dataset. function atom.ATOM. scale () [source] Scale all the features to mean=1 and std=0. function atom.ATOM. update (df='dataset') [source] If you change any of the class' data attributes in between the pipeline, you should call this method to change all other data attributes to their correct values. Independent attributes are updated in unison, that is, setting df='X_train' will also update X_test, y_train and y_test, or df='train' will also update the test set, etc... This means that you can change both X_train and y_train and update them with one call of the method. Parameters: df: string, optional(default='dataset') Data attribute that has been changed. function atom.ATOM. report (df='dataset', rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for very large datasets. Dependency: pandas-profiling . Parameters: df: string, optional(default='dataset') Name of the data class attribute to get the profile from. rows: int or None, optional(default=None) Number of rows to process (randomly picked). None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. function atom.ATOM. results (metric=None) [source] Print the pipeline's final results for a specific metric. If a model shows a XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric needs it. Parameters: metric: string or None, optional (default=None) String of one of sklearn's predefined metrics. If None, the metric used to fit the pipeline is selected and the bagging results will be showed (if used). function atom.ATOM. save (filename=None) [source] Save the ATOM class to a pickle file. This method is also available for the model subclasses, e.g. atom.XGB.save(filename='ATOM_xgboost') . In this case, the model subclass is saved, instead of the ATOM class. Warning Remember that the class contains the complete dataset (and variations of it). This means the files can become very large for big datasets! Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. Data cleaning Before throwing your data in a model, it is crucial to apply some standard data cleaning steps. ATOM provides four data cleaning methods to handle missing values, categorical columns, outliers and unbalanced datasets. Calling on one of them will automatically apply the method on the dataset in the class and update the class' data attributes accordingly. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. impute Handle missing values in the dataset. encode Encode categorical columns. outliers Remove outliers from the training set. balance Balance the number of instances per target class. function atom.ATOM. impute (strat_num='remove', strat_cat='remove', max_frac_rows=0.5, max_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. Parameters: strat_num: str, int or float, optional (default='remove') Imputing strategy for numerical columns. Choose from: 'remove': remove row if any missing value 'mean': impute with mean of column 'median': impute with median of column 'knn': impute using a K-Nearest Neighbors approach 'most_frequent': impute with most frequent value int or float: impute with provided numerical value strat_cat: str, optional (default='remove') Imputing strategy for categorical columns. Choose from: 'remove': remove row if any missing value 'most_frequent': impute with most frequent value string: impute with provided string min_frac_rows: float, optional (default=0.5) Minimum fraction of non missing values in a row. If less, the row is removed. min_frac_cols: float, optional (default=0.5) Minimum fraction of non missing values in a column. If less, the column is removed. missing: int, float or list, optional (default=None) List of values to impute. None for default list: [None, np.NaN, np.inf, -np.inf, '', '?', 'NA', 'nan', 'inf']. function atom.ATOM. encode (max_onehot=10, frac_to_other=0) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: label-encoding for n_unique=2 one-hot-encoding for 2 < n_unique <= max_onehot target-encoding for n_unique > max_onehot It also replaces classes with low occurences with the value 'other' in order to prevent too high cardinality. Parameters: max_onehot: int or None, optional (default=10) Maximum number of unique values in a feature to perform one-hot-encoding. If None, it will never perform one-hot-encoding. frac_to_other: float, optional (default=0) Classes with less instances than n_rows * fraction_to_other are replaced with 'other'. function atom.ATOM. outliers (max_sigma=3, include_target=False) [source] Remove rows from the training set where at least one of the values lies further than max_sigma * standard_deviation away from the mean of the column. Parameters: max_sigma: int or float, optional (default=3) Maximum allowed standard deviations from the mean. include_target: bool, optional (default=False) Wether to include the target column when searching for outliers. function atom.ATOM. balance (oversample=None, undersample=None, n_neighbors=5) [source] Balance the number of instances per target class in the training set. If both oversampling and undersampling are used, they will be applied in that order. Only for classification tasks. Dependency: imbalanced-learn . Parameters: oversample: float, string or None, optional (default=None) Oversampling strategy using ADASYN . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'minority': resample only the minority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes undersample: float, string or None, optional (default=None) Undersampling strategy using NearMiss . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'majority': resample only the majority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes n_neighbors: int, optional (default=5) Number of nearest neighbors used for any of the algorithms. Feature selection To further pre-process the data you can create new non-linear features using a genetic algorithm or, if your dataset is too large, remove features using one of the provided strategies. feature_insertion Use a genetic algorithm to create new combinations of existing features. feature_selection Remove features according to the selected strategy. function atom.ATOM. feature_insertion (n_features=2, generations=20, population=500) [source] Use a genetic algorithm to create new combinations of existing features and add them to the original dataset in order to capture the non-linear relations between the original features. A dataframe containing the description of the newly generated features and their scores can be accessed through the genetic_features attribute. The algorithm is implemented using the Symbolic Transformer method, which can be accessed through the genetic_algorithm attribute. It is adviced to only use this method when fitting linear models. Dependency: gplearn . Parameters: n_features: int, optional (default=2) Maximum number of newly generated features (no more than 1% of the population). generations: int, optional (default=20) Number of generations to evolve. population: int, optional (default=500) Number of programs in each generation. function atom.ATOM. feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=0.98, **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. Note that the RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs. If the pipeline has already ran before running the RFECV, the scoring parameter will be set to the selected metric (if scoring=None). Parameters: strategy: string or None, optional (default=None) Feature selection strategy to use. Choose from: None: do not perform any feature selection algorithm 'univariate': perform a univariate F-test, from sklearn SelectKBest 'PCA': perform a principal component analysis, from sklearn PCA 'SFM': select best features from model, from sklearn SelectFromModel 'RFE': recursive feature eliminator, from sklearn RFE 'RFECV': RFE with cross-validated selection, from sklearn RFECV The sklearn objects can be found under the univariate , PCA , SFM , RFE or RFECV attributes of the class. solver: string, callable or None, optional (default=None) Solver or model to use for the feature selection strategy. See the sklearn documentation for an extended descrition of the choices. Select None for the default option per strategy (not applicable for SFM, RFE and RFECV). for 'univariate', choose from: 'f_classif' (default for classification tasks) 'f_regression' (default for regression tasks) 'mutual_info_classif' 'mutual_info_regression' 'chi2' Any function taking two arrays (X, y), and returning arrays (scores, pvalues). for 'PCA', choose from: 'auto' (default) 'full' 'arpack' 'randomized' for 'SFM': choose a base estimator from which the transformer is built. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFE': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFECV': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. n_features: int, float or None, optional (default=None) Number of features to select (except for RFECV, where it's the minimum number of features to select). if < 1: fraction of features to select if >= 1: number of features to select None to select all, or 1 for the RFECV max_frac_repeated: float or None, optional (default=1.) Remove features with the same value in at least this fraction of the total rows. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples. None to skip this step. max_correlation: float or None, optional (default=0.98) Minimum value of the Pearson correlation cofficient to identify correlated features. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. None to skip this step. **kwargs Any extra parameter for the PCA, SFM, RFE or RFECV. See the sklearn documentation for the available options. Pipeline The pipeline method is where the models are fitted to the data and their performance is evaluated according to the selected metric. For every model, the pipeline applies the following steps: The optimal hyperparameters are selectred using a Bayesian Optimization (BO) algorithm with gaussian process as kernel. The resulting score of each step of the BO is either computed by cross-validation on the complete training set or by randomly splitting the training set every iteration into a (sub) training set and a validation set. This process can create some data leakage but ensures a maximal use of the provided data. The test set, however, does not contain any leakage and will be used to determine the final score of every model. Note that, if the dataset is relatively small, the best score on the BO can consistently be lower than the final score on the test set (despite the leakage) due to the considerable fewer instances on which it is trained. Once the best hyperparameters are found, the model is trained again, now using the complete training set. After this, predictions are made on the test set. You can choose to evaluate the robustness of each model's applying a bagging algorithm, i.e. the model will be trained multiple times on a bootstrapped training set, returning a distribution of its performance on the test set. A couple of things to take into account: The metric implementation follows sklearn's API . This means that the implementation always tries to maximize the scorer, i.e. loss functions will be made negative. If an exception is encountered while fitting a model, the pipeline will automatically jump to the next model and save the exception in the errors attribute. When showing the final results, a !! indicates the highest score and a ~ indicates that the model is possibly overfitting (training set has a score at least 20% higher than the test set). The winning model subclass will be attached to the winner attribute. There are three methods to call for the pipeline. The pipeline method fits the models directly to the dataset. If you want to compare similar models, you can use the successive_halving method when running the pipeline. This technique fits N models to 1/N of the data. The best half are selected to go to the next iteration where the process is repeated. This continues until only one model remains, which is fitted on the complete dataset. Beware that a model's performance can depend greatly on the amount of data on which it is trained. For this reason we recommend only to use this technique with similar models, e.g. only using tree-based models. The train_sizing method fits the models on subsets of the training data. This can be used to examine the optimum size of the dataset needed for a satisfying performance. pipeline Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. function atom.ATOM. pipeline (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_iter=0, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. skip_iter: int, optional (default=0) Skip last skip_iter iterations of the successive halving. Will be ignored if successive_halving=False. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspcae(0.1, 1.0, 10), max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. train_sizes: sequence, optional (default=np.linspace(0.1, 1.0, 10)) Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set. Otherwise it is interpreted as absolute sizes of the training sets. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. Model subclass After running the pipeline method, a class for every selected model is created and attached to the main ATOM class as an attribute. These classes can be called upon using the models' acronyms, e.g. atom.LGB . Lowercase calls are also allowed for this attribute, e.g. atom.lgb . The model subclasses contain a variety of methods and attributes to help you understand how every specific model performed. The majority of the plots can be called directly from the subclasses. For example, to plot the ROC for the LightGBM model we could type atom.lgb.plot_ROC() . You can also save the whole subclass to a pickle file using the save method, e.g. atom.rf.save('random_forest') , or only save the best fitted model with the save_model method, e.g. atom.rf.save_model('random_forest_model') . You can also call for any of the sklearn pre-defined metrics, (e.g. atom.ET.recall ) or for any of the following custom metrics: tn (true negatives), fp (false positives), fn (false negatives), tp (true positives), tpr (true positive rate), fpr (false positive rate), sup (support/predicted positive rate) or lift . The rest of the available attributes can be found hereunder: Parameters: error: string Any exception encountered by the model. BO: dict Dictionary containing the information of every step taken by the BO. Keys include: 'params': Parameters used for the model 'score': Score of the chosen metric 'time': Time spent on this iteration 'total_time': Time spent since the start of the BO best_params: dict Dictionary of the best combination of hyperparameters found by the BO. best_model: callable Model object that performed best on the test set. Not fitted. best_model_fit: callable Model object that performed best on the test set. Fitted to the complete training set. predict_train: list Predictions of the model on the training set. predict_test: list Predictions of the model on the test set. predict_proba_train: list Predict probabilities of the model on the training set. Only for models with a `predict_proba` method. predict_proba_test: list Predict probabilities of the model on the test set. Only for models with a `predict_proba` method. decision_function_train: list Decision function scores on the training set. Only for models with a `decision_function` method. decision_function_test: list Decision function scores on the test set. Only for models with a `decision_function` method. score_bo: float Best score of the model on the Bayesian Optimization algorithm. score_train: float Metric score of the model on the training set. score_test: float Metric score of the model on the test set. bagging_scores: np.ndarray Array of the bagging's results. permutations: dict Dictionary of the permutation's results (if `plot_permutation_importance` was used). Plots The ATOM class provides a variety of plot methods to analyze the results of the pipeline. To use the plots to compare the results of multiple models, you can call them directly from the main class using the models parameter, e.g. atom.plot_PRC(models=['LDA', 'LGB']) . To call the plot for a single model, you can either fill the model in the models parameter (e.g. atom.plot_PRC(models='LDA') ) or call the from the model subclass (e.g. atom.LDA.plot_PRC() ). These two examples will render the same plot. Note that the latter approach is not available for the plot_correlation , plot_PCA , plot_components and plot_RFECV methods since they are unrelated to the models fitted in the pipeline. Note Remember that if successive halving=True, only the last fitted model is saved in the model subclass. Avoid plotting models from different iterations together since this can lead to misleading insights. The plots aesthetics can be customized using various classmethods . plot_correlation Correlation matrix plot of the data. plot_PCA Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per component. plot_RFECV Plot the scores obtained by the estimator on the RFECV. plot_bagging Plot a boxplot of the bagging's results. plot_successive_halving Plot the models' scores per iteration of the successive halving. plot_learning_curve Plot the model's learning curve: score vs training samples. plot_ROC Plot the Receiver Operating Characteristics curve. plot_PRC Plot the precision-recall curve. plot_permutation_importance Plot the feature permutation importance of models. plot_feature_importance Plot the feature permutation importance of models. plot_permutation_importance Plot tree-based model's normalized feature importances. plot_confusion_matrix Plot a model's confusion matrix. plot_threshold Plot performance metric(s) against threshold values. plot_probabilities Plot the probabilities of the different classes of belonging to the target class. plot_calibration Plot the calibration curve for a binary classifier. plot_gains Plot the cumulative gains curve. plot_lift Plot the lift curve. function atom.ATOM. plot_correlation (title=None, figsize=(10, 10), filename=None, display=True) [source] Correlation matrix plot of the dataset. Ignores non-numeric columns. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PCA (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of componenets. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: show: int or None, optional (default=None) Number of components to show. If None, the selected number of componenets are plotted. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_RFECV (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the scores obtained by the estimator fitted on every subset of the data. Only if RFECV was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_bagging (models=None, title=None, figsize=None, filename=None, display=True) [source] Plot a boxplot of the bagging's results. Only available if the models were fitted using bagging>0. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size the to number of models. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_successive_halving (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot of the models' scores per iteration of the successive halving. Only available if the models were fitted via successive_halving. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_learning_curve (models=None, train_sizes=np.linspace(0.1, 1.0, 10), cv=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the model's learning curve: score vs number of training samples. Only available if the models were fitted via train_sizing. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_ROC (models=None, title=None, figsize=(10, 6)), filename=None, display=True) [source] Plot the Receiver Operating Characteristics curve. The legend shows the Area Under the ROC Curve (AUC) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PRC (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the precision-recall curve. The legend shows the average precision (AP) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_permutation_importance (models=None, show=None, n_repeats=10, title=None, figsize=None, filename=None, display=True) [source] Plot the feature permutation importance of models. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. n_repeats: int, optional (default=10) Number of times to permute each feature. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_feature_importance (models=None, show=None, title=None, figsize=None, filename=None, display=True) [source] Plot a tree-based model's normalized feature importance. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_confusion_matrix (models=None, normalize=False, title=None, figsize=(8, 8), filename=None, display=True) [source] For 1 model: plot it's confusion matrix in a heatmap. For >1 models: compare TP, FP, FN and TN in a barplot. Not supported for multiclass classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. normalize: bool, optional (default=False) Wether to normalize the matrix. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(8, 8)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_threshold (models=None, metric=None, steps=100, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot performance metric(s) against multiple threshold values. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. metric: string, callable, sequence or None, optional (default=None) Metric(s) to plot. These can be one of the pre-defined sklearn scorers as string, a metric function or a sklearn scorer object. If None, the metric used to fit the pipeline is used. steps: int, optional (default=100) Number of thresholds measured. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_probabilities (models=None, target=1, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot a function of the probability of the classes of being the target class. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. target: int or string, optional (default=1) Probability of being that class (as index or name). title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_calibration (models=None, n_bins=10, title=None, figsize=(10, 10), filename=None, display=True) [source] Plot the calibration curve for a binary classifier. Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class. This figure shows two plots: the calibration curve and a distribution of all predicted probabilities of the classifier. Code snippets from https://scikit-learn.org/stable/auto_examples/ calibration/plot_calibration_curve.html . Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. n_bins: int, optional (default=10) Number of bins for the calibration calculation and the histogram. Minimum of 5 required. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_gains (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the cumulative gains curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_lift (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the lift curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. Plot customization The plotting aesthetics can be customized with the use of the @classmethods described hereunder, e.g. ATOMClassifier.set_style('white') . set_style Change the seaborn plotting style. set_palette Change the seaborn color palette. set_title_fontsize Change the fontsize of the plot's title. set_label_fontsize Change the fontsize of the plot's labels and legends. set_tick_fontsize Change the fontsize of the plot's ticks. classmethod ATOM. set_style (style='darkgrid') [source] Change the plotting style. See the seaborn documentation . Parameters: style: string, optional (default='darkgrid') Style to change to. Available options are: 'darkgrid', 'whitegrid', 'dark', 'white', and 'ticks'. classmethod ATOM. set_palette (palette='GnBu_d') [source] Change the plotting palette. See the seaborn documentation for the available options. Parameters: palette: string, optional (default='GnBu_d') Palette to change to. classmethod ATOM. set_title_fontsize (fontsize=20) [source] Change the fontsize of the plot's title. Parameters: fontsize: int, optional (default=20) Fontsize to change to. classmethod ATOM. set_label_fontsize (fontsize=16) [source] Change the fontsize of the plot's labels and legends. Parameters: fontsize: int, optional (default=16) Fontsize to change to. classmethod ATOM. set_tick_fontsize (fontsize=12) [source] Change the fontsize of the plot's ticks. Parameters: fontsize: int, optional (default=12) Fontsize to change to.","title":"API"},{"location":"api/#atom","text":"class atom. ATOM (X, y=None, percentage=100, test_size=0.3, log=None, n_jobs=1, warnings=False, verbose=0, random_state=None, verbose=0) [source] Main class of the package. The ATOM class is a parent class of the ATOMClassifier and ATOMRegressor classes. These will inherit all methods and attributes described in this page. Note that contrary to scikit-learn's API, the ATOM object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. Warning Don't call the ATOM class directly! Use ATOMClassifier or ATOMRegressor depending on the task at hand. Click here for an example. The class initializer will label-encode the target column if its labels are not ordered integers. It will also apply some standard data cleaning steps unto the dataset. These steps include: Transforming the input data into a pd.DataFrame (if it wasn't one already) that can be accessed through the class' data attributes. Removing columns with prohibited data types ('datetime64', 'datetime64[ns]', 'timedelta[ns]'). Removing categorical columns with maximal cardinality (the number of unique values is equal to the number of instances. Usually the case for names, IDs, etc...). Removing columns with minimum cardinality (all values are the same). Removing rows with missing values in the target column. Parameters: X: dict, sequence, np.array or pd.DataFrame Dataset containing the features, with shape=(n_samples, n_features). y: string, sequence, np.array or pd.Series, optional (default=None) If None: the last column of X is selected as target column If string: name of the target column in X Else: data target column with shape=(n_samples,) percentage: int or float, optional (default=100) Percentage of the provided dataset to use. test_size: float, optional (default=0.3) Split fraction of the train and test set. log: string or None, optional (default=None) Name of the logging file. 'auto' for default name with date and time. None to not save any log. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If -1, use all available cores If < -1, use available_cores - 1 + n_jobs Beware that using multiple processes on the same machine may cause memory issues for large datasets. warnings: bool, optional (default=False) If False, it supresses all warnings. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything 1 to print minimum information 2 to print average information 3 to print maximum information random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by np.random. Data attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. Attributes: mapping: dict Dictionary of the target values mapped to their respective encoded integer. Only for classification tasks. errors: dict Dictionary of the encountered exceptions (if any) while fitting the models. winner: callable Model subclass that performed best on the test set. scores: pd.DataFrame Dataframe (or list of dataframes if successive_halving=True) of the results. Columns can include: model: model's name (acronym) total_time: time spent on this model score_train: metric score on the training set score_test: metric score on the test set fit_time: time spent fitting and predicting bagging_mean: mean score of the bagging's results bagging_std: standard deviation score of the bagging's results bagging_time: time spent on the bagging algorithm","title":"ATOM"},{"location":"api/#utilities","text":"The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. stats Print out a list of basic statistics on the dataset. scale Scale all the features to mean=1 and std=0. update Update all data attributes. report Get an extensive profile analysis of the data. results Print final results for a specific metric. save Save the ATOM class to a pickle file. function atom.ATOM. stats () [source] Print out a list of basic statistics on the dataset. function atom.ATOM. scale () [source] Scale all the features to mean=1 and std=0. function atom.ATOM. update (df='dataset') [source] If you change any of the class' data attributes in between the pipeline, you should call this method to change all other data attributes to their correct values. Independent attributes are updated in unison, that is, setting df='X_train' will also update X_test, y_train and y_test, or df='train' will also update the test set, etc... This means that you can change both X_train and y_train and update them with one call of the method. Parameters: df: string, optional(default='dataset') Data attribute that has been changed. function atom.ATOM. report (df='dataset', rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for very large datasets. Dependency: pandas-profiling . Parameters: df: string, optional(default='dataset') Name of the data class attribute to get the profile from. rows: int or None, optional(default=None) Number of rows to process (randomly picked). None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. function atom.ATOM. results (metric=None) [source] Print the pipeline's final results for a specific metric. If a model shows a XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric needs it. Parameters: metric: string or None, optional (default=None) String of one of sklearn's predefined metrics. If None, the metric used to fit the pipeline is selected and the bagging results will be showed (if used). function atom.ATOM. save (filename=None) [source] Save the ATOM class to a pickle file. This method is also available for the model subclasses, e.g. atom.XGB.save(filename='ATOM_xgboost') . In this case, the model subclass is saved, instead of the ATOM class. Warning Remember that the class contains the complete dataset (and variations of it). This means the files can become very large for big datasets! Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name.","title":"Utilities"},{"location":"api/#data-cleaning","text":"Before throwing your data in a model, it is crucial to apply some standard data cleaning steps. ATOM provides four data cleaning methods to handle missing values, categorical columns, outliers and unbalanced datasets. Calling on one of them will automatically apply the method on the dataset in the class and update the class' data attributes accordingly. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. impute Handle missing values in the dataset. encode Encode categorical columns. outliers Remove outliers from the training set. balance Balance the number of instances per target class. function atom.ATOM. impute (strat_num='remove', strat_cat='remove', max_frac_rows=0.5, max_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. Parameters: strat_num: str, int or float, optional (default='remove') Imputing strategy for numerical columns. Choose from: 'remove': remove row if any missing value 'mean': impute with mean of column 'median': impute with median of column 'knn': impute using a K-Nearest Neighbors approach 'most_frequent': impute with most frequent value int or float: impute with provided numerical value strat_cat: str, optional (default='remove') Imputing strategy for categorical columns. Choose from: 'remove': remove row if any missing value 'most_frequent': impute with most frequent value string: impute with provided string min_frac_rows: float, optional (default=0.5) Minimum fraction of non missing values in a row. If less, the row is removed. min_frac_cols: float, optional (default=0.5) Minimum fraction of non missing values in a column. If less, the column is removed. missing: int, float or list, optional (default=None) List of values to impute. None for default list: [None, np.NaN, np.inf, -np.inf, '', '?', 'NA', 'nan', 'inf']. function atom.ATOM. encode (max_onehot=10, frac_to_other=0) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: label-encoding for n_unique=2 one-hot-encoding for 2 < n_unique <= max_onehot target-encoding for n_unique > max_onehot It also replaces classes with low occurences with the value 'other' in order to prevent too high cardinality. Parameters: max_onehot: int or None, optional (default=10) Maximum number of unique values in a feature to perform one-hot-encoding. If None, it will never perform one-hot-encoding. frac_to_other: float, optional (default=0) Classes with less instances than n_rows * fraction_to_other are replaced with 'other'. function atom.ATOM. outliers (max_sigma=3, include_target=False) [source] Remove rows from the training set where at least one of the values lies further than max_sigma * standard_deviation away from the mean of the column. Parameters: max_sigma: int or float, optional (default=3) Maximum allowed standard deviations from the mean. include_target: bool, optional (default=False) Wether to include the target column when searching for outliers. function atom.ATOM. balance (oversample=None, undersample=None, n_neighbors=5) [source] Balance the number of instances per target class in the training set. If both oversampling and undersampling are used, they will be applied in that order. Only for classification tasks. Dependency: imbalanced-learn . Parameters: oversample: float, string or None, optional (default=None) Oversampling strategy using ADASYN . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'minority': resample only the minority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes undersample: float, string or None, optional (default=None) Undersampling strategy using NearMiss . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'majority': resample only the majority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes n_neighbors: int, optional (default=5) Number of nearest neighbors used for any of the algorithms.","title":"Data cleaning"},{"location":"api/#feature-selection","text":"To further pre-process the data you can create new non-linear features using a genetic algorithm or, if your dataset is too large, remove features using one of the provided strategies. feature_insertion Use a genetic algorithm to create new combinations of existing features. feature_selection Remove features according to the selected strategy. function atom.ATOM. feature_insertion (n_features=2, generations=20, population=500) [source] Use a genetic algorithm to create new combinations of existing features and add them to the original dataset in order to capture the non-linear relations between the original features. A dataframe containing the description of the newly generated features and their scores can be accessed through the genetic_features attribute. The algorithm is implemented using the Symbolic Transformer method, which can be accessed through the genetic_algorithm attribute. It is adviced to only use this method when fitting linear models. Dependency: gplearn . Parameters: n_features: int, optional (default=2) Maximum number of newly generated features (no more than 1% of the population). generations: int, optional (default=20) Number of generations to evolve. population: int, optional (default=500) Number of programs in each generation. function atom.ATOM. feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=0.98, **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. Note that the RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs. If the pipeline has already ran before running the RFECV, the scoring parameter will be set to the selected metric (if scoring=None). Parameters: strategy: string or None, optional (default=None) Feature selection strategy to use. Choose from: None: do not perform any feature selection algorithm 'univariate': perform a univariate F-test, from sklearn SelectKBest 'PCA': perform a principal component analysis, from sklearn PCA 'SFM': select best features from model, from sklearn SelectFromModel 'RFE': recursive feature eliminator, from sklearn RFE 'RFECV': RFE with cross-validated selection, from sklearn RFECV The sklearn objects can be found under the univariate , PCA , SFM , RFE or RFECV attributes of the class. solver: string, callable or None, optional (default=None) Solver or model to use for the feature selection strategy. See the sklearn documentation for an extended descrition of the choices. Select None for the default option per strategy (not applicable for SFM, RFE and RFECV). for 'univariate', choose from: 'f_classif' (default for classification tasks) 'f_regression' (default for regression tasks) 'mutual_info_classif' 'mutual_info_regression' 'chi2' Any function taking two arrays (X, y), and returning arrays (scores, pvalues). for 'PCA', choose from: 'auto' (default) 'full' 'arpack' 'randomized' for 'SFM': choose a base estimator from which the transformer is built. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFE': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFECV': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. n_features: int, float or None, optional (default=None) Number of features to select (except for RFECV, where it's the minimum number of features to select). if < 1: fraction of features to select if >= 1: number of features to select None to select all, or 1 for the RFECV max_frac_repeated: float or None, optional (default=1.) Remove features with the same value in at least this fraction of the total rows. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples. None to skip this step. max_correlation: float or None, optional (default=0.98) Minimum value of the Pearson correlation cofficient to identify correlated features. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. None to skip this step. **kwargs Any extra parameter for the PCA, SFM, RFE or RFECV. See the sklearn documentation for the available options.","title":"Feature selection"},{"location":"api/#pipeline","text":"The pipeline method is where the models are fitted to the data and their performance is evaluated according to the selected metric. For every model, the pipeline applies the following steps: The optimal hyperparameters are selectred using a Bayesian Optimization (BO) algorithm with gaussian process as kernel. The resulting score of each step of the BO is either computed by cross-validation on the complete training set or by randomly splitting the training set every iteration into a (sub) training set and a validation set. This process can create some data leakage but ensures a maximal use of the provided data. The test set, however, does not contain any leakage and will be used to determine the final score of every model. Note that, if the dataset is relatively small, the best score on the BO can consistently be lower than the final score on the test set (despite the leakage) due to the considerable fewer instances on which it is trained. Once the best hyperparameters are found, the model is trained again, now using the complete training set. After this, predictions are made on the test set. You can choose to evaluate the robustness of each model's applying a bagging algorithm, i.e. the model will be trained multiple times on a bootstrapped training set, returning a distribution of its performance on the test set. A couple of things to take into account: The metric implementation follows sklearn's API . This means that the implementation always tries to maximize the scorer, i.e. loss functions will be made negative. If an exception is encountered while fitting a model, the pipeline will automatically jump to the next model and save the exception in the errors attribute. When showing the final results, a !! indicates the highest score and a ~ indicates that the model is possibly overfitting (training set has a score at least 20% higher than the test set). The winning model subclass will be attached to the winner attribute. There are three methods to call for the pipeline. The pipeline method fits the models directly to the dataset. If you want to compare similar models, you can use the successive_halving method when running the pipeline. This technique fits N models to 1/N of the data. The best half are selected to go to the next iteration where the process is repeated. This continues until only one model remains, which is fitted on the complete dataset. Beware that a model's performance can depend greatly on the amount of data on which it is trained. For this reason we recommend only to use this technique with similar models, e.g. only using tree-based models. The train_sizing method fits the models on subsets of the training data. This can be used to examine the optimum size of the dataset needed for a satisfying performance. pipeline Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. function atom.ATOM. pipeline (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_iter=0, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. skip_iter: int, optional (default=0) Skip last skip_iter iterations of the successive halving. Will be ignored if successive_halving=False. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspcae(0.1, 1.0, 10), max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. train_sizes: sequence, optional (default=np.linspace(0.1, 1.0, 10)) Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set. Otherwise it is interpreted as absolute sizes of the training sets. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed.","title":"Pipeline"},{"location":"api/#model-subclass","text":"After running the pipeline method, a class for every selected model is created and attached to the main ATOM class as an attribute. These classes can be called upon using the models' acronyms, e.g. atom.LGB . Lowercase calls are also allowed for this attribute, e.g. atom.lgb . The model subclasses contain a variety of methods and attributes to help you understand how every specific model performed. The majority of the plots can be called directly from the subclasses. For example, to plot the ROC for the LightGBM model we could type atom.lgb.plot_ROC() . You can also save the whole subclass to a pickle file using the save method, e.g. atom.rf.save('random_forest') , or only save the best fitted model with the save_model method, e.g. atom.rf.save_model('random_forest_model') . You can also call for any of the sklearn pre-defined metrics, (e.g. atom.ET.recall ) or for any of the following custom metrics: tn (true negatives), fp (false positives), fn (false negatives), tp (true positives), tpr (true positive rate), fpr (false positive rate), sup (support/predicted positive rate) or lift . The rest of the available attributes can be found hereunder: Parameters: error: string Any exception encountered by the model. BO: dict Dictionary containing the information of every step taken by the BO. Keys include: 'params': Parameters used for the model 'score': Score of the chosen metric 'time': Time spent on this iteration 'total_time': Time spent since the start of the BO best_params: dict Dictionary of the best combination of hyperparameters found by the BO. best_model: callable Model object that performed best on the test set. Not fitted. best_model_fit: callable Model object that performed best on the test set. Fitted to the complete training set. predict_train: list Predictions of the model on the training set. predict_test: list Predictions of the model on the test set. predict_proba_train: list Predict probabilities of the model on the training set. Only for models with a `predict_proba` method. predict_proba_test: list Predict probabilities of the model on the test set. Only for models with a `predict_proba` method. decision_function_train: list Decision function scores on the training set. Only for models with a `decision_function` method. decision_function_test: list Decision function scores on the test set. Only for models with a `decision_function` method. score_bo: float Best score of the model on the Bayesian Optimization algorithm. score_train: float Metric score of the model on the training set. score_test: float Metric score of the model on the test set. bagging_scores: np.ndarray Array of the bagging's results. permutations: dict Dictionary of the permutation's results (if `plot_permutation_importance` was used).","title":"Model subclass"},{"location":"api/#plots","text":"The ATOM class provides a variety of plot methods to analyze the results of the pipeline. To use the plots to compare the results of multiple models, you can call them directly from the main class using the models parameter, e.g. atom.plot_PRC(models=['LDA', 'LGB']) . To call the plot for a single model, you can either fill the model in the models parameter (e.g. atom.plot_PRC(models='LDA') ) or call the from the model subclass (e.g. atom.LDA.plot_PRC() ). These two examples will render the same plot. Note that the latter approach is not available for the plot_correlation , plot_PCA , plot_components and plot_RFECV methods since they are unrelated to the models fitted in the pipeline. Note Remember that if successive halving=True, only the last fitted model is saved in the model subclass. Avoid plotting models from different iterations together since this can lead to misleading insights. The plots aesthetics can be customized using various classmethods . plot_correlation Correlation matrix plot of the data. plot_PCA Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per component. plot_RFECV Plot the scores obtained by the estimator on the RFECV. plot_bagging Plot a boxplot of the bagging's results. plot_successive_halving Plot the models' scores per iteration of the successive halving. plot_learning_curve Plot the model's learning curve: score vs training samples. plot_ROC Plot the Receiver Operating Characteristics curve. plot_PRC Plot the precision-recall curve. plot_permutation_importance Plot the feature permutation importance of models. plot_feature_importance Plot the feature permutation importance of models. plot_permutation_importance Plot tree-based model's normalized feature importances. plot_confusion_matrix Plot a model's confusion matrix. plot_threshold Plot performance metric(s) against threshold values. plot_probabilities Plot the probabilities of the different classes of belonging to the target class. plot_calibration Plot the calibration curve for a binary classifier. plot_gains Plot the cumulative gains curve. plot_lift Plot the lift curve. function atom.ATOM. plot_correlation (title=None, figsize=(10, 10), filename=None, display=True) [source] Correlation matrix plot of the dataset. Ignores non-numeric columns. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PCA (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of componenets. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: show: int or None, optional (default=None) Number of components to show. If None, the selected number of componenets are plotted. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_RFECV (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the scores obtained by the estimator fitted on every subset of the data. Only if RFECV was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_bagging (models=None, title=None, figsize=None, filename=None, display=True) [source] Plot a boxplot of the bagging's results. Only available if the models were fitted using bagging>0. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size the to number of models. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_successive_halving (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot of the models' scores per iteration of the successive halving. Only available if the models were fitted via successive_halving. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_learning_curve (models=None, train_sizes=np.linspace(0.1, 1.0, 10), cv=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the model's learning curve: score vs number of training samples. Only available if the models were fitted via train_sizing. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_ROC (models=None, title=None, figsize=(10, 6)), filename=None, display=True) [source] Plot the Receiver Operating Characteristics curve. The legend shows the Area Under the ROC Curve (AUC) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PRC (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the precision-recall curve. The legend shows the average precision (AP) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_permutation_importance (models=None, show=None, n_repeats=10, title=None, figsize=None, filename=None, display=True) [source] Plot the feature permutation importance of models. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. n_repeats: int, optional (default=10) Number of times to permute each feature. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_feature_importance (models=None, show=None, title=None, figsize=None, filename=None, display=True) [source] Plot a tree-based model's normalized feature importance. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_confusion_matrix (models=None, normalize=False, title=None, figsize=(8, 8), filename=None, display=True) [source] For 1 model: plot it's confusion matrix in a heatmap. For >1 models: compare TP, FP, FN and TN in a barplot. Not supported for multiclass classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. normalize: bool, optional (default=False) Wether to normalize the matrix. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(8, 8)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_threshold (models=None, metric=None, steps=100, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot performance metric(s) against multiple threshold values. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. metric: string, callable, sequence or None, optional (default=None) Metric(s) to plot. These can be one of the pre-defined sklearn scorers as string, a metric function or a sklearn scorer object. If None, the metric used to fit the pipeline is used. steps: int, optional (default=100) Number of thresholds measured. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_probabilities (models=None, target=1, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot a function of the probability of the classes of being the target class. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. target: int or string, optional (default=1) Probability of being that class (as index or name). title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_calibration (models=None, n_bins=10, title=None, figsize=(10, 10), filename=None, display=True) [source] Plot the calibration curve for a binary classifier. Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class. This figure shows two plots: the calibration curve and a distribution of all predicted probabilities of the classifier. Code snippets from https://scikit-learn.org/stable/auto_examples/ calibration/plot_calibration_curve.html . Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. n_bins: int, optional (default=10) Number of bins for the calibration calculation and the histogram. Minimum of 5 required. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_gains (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the cumulative gains curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_lift (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the lift curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot.","title":"Plots"},{"location":"api/#plot-customization","text":"The plotting aesthetics can be customized with the use of the @classmethods described hereunder, e.g. ATOMClassifier.set_style('white') . set_style Change the seaborn plotting style. set_palette Change the seaborn color palette. set_title_fontsize Change the fontsize of the plot's title. set_label_fontsize Change the fontsize of the plot's labels and legends. set_tick_fontsize Change the fontsize of the plot's ticks. classmethod ATOM. set_style (style='darkgrid') [source] Change the plotting style. See the seaborn documentation . Parameters: style: string, optional (default='darkgrid') Style to change to. Available options are: 'darkgrid', 'whitegrid', 'dark', 'white', and 'ticks'. classmethod ATOM. set_palette (palette='GnBu_d') [source] Change the plotting palette. See the seaborn documentation for the available options. Parameters: palette: string, optional (default='GnBu_d') Palette to change to. classmethod ATOM. set_title_fontsize (fontsize=20) [source] Change the fontsize of the plot's title. Parameters: fontsize: int, optional (default=20) Fontsize to change to. classmethod ATOM. set_label_fontsize (fontsize=16) [source] Change the fontsize of the plot's labels and legends. Parameters: fontsize: int, optional (default=16) Fontsize to change to. classmethod ATOM. set_tick_fontsize (fontsize=12) [source] Change the fontsize of the plot's ticks. Parameters: fontsize: int, optional (default=12) Fontsize to change to.","title":"Plot customization"},{"location":"dependencies/","text":"Python As of the moment, ATOM supports Python 3.6 , 3.7 and 3.8 . Packages ATOM is built on top of several existing Python libraries. The required packages are necessary for it's correct functioning. Additionnaly, you can install some optional packages needed for specific methods or to use machine learning models not provided by sklearn. Required numpy (>=1.17.2) scipy (>=1.4.1) pandas (>=1.0.1) scikit-learn (>=0.22) tabulate (>=0.8.6) tqdm (>=4.35.0) typeguard (>=2.7.1) gpyopt (>=1.2.5) matplotlib (>=3.1.0) seaborn (>=0.9.0) Optional pandas-profiling (>=2.3.0) imbalanced-learn (>=0.5.0) gplearn (>=0.4.1) xgboost (>=0.90) lightgbm (>=2.3.0) catboost (>=0.19.1)","title":"Dependencies"},{"location":"dependencies/#python","text":"As of the moment, ATOM supports Python 3.6 , 3.7 and 3.8 .","title":"Python"},{"location":"dependencies/#packages","text":"ATOM is built on top of several existing Python libraries. The required packages are necessary for it's correct functioning. Additionnaly, you can install some optional packages needed for specific methods or to use machine learning models not provided by sklearn. Required numpy (>=1.17.2) scipy (>=1.4.1) pandas (>=1.0.1) scikit-learn (>=0.22) tabulate (>=0.8.6) tqdm (>=4.35.0) typeguard (>=2.7.1) gpyopt (>=1.2.5) matplotlib (>=3.1.0) seaborn (>=0.9.0) Optional pandas-profiling (>=2.3.0) imbalanced-learn (>=0.5.0) gplearn (>=0.4.1) xgboost (>=0.90) lightgbm (>=2.3.0) catboost (>=0.19.1)","title":"Packages"},{"location":"examples/","text":"Binary classification Download the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . This dataset tries to predict whether or not it will rain tomorrow by training a classification model on target RainTomorrow . Load the data # Import packages import numpy as np import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('../weatherAUS.csv') X = X.drop(['RISK_MM', 'Date'], axis=1) # Drop unrelated features # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow 0 Albury 13.4 22.9 0.6 NaN NaN W 44.0 W WNW 20.0 24.0 71.0 22.0 1007.7 1007.1 8.0 NaN 16.9 21.8 No No 1 Albury 7.4 25.1 0.0 NaN NaN WNW 44.0 NNW WSW 4.0 22.0 44.0 25.0 1010.6 1007.8 NaN NaN 17.2 24.3 No No 2 Albury 12.9 25.7 0.0 NaN NaN WSW 46.0 W WSW 19.0 26.0 38.0 30.0 1007.6 1008.7 NaN 2.0 21.0 23.2 No No 3 Albury 9.2 28.0 0.0 NaN NaN NE 24.0 SE E 11.0 9.0 45.0 16.0 1017.6 1012.8 NaN NaN 18.1 26.5 No No 4 Albury 17.5 32.3 1.0 NaN NaN W 41.0 ENE NW 7.0 20.0 82.0 33.0 1010.8 1006.0 7.0 8.0 17.8 29.7 No No Run the pipeline # Call ATOM using only a percentage of the complete dataset (for explanatory purposes) atom = ATOMClassifier(X, y=\"RainTomorrow\", percentage=5, log='auto', n_jobs=2, verbose=3) <<=============== ATOM ===============>> Parallel processing with 2 cores. Initial data cleaning... Algorithm task: binary classification. Dataset stats ===================> Shape: (7110, 22) Missing values: 15836 Categorical columns: 5 Scaled: False ---------------------------------- Size of training set: 4977 Size of test set: 2133 ---------------------------------- Class balance: No:Yes <==> 3.6:1.0 Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 5562 | 3896 | 1666 | | 1: Yes | 1548 | 1081 | 467 | # If we change a column during the pre-processing, # we need to call the update method to update all data attributes atom.X['MaxTemp'] = np.log(atom.X['MaxTemp']) # Random operator on column MaxTemp # MaxTemp has now been changed for atom.X, but not in atom.X_train, atom.dataset, etc... # To do so, we use the update method, where the parameter is a string of the changed attribute atom.update('X') assert atom.X['MaxTemp'].equals(atom.dataset['MaxTemp']) # Impute missing values atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) Imputing missing values... --> Removing 736 rows for containing too many missing values. --> Imputing 10 missing values using the KNN imputer in feature MinTemp. --> Imputing 2 missing values using the KNN imputer in feature MaxTemp. --> Imputing 35 missing values using the KNN imputer in feature Rainfall. --> Imputing 2365 missing values using the KNN imputer in feature Evaporation. --> Imputing 2666 missing values using the KNN imputer in feature Sunshine. --> Removing 224 rows due to missing values in feature WindGustDir. --> Imputing 223 missing values using the KNN imputer in feature WindGustSpeed. --> Removing 327 rows due to missing values in feature WindDir9am. --> Removing 26 rows due to missing values in feature WindDir3pm. --> Imputing 4 missing values using the KNN imputer in feature WindSpeed9am. --> Imputing 5 missing values using the KNN imputer in feature WindSpeed3pm. --> Imputing 25 missing values using the KNN imputer in feature Humidity9am. --> Imputing 59 missing values using the KNN imputer in feature Humidity3pm. --> Imputing 55 missing values using the KNN imputer in feature Pressure9am. --> Imputing 52 missing values using the KNN imputer in feature Pressure3pm. --> Imputing 2127 missing values using the KNN imputer in feature Cloud9am. --> Imputing 2209 missing values using the KNN imputer in feature Cloud3pm. --> Imputing 5 missing values using the KNN imputer in feature Temp9am. --> Imputing 41 missing values using the KNN imputer in feature Temp3pm. --> Removing 35 rows due to missing values in feature RainToday. # Encode the categorical features atom.encode(max_onehot=10, frac_to_other=0.04) Encoding categorical features... --> Target-encoding feature Location. Contains 1 unique categories. --> Target-encoding feature WindGustDir. Contains 16 unique categories. --> Target-encoding feature WindDir9am. Contains 16 unique categories. --> Target-encoding feature WindDir3pm. Contains 16 unique categories. --> Label-encoding feature RainToday. Contains 2 unique categories. # Perform undersampling of the majority class to balance the dataset atom.balance(undersample=0.8) Performing undersampling... --> Removing 239 rows from class No. Using TensorFlow backend. # Remove outliers from the training set atom.outliers(max_sigma=5) Handling outliers... --> Dropping 22 rows due to outliers. # Select only the best 10 features atom.feature_selection(strategy=\"univariate\", max_features=15, max_correlation=0.8) # See which features were removed due to collinearity atom.collinear Performing feature selection... --> Feature Pressure3pm was removed due to collinearity with another feature. --> Feature Temp9am was removed due to collinearity with another feature. --> Feature Temp3pm was removed due to collinearity with another feature. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } drop_feature correlated_feature correlation_value 0 Pressure3pm Pressure9am 0.95258 1 Temp9am MinTemp, MaxTemp 0.93135, 0.89859 2 Temp3pm MaxTemp, Temp9am 0.95784, 0.88146 # Change the verbosity of ATOM to not print too much details while fitting atom.verbose = 2 # Define a custom metric def f2_score(y_true, y_pred): return fbeta_score(y_true, y_pred, beta=2) # We can compare the performance of various gradient boosting algorithms atom.pipeline(['gbm', 'lgb', 'catb'], metric=f2_score, max_iter=5, init_points=5, cv=1, bagging=5) Running pipeline =================> Models in pipeline: GBM, LGB, CatB Metric: f2_score Running BO for Gradient Boosting Machine... Final results for Gradient Boosting Machine: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 249, 'learning_rate': 1.0, 'subsample': 0.7, 'max_depth': 2, 'max_features': 0.6, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 11, 'ccp_alpha': 0.02} Best score on the BO: 0.7684 Time elapsed: 6.856s Fitting ----------------------------------------- Score on the training set: 0.7305 Score on the test set: 0.6330 Time elapsed: 0.491s Bagging ----------------------------------------- Mean: 0.6086 Std: 0.0269 Time elapsed: 2.117s ------------------------------------------------- Total time: 9.469s Running BO for LightGBM... Final results for LightGBM: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 361, 'learning_rate': 0.8, 'max_depth': 1, 'num_leaves': 37, 'min_child_weight': 11, 'min_child_samples': 14, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.1, 'reg_lambda': 100.0} Best score on the BO: 0.7471 Time elapsed: 3.781s Fitting ----------------------------------------- Score on the training set: 0.7702 Score on the test set: 0.6831 Time elapsed: 0.139s Bagging ----------------------------------------- Mean: 0.6671 Std: 0.0173 Time elapsed: 0.258s ------------------------------------------------- Total time: 4.181s Running BO for CatBoost... Final results for CatBoost: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 461, 'learning_rate': 0.38, 'max_depth': 3, 'subsample': 0.6, 'colsample_bylevel': 1.0, 'reg_lambda': 30.0} Best score on the BO: 0.7465 Time elapsed: 24.624s Fitting ----------------------------------------- Score on the training set: 0.9644 Score on the test set: 0.6531 Time elapsed: 0.596s Bagging ----------------------------------------- Mean: 0.6606 Std: 0.0074 Time elapsed: 2.815s ------------------------------------------------- Total time: 28.040s Final results ================>> Duration: 41.841s Metric: f2_score -------------------------------- Gradient Boosting Machine --> 0.609 \u00b1 0.027 LightGBM --> 0.667 \u00b1 0.017 !! CatBoost --> 0.661 \u00b1 0.007 ~ Analyze the results # Let's have a look at the best model print('And the winner is...', atom.winner.longname) # The ~ symbol indicates that the model is probably overfitting the training set # This happens because we only use 5% of the dataset # We can see that the training score is >20% of the test score print('Score on the training set: ', atom.winner.score_train) print('Score on the test set: ', atom.winner.score_test) And the winner is... LightGBM Score on the training set: 0.7702407002188184 Score on the test set: 0.6830769230769231 # Check the winner's confusion matrix and probability distribution atom.winner.plot_confusion_matrix(normalize=True, figsize=(7, 7), filename='confusion_matrix.png') atom.winner.plot_probabilities() # How do other metrics perform for different thresholds on the winning model atom.winner.plot_threshold(metric=['f1', 'accuracy', 'average_precision'], steps=50, filename='thresholds.png') # Change plots aesthetics ATOMClassifier.set_style('whitegrid') ATOMClassifier.set_title_fontsize(24) # Make some plots to compare the models atom.plot_ROC(title=\"ROC for the LightGBM vs CatBoost model\") atom.plot_PRC(title=\"PRC comparison of the models\") Multiclass classification Import the wine dataset from sklearn.datasets . This is a small and easy to train dataset which goal is to classify wines into three groups (which cultivator it's from) using features based on the results of chemical analysis. Load the data # Import packages import numpy as np import pandas as pd from sklearn.datasets import load_wine from atom import ATOMClassifier # Load the dataset's features and targets dataset = load_wine() # Convert to pd.DataFrame to get the names of the features data = np.c_[dataset.data, dataset.target] columns = np.append(dataset.feature_names, [\"target\"]) data = pd.DataFrame(data, columns=columns) X = data.drop('target', axis=1) y = data['target'] # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } alcohol malic_acid ash alcalinity_of_ash magnesium total_phenols flavanoids nonflavanoid_phenols proanthocyanins color_intensity hue od280/od315_of_diluted_wines proline 0 14.23 1.71 2.43 15.6 127.0 2.80 3.06 0.28 2.29 5.64 1.04 3.92 1065.0 1 13.20 1.78 2.14 11.2 100.0 2.65 2.76 0.26 1.28 4.38 1.05 3.40 1050.0 2 13.16 2.36 2.67 18.6 101.0 2.80 3.24 0.30 2.81 5.68 1.03 3.17 1185.0 3 14.37 1.95 2.50 16.8 113.0 3.85 3.49 0.24 2.18 7.80 0.86 3.45 1480.0 4 13.24 2.59 2.87 21.0 118.0 2.80 2.69 0.39 1.82 4.32 1.04 2.93 735.0 Run the pipeline # Call ATOMclass for ML task exploration atom = ATOMClassifier(X, y, n_jobs=-1, verbose=3) # Fit the pipeline with the selected models atom.pipeline(models=['LDA','RF', 'lSVM'], metric='f1_macro', max_iter=4, init_points=3, cv=3, bagging=10) <<=============== ATOM ===============>> Parallel processing with 4 cores. Initial data cleaning... Algorithm task: multiclass classification. Number of classes: 3. Dataset stats ===================> Shape: (178, 14) Scaled: False ---------------------------------- Size of training set: 124 Size of test set: 54 ---------------------------------- Class balance: 0:1:2 <==> 1.2:1.5:1.0 Instances in target per class: | | total | train_set | test_set | |---:|---------:|-------------:|------------:| | 0 | 59 | 40 | 19 | | 1 | 71 | 53 | 18 | | 2 | 48 | 31 | 17 | Running pipeline =================> Models in pipeline: LDA, RF, lSVM Metric: f1_macro Running BO for Linear Discriminant Analysis... Initial point: 1 -------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.774s Total time: 0.774s Initial point: 2 -------------------------------- Parameters --> {'solver': 'eigen', 'shrinkage': 0.3} Evaluation --> f1_macro: 0.6488 Time elapsed: 0.477s Total time: 1.251s Initial point: 3 -------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.019s Total time: 1.270s Iteration: 1 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.019s Total time: 1.485s Iteration: 2 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.024s Total time: 1.690s Iteration: 3 ------------------------------------ Parameters --> {'solver': 'eigen', 'shrinkage': 0.7} Evaluation --> f1_macro: 0.6951 Time elapsed: 0.020s Total time: 1.895s Iteration: 4 ------------------------------------ Parameters --> {'solver': 'lsqr', 'shrinkage': 1.0} Evaluation --> f1_macro: 0.7274 Time elapsed: 0.024s Total time: 2.107s Final results for Linear Discriminant Analysis: Bayesian Optimization --------------------------- Best hyperparameters: {'solver': 'svd'} Best score on the BO: 0.9754 Time elapsed: 2.240s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 1.0000 Time elapsed: 0.043s Bagging ----------------------------------------- Mean: 1.0000 Std: 0.0000 Time elapsed: 0.039s ------------------------------------------------- Total time: 2.324s Running BO for Random Forest... Initial point: 1 -------------------------------- Parameters --> {'n_estimators': 361, 'max_depth': 7, 'max_features': 0.7, 'criterion': 'gini', 'min_samples_split': 6, 'min_samples_leaf': 2, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.7} Evaluation --> f1_macro: 0.9377 Time elapsed: 0.497s Total time: 0.498s Initial point: 2 -------------------------------- Parameters --> {'n_estimators': 39, 'max_depth': 7, 'max_features': 0.6, 'criterion': 'gini', 'min_samples_split': 17, 'min_samples_leaf': 1, 'ccp_alpha': 0.035, 'bootstrap': True, 'max_samples': 0.8} Evaluation --> f1_macro: 0.9454 Time elapsed: 0.271s Total time: 0.769s Initial point: 3 -------------------------------- Parameters --> {'n_estimators': 62, 'max_depth': 9, 'max_features': 0.9, 'criterion': 'entropy', 'min_samples_split': 19, 'min_samples_leaf': 4, 'ccp_alpha': 0.005, 'bootstrap': False} Evaluation --> f1_macro: 0.8743 Time elapsed: 0.274s Total time: 1.044s Iteration: 1 ------------------------------------ Parameters --> {'n_estimators': 40, 'max_depth': 7, 'max_features': 0.6, 'criterion': 'gini', 'min_samples_split': 17, 'min_samples_leaf': 1, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.8} Evaluation --> f1_macro: 0.9229 Time elapsed: 0.243s Total time: 1.556s Iteration: 2 ------------------------------------ Parameters --> {'n_estimators': 500, 'max_depth': 3, 'max_features': 0.5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 1, 'ccp_alpha': 0.035, 'bootstrap': True, 'max_samples': 0.9} Evaluation --> f1_macro: 0.9377 Time elapsed: 0.624s Total time: 2.408s Iteration: 3 ------------------------------------ Parameters --> {'n_estimators': 500, 'max_depth': 3, 'max_features': 0.6, 'criterion': 'entropy', 'min_samples_split': 18, 'min_samples_leaf': 4, 'ccp_alpha': 0.02, 'bootstrap': False} Evaluation --> f1_macro: 0.9141 Time elapsed: 0.754s Total time: 3.437s Iteration: 4 ------------------------------------ Parameters --> {'n_estimators': 499, 'max_depth': 5, 'max_features': 0.5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 7, 'ccp_alpha': 0.015, 'bootstrap': True, 'max_samples': 0.5} Evaluation --> f1_macro: 0.9460 Time elapsed: 0.632s Total time: 4.321s Final results for Random Forest: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 499, 'max_depth': 5, 'max_features': 0.5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 7, 'ccp_alpha': 0.015, 'bootstrap': True, 'max_samples': 0.5} Best score on the BO: 0.9460 Time elapsed: 4.527s Fitting ----------------------------------------- Score on the training set: 0.9758 Score on the test set: 1.0000 Time elapsed: 1.150s Bagging ----------------------------------------- Mean: 0.9817 Std: 0.0184 Time elapsed: 6.119s ------------------------------------------------- Total time: 11.797s Running BO for Linear SVM... Initial point: 1 -------------------------------- Parameters --> {'C': 0.1, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9680 Time elapsed: 0.023s Total time: 0.024s Initial point: 2 -------------------------------- Parameters --> {'C': 0.1, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9913 Time elapsed: 0.020s Total time: 0.045s Initial point: 3 -------------------------------- Parameters --> {'C': 0.001, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9215 Time elapsed: 0.019s Total time: 0.065s Iteration: 1 ------------------------------------ Parameters --> {'C': 100, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9503 Time elapsed: 0.025s Total time: 0.282s Iteration: 2 ------------------------------------ Parameters --> {'C': 0.001, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.1626 Time elapsed: 0.024s Total time: 0.563s Iteration: 3 ------------------------------------ Parameters --> {'C': 100, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9503 Time elapsed: 0.021s Total time: 0.806s Iteration: 4 ------------------------------------ Parameters --> {'C': 100, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9503 Time elapsed: 0.021s Total time: 1.056s Final results for Linear SVM: Bayesian Optimization --------------------------- Best hyperparameters: {'C': 0.1, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Best score on the BO: 0.9913 Time elapsed: 1.247s Fitting ----------------------------------------- Score on the training set: 0.9842 Score on the test set: 1.0000 Time elapsed: 0.032s Bagging ----------------------------------------- Mean: 1.0000 Std: 0.0000 Time elapsed: 0.030s ------------------------------------------------- Total time: 1.309s Final results ================>> Duration: 15.434s Metric: f1_macro -------------------------------- Linear Discriminant Analysis --> 1.000 \u00b1 0.000 !! Random Forest --> 0.982 \u00b1 0.018 Linear SVM --> 1.000 \u00b1 0.000 !! Analyze the results atom.scores .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } model total_time score_train score_test fit_time bagging_mean bagging_std bagging_time 0 LDA 2.324s 1.000000 1.0 0.043s 1.000000 0.000000 0.039s 1 RF 11.797s 0.975759 1.0 1.150s 0.981706 0.018371 6.119s 2 lSVM 1.309s 0.984184 1.0 0.032s 1.000000 0.000000 0.030s # Show the results for a different metric atom.results('precision_macro') Final results ================>> Metric: precision_macro -------------------------------- Linear Discriminant Analysis --> 1.000 !! Random Forest --> 1.000 !! Linear SVM --> 1.000 !! atom.plot_bagging() Let's have a closer look at the Random Forest # Get the results on some other metrics print('Jaccard score:', atom.rf.jaccard_weighted) print('Recall score:', atom.rf.recall_macro) Jaccard score: 1.0 Recall score: 1.0 # Check the winner's confusion matrix atom.RF.plot_confusion_matrix() # Save the random forest class for production atom.RF.save('Random_Forest_class') Random Forest model subclass saved successfully! Regression Download the abalone dataset from https://archive.ics.uci.edu/ml/datasets/Abalone . The goal of this dataset is to predict the age of abalone shells from physical measurements. Load the data # Import packages import pandas as pd from atom import ATOMRegressor # Load the abalone dataset X = pd.read_csv('../abalone.csv') # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex Length Diameter Height Whole weight Shucked weight Viscera weight Shell weight Rings 0 M 0.455 0.365 0.095 0.5140 0.2245 0.1010 0.150 15 1 M 0.350 0.265 0.090 0.2255 0.0995 0.0485 0.070 7 2 F 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9 3 M 0.440 0.365 0.125 0.5160 0.2155 0.1140 0.155 10 4 I 0.330 0.255 0.080 0.2050 0.0895 0.0395 0.055 7 # Initlaize ATOM for regression tasks and encode the categorical features atom = ATOMRegressor(X, y=\"Rings\", verbose=2, random_state=42) atom.encode() <<=============== ATOM ===============>> Initial data cleaning... Algorithm task: regression. Dataset stats ===================> Shape: (4177, 9) Categorical columns: 1 Scaled: False ---------------------------------- Size of training set: 2923 Size of test set: 1254 Encoding categorical features... # Plot the dataset's correlation matrix atom.plot_correlation() # Apply PCA for dimensionality reduction atom.feature_selection(strategy=\"pca\", n_features=6) atom.plot_PCA() atom.plot_components(figsize=(8, 6), filename='atom_PCA_plot') Performing feature selection... Run the pipeline atom.pipeline(['tree', 'bag', 'et'], metric='neg_mean_squared_error', max_iter=5, init_points=2, cv=1, bagging=5) Running pipeline =================> Models in pipeline: Tree, Bag, ET Metric: neg_mean_squared_error Running BO for Decision Tree... Final results for Decision Tree: Bayesian Optimization --------------------------- Best hyperparameters: {'criterion': 'mse', 'splitter': 'random', 'max_depth': 10, 'max_features': 0.5, 'min_samples_split': 2, 'min_samples_leaf': 20, 'ccp_alpha': 0.0} Best score on the BO: -6.6417 Time elapsed: 0.894s Fitting ----------------------------------------- Score on the training set: -10.0595 Score on the test set: -8.7809 Time elapsed: 0.024s Bagging ----------------------------------------- Mean: -7.5249 Std: 1.2204 Time elapsed: 0.013s ------------------------------------------------- Total time: 0.932s Running BO for Bagging Regressor... Final results for Bagging Regressor: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 93, 'max_samples': 0.5, 'max_features': 1.0, 'bootstrap': False, 'bootstrap_features': True} Best score on the BO: -5.2595 Time elapsed: 7.585s Fitting ----------------------------------------- Score on the training set: -1.4264 Score on the test set: -4.9367 Time elapsed: 0.971s Bagging ----------------------------------------- Mean: -5.0745 Std: 0.0345 Time elapsed: 3.621s ------------------------------------------------- Total time: 12.178s Running BO for Extra-Trees... Final results for Extra-Trees: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 159, 'max_depth': 10, 'max_features': 0.9, 'criterion': 'mae', 'min_samples_split': 10, 'min_samples_leaf': 15, 'ccp_alpha': 0.01, 'bootstrap': True, 'max_samples': 0.8} Best score on the BO: -6.2369 Time elapsed: 11.282s Fitting ----------------------------------------- Score on the training set: -7.2610 Score on the test set: -6.4164 Time elapsed: 3.024s Bagging ----------------------------------------- Mean: -6.2672 Std: 0.0772 Time elapsed: 15.529s ------------------------------------------------- Total time: 29.835s Final results ================>> Duration: 42.945s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -7.525 \u00b1 1.220 ~ Bagging Regressor --> -5.075 \u00b1 0.035 !! ~ Extra-Trees --> -6.267 \u00b1 0.077 ~ Successive halving Import the boston dataset from sklearn.datasets . This is a small and easy to train dataset which goal is to predict house prices. Load the data # Import packages import numpy as np import pandas as pd from sklearn.datasets import load_boston from atom import ATOMRegressor # Load the dataset's features and targets dataset = load_boston() # Convert to pd.DataFrame to get the names of the features data = np.c_[dataset.data, dataset.target] columns = np.append(dataset.feature_names, [\"target\"]) data = pd.DataFrame(data, columns=columns) X = data.drop('target', axis=1) y = data['target'] # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 # Initialize ATOM atom = ATOMRegressor(X, y, verbose=1, random_state=42) # Select best features with the RFECV strategy atom.feature_selection('RFECV', solver='OLS', scoring='r2') atom.plot_RFECV() <<=============== ATOM ===============>> Algorithm task: regression. Run the pipeline # We can compare tree-based models via successive halving atom.successive_halving(['tree', 'bag', 'et', 'rf', 'lgb', 'catb'], metric='neg_mean_squared_error', max_iter=5, init_points=2, cv=1, bagging=5) Running pipeline =================> Metric: neg_mean_squared_error <<=============== Iteration 0 ==============>> Models in pipeline: Tree, Bag, ET, RF, LGB, CatB Percentage of data: 16.7% Size of training set: 58 Size of test set: 26 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:12<00:00, 2.04s/it] Final results ================>> Duration: 12.251s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -49.394 \u00b1 27.206 ~ Bagging Regressor --> -38.655 \u00b1 3.232 ~ Extra-Trees --> -49.144 \u00b1 13.045 ~ Random Forest --> -100.813 \u00b1 101.754 ~ LightGBM --> -31.724 \u00b1 8.447 !! ~ <<=============== Iteration 1 ==============>> Models in pipeline: Bag, LGB Percentage of data: 50.0% Size of training set: 177 Size of test set: 76 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:05<00:00, 2.58s/it] Final results ================>> Duration: 17.454s Metric: neg_mean_squared_error -------------------------------- Bagging Regressor --> -27.847 \u00b1 4.189 !! ~ LightGBM --> -32.049 \u00b1 6.159 ~ <<=============== Iteration 2 ==============>> Model in pipeline: Bag Percentage of data: 100.0% Size of training set: 354 Size of test set: 152 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:05<00:00, 5.73s/it] Final results ================>> Duration: 23.209s Metric: neg_mean_squared_error -------------------------------- Bagging Regressor --> -16.360 \u00b1 3.548 ~ atom.plot_successive_halving() Train sizing Download the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . This dataset tries to predict whether or not it will rain tomorrow by training a classification model on target RainTomorrow . Load the data # Import packages import numpy as np import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('../weatherAUS.csv') X = X.drop(['RISK_MM', 'Date'], axis=1) # Drop unrelated features # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm ... Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow 0 Albury 13.4 22.9 0.6 NaN NaN W 44.0 W WNW ... 71.0 22.0 1007.7 1007.1 8.0 NaN 16.9 21.8 No No 1 Albury 7.4 25.1 0.0 NaN NaN WNW 44.0 NNW WSW ... 44.0 25.0 1010.6 1007.8 NaN NaN 17.2 24.3 No No 2 Albury 12.9 25.7 0.0 NaN NaN WSW 46.0 W WSW ... 38.0 30.0 1007.6 1008.7 NaN 2.0 21.0 23.2 No No 3 Albury 9.2 28.0 0.0 NaN NaN NE 24.0 SE E ... 45.0 16.0 1017.6 1012.8 NaN NaN 18.1 26.5 No No 4 Albury 17.5 32.3 1.0 NaN NaN W 41.0 ENE NW ... 82.0 33.0 1010.8 1006.0 7.0 8.0 17.8 29.7 No No 5 rows \u00d7 22 columns Run the pipeline # Initialize ATOM atom = ATOMClassifier(X, verbose=1, random_state=42) atom.impute(strat_num='median', strat_cat='most_frequent', min_frac_rows=0.8) atom.encode() # We can compare tree-based models via successive halving atom.train_sizing('lgb', metric='accuracy', max_iter=5, init_points=2, cv=3) <<=============== ATOM ===============>> Algorithm task: binary classification. Running pipeline =================> Model in pipeline: LGB Metric: accuracy <<=============== Iteration 0 ==============>> Percentage of data: 10.0% Size of training set: 8890 Size of test set: 3811 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:08<00:00, 8.79s/it] Final results ================>> Duration: 8.837s Metric: accuracy -------------------------------- LightGBM --> 0.845 <<=============== Iteration 1 ==============>> Percentage of data: 20.0% Size of training set: 17781 Size of test set: 7621 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:09<00:00, 9.97s/it] Final results ================>> Duration: 18.863s Metric: accuracy -------------------------------- LightGBM --> 0.837 <<=============== Iteration 2 ==============>> Percentage of data: 30.0% Size of training set: 26672 Size of test set: 11431 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:17<00:00, 17.26s/it] Final results ================>> Duration: 36.187s Metric: accuracy -------------------------------- LightGBM --> 0.852 <<=============== Iteration 3 ==============>> Percentage of data: 40.0% Size of training set: 35562 Size of test set: 15242 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:29<00:00, 29.42s/it] Final results ================>> Duration: 1m:05s Metric: accuracy -------------------------------- LightGBM --> 0.862 <<=============== Iteration 4 ==============>> Percentage of data: 50.0% Size of training set: 44454 Size of test set: 19052 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:24<00:00, 24.44s/it] Final results ================>> Duration: 1m:30s Metric: accuracy -------------------------------- LightGBM --> 0.857 <<=============== Iteration 5 ==============>> Percentage of data: 60.0% Size of training set: 53344 Size of test set: 22863 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:30<00:00, 30.59s/it] Final results ================>> Duration: 2m:01s Metric: accuracy -------------------------------- LightGBM --> 0.859 Processing: 0%| | 0/1 [00:00<?, ?it/s] <<=============== Iteration 6 ==============>> Percentage of data: 70.0% Size of training set: 62235 Size of test set: 26673 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:47<00:00, 47.88s/it] Final results ================>> Duration: 2m:50s Metric: accuracy -------------------------------- LightGBM --> 0.862 <<=============== Iteration 7 ==============>> Percentage of data: 80.0% Size of training set: 71126 Size of test set: 30483 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:58<00:00, 58.07s/it] Final results ================>> Duration: 3m:48s Metric: accuracy -------------------------------- LightGBM --> 0.854 <<=============== Iteration 8 ==============>> Percentage of data: 90.0% Size of training set: 80017 Size of test set: 34293 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:57<00:00, 57.22s/it] Final results ================>> Duration: 4m:46s Metric: accuracy -------------------------------- LightGBM --> 0.860 <<=============== Iteration 9 ==============>> Percentage of data: 100.0% Size of training set: 88907 Size of test set: 38104 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [01:15<00:00, 75.39s/it] Final results ================>> Duration: 6m:02s Metric: accuracy -------------------------------- LightGBM --> 0.855 atom.plot_learning_curve()","title":"Examples"},{"location":"examples/#binary-classification","text":"Download the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . This dataset tries to predict whether or not it will rain tomorrow by training a classification model on target RainTomorrow . Load the data # Import packages import numpy as np import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('../weatherAUS.csv') X = X.drop(['RISK_MM', 'Date'], axis=1) # Drop unrelated features # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm WindSpeed9am WindSpeed3pm Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow 0 Albury 13.4 22.9 0.6 NaN NaN W 44.0 W WNW 20.0 24.0 71.0 22.0 1007.7 1007.1 8.0 NaN 16.9 21.8 No No 1 Albury 7.4 25.1 0.0 NaN NaN WNW 44.0 NNW WSW 4.0 22.0 44.0 25.0 1010.6 1007.8 NaN NaN 17.2 24.3 No No 2 Albury 12.9 25.7 0.0 NaN NaN WSW 46.0 W WSW 19.0 26.0 38.0 30.0 1007.6 1008.7 NaN 2.0 21.0 23.2 No No 3 Albury 9.2 28.0 0.0 NaN NaN NE 24.0 SE E 11.0 9.0 45.0 16.0 1017.6 1012.8 NaN NaN 18.1 26.5 No No 4 Albury 17.5 32.3 1.0 NaN NaN W 41.0 ENE NW 7.0 20.0 82.0 33.0 1010.8 1006.0 7.0 8.0 17.8 29.7 No No Run the pipeline # Call ATOM using only a percentage of the complete dataset (for explanatory purposes) atom = ATOMClassifier(X, y=\"RainTomorrow\", percentage=5, log='auto', n_jobs=2, verbose=3) <<=============== ATOM ===============>> Parallel processing with 2 cores. Initial data cleaning... Algorithm task: binary classification. Dataset stats ===================> Shape: (7110, 22) Missing values: 15836 Categorical columns: 5 Scaled: False ---------------------------------- Size of training set: 4977 Size of test set: 2133 ---------------------------------- Class balance: No:Yes <==> 3.6:1.0 Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 5562 | 3896 | 1666 | | 1: Yes | 1548 | 1081 | 467 | # If we change a column during the pre-processing, # we need to call the update method to update all data attributes atom.X['MaxTemp'] = np.log(atom.X['MaxTemp']) # Random operator on column MaxTemp # MaxTemp has now been changed for atom.X, but not in atom.X_train, atom.dataset, etc... # To do so, we use the update method, where the parameter is a string of the changed attribute atom.update('X') assert atom.X['MaxTemp'].equals(atom.dataset['MaxTemp']) # Impute missing values atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) Imputing missing values... --> Removing 736 rows for containing too many missing values. --> Imputing 10 missing values using the KNN imputer in feature MinTemp. --> Imputing 2 missing values using the KNN imputer in feature MaxTemp. --> Imputing 35 missing values using the KNN imputer in feature Rainfall. --> Imputing 2365 missing values using the KNN imputer in feature Evaporation. --> Imputing 2666 missing values using the KNN imputer in feature Sunshine. --> Removing 224 rows due to missing values in feature WindGustDir. --> Imputing 223 missing values using the KNN imputer in feature WindGustSpeed. --> Removing 327 rows due to missing values in feature WindDir9am. --> Removing 26 rows due to missing values in feature WindDir3pm. --> Imputing 4 missing values using the KNN imputer in feature WindSpeed9am. --> Imputing 5 missing values using the KNN imputer in feature WindSpeed3pm. --> Imputing 25 missing values using the KNN imputer in feature Humidity9am. --> Imputing 59 missing values using the KNN imputer in feature Humidity3pm. --> Imputing 55 missing values using the KNN imputer in feature Pressure9am. --> Imputing 52 missing values using the KNN imputer in feature Pressure3pm. --> Imputing 2127 missing values using the KNN imputer in feature Cloud9am. --> Imputing 2209 missing values using the KNN imputer in feature Cloud3pm. --> Imputing 5 missing values using the KNN imputer in feature Temp9am. --> Imputing 41 missing values using the KNN imputer in feature Temp3pm. --> Removing 35 rows due to missing values in feature RainToday. # Encode the categorical features atom.encode(max_onehot=10, frac_to_other=0.04) Encoding categorical features... --> Target-encoding feature Location. Contains 1 unique categories. --> Target-encoding feature WindGustDir. Contains 16 unique categories. --> Target-encoding feature WindDir9am. Contains 16 unique categories. --> Target-encoding feature WindDir3pm. Contains 16 unique categories. --> Label-encoding feature RainToday. Contains 2 unique categories. # Perform undersampling of the majority class to balance the dataset atom.balance(undersample=0.8) Performing undersampling... --> Removing 239 rows from class No. Using TensorFlow backend. # Remove outliers from the training set atom.outliers(max_sigma=5) Handling outliers... --> Dropping 22 rows due to outliers. # Select only the best 10 features atom.feature_selection(strategy=\"univariate\", max_features=15, max_correlation=0.8) # See which features were removed due to collinearity atom.collinear Performing feature selection... --> Feature Pressure3pm was removed due to collinearity with another feature. --> Feature Temp9am was removed due to collinearity with another feature. --> Feature Temp3pm was removed due to collinearity with another feature. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } drop_feature correlated_feature correlation_value 0 Pressure3pm Pressure9am 0.95258 1 Temp9am MinTemp, MaxTemp 0.93135, 0.89859 2 Temp3pm MaxTemp, Temp9am 0.95784, 0.88146 # Change the verbosity of ATOM to not print too much details while fitting atom.verbose = 2 # Define a custom metric def f2_score(y_true, y_pred): return fbeta_score(y_true, y_pred, beta=2) # We can compare the performance of various gradient boosting algorithms atom.pipeline(['gbm', 'lgb', 'catb'], metric=f2_score, max_iter=5, init_points=5, cv=1, bagging=5) Running pipeline =================> Models in pipeline: GBM, LGB, CatB Metric: f2_score Running BO for Gradient Boosting Machine... Final results for Gradient Boosting Machine: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 249, 'learning_rate': 1.0, 'subsample': 0.7, 'max_depth': 2, 'max_features': 0.6, 'criterion': 'friedman_mse', 'min_samples_split': 20, 'min_samples_leaf': 11, 'ccp_alpha': 0.02} Best score on the BO: 0.7684 Time elapsed: 6.856s Fitting ----------------------------------------- Score on the training set: 0.7305 Score on the test set: 0.6330 Time elapsed: 0.491s Bagging ----------------------------------------- Mean: 0.6086 Std: 0.0269 Time elapsed: 2.117s ------------------------------------------------- Total time: 9.469s Running BO for LightGBM... Final results for LightGBM: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 361, 'learning_rate': 0.8, 'max_depth': 1, 'num_leaves': 37, 'min_child_weight': 11, 'min_child_samples': 14, 'subsample': 1.0, 'colsample_bytree': 0.5, 'reg_alpha': 0.1, 'reg_lambda': 100.0} Best score on the BO: 0.7471 Time elapsed: 3.781s Fitting ----------------------------------------- Score on the training set: 0.7702 Score on the test set: 0.6831 Time elapsed: 0.139s Bagging ----------------------------------------- Mean: 0.6671 Std: 0.0173 Time elapsed: 0.258s ------------------------------------------------- Total time: 4.181s Running BO for CatBoost... Final results for CatBoost: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 461, 'learning_rate': 0.38, 'max_depth': 3, 'subsample': 0.6, 'colsample_bylevel': 1.0, 'reg_lambda': 30.0} Best score on the BO: 0.7465 Time elapsed: 24.624s Fitting ----------------------------------------- Score on the training set: 0.9644 Score on the test set: 0.6531 Time elapsed: 0.596s Bagging ----------------------------------------- Mean: 0.6606 Std: 0.0074 Time elapsed: 2.815s ------------------------------------------------- Total time: 28.040s Final results ================>> Duration: 41.841s Metric: f2_score -------------------------------- Gradient Boosting Machine --> 0.609 \u00b1 0.027 LightGBM --> 0.667 \u00b1 0.017 !! CatBoost --> 0.661 \u00b1 0.007 ~ Analyze the results # Let's have a look at the best model print('And the winner is...', atom.winner.longname) # The ~ symbol indicates that the model is probably overfitting the training set # This happens because we only use 5% of the dataset # We can see that the training score is >20% of the test score print('Score on the training set: ', atom.winner.score_train) print('Score on the test set: ', atom.winner.score_test) And the winner is... LightGBM Score on the training set: 0.7702407002188184 Score on the test set: 0.6830769230769231 # Check the winner's confusion matrix and probability distribution atom.winner.plot_confusion_matrix(normalize=True, figsize=(7, 7), filename='confusion_matrix.png') atom.winner.plot_probabilities() # How do other metrics perform for different thresholds on the winning model atom.winner.plot_threshold(metric=['f1', 'accuracy', 'average_precision'], steps=50, filename='thresholds.png') # Change plots aesthetics ATOMClassifier.set_style('whitegrid') ATOMClassifier.set_title_fontsize(24) # Make some plots to compare the models atom.plot_ROC(title=\"ROC for the LightGBM vs CatBoost model\") atom.plot_PRC(title=\"PRC comparison of the models\")","title":"Binary classification"},{"location":"examples/#multiclass-classification","text":"Import the wine dataset from sklearn.datasets . This is a small and easy to train dataset which goal is to classify wines into three groups (which cultivator it's from) using features based on the results of chemical analysis. Load the data # Import packages import numpy as np import pandas as pd from sklearn.datasets import load_wine from atom import ATOMClassifier # Load the dataset's features and targets dataset = load_wine() # Convert to pd.DataFrame to get the names of the features data = np.c_[dataset.data, dataset.target] columns = np.append(dataset.feature_names, [\"target\"]) data = pd.DataFrame(data, columns=columns) X = data.drop('target', axis=1) y = data['target'] # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } alcohol malic_acid ash alcalinity_of_ash magnesium total_phenols flavanoids nonflavanoid_phenols proanthocyanins color_intensity hue od280/od315_of_diluted_wines proline 0 14.23 1.71 2.43 15.6 127.0 2.80 3.06 0.28 2.29 5.64 1.04 3.92 1065.0 1 13.20 1.78 2.14 11.2 100.0 2.65 2.76 0.26 1.28 4.38 1.05 3.40 1050.0 2 13.16 2.36 2.67 18.6 101.0 2.80 3.24 0.30 2.81 5.68 1.03 3.17 1185.0 3 14.37 1.95 2.50 16.8 113.0 3.85 3.49 0.24 2.18 7.80 0.86 3.45 1480.0 4 13.24 2.59 2.87 21.0 118.0 2.80 2.69 0.39 1.82 4.32 1.04 2.93 735.0 Run the pipeline # Call ATOMclass for ML task exploration atom = ATOMClassifier(X, y, n_jobs=-1, verbose=3) # Fit the pipeline with the selected models atom.pipeline(models=['LDA','RF', 'lSVM'], metric='f1_macro', max_iter=4, init_points=3, cv=3, bagging=10) <<=============== ATOM ===============>> Parallel processing with 4 cores. Initial data cleaning... Algorithm task: multiclass classification. Number of classes: 3. Dataset stats ===================> Shape: (178, 14) Scaled: False ---------------------------------- Size of training set: 124 Size of test set: 54 ---------------------------------- Class balance: 0:1:2 <==> 1.2:1.5:1.0 Instances in target per class: | | total | train_set | test_set | |---:|---------:|-------------:|------------:| | 0 | 59 | 40 | 19 | | 1 | 71 | 53 | 18 | | 2 | 48 | 31 | 17 | Running pipeline =================> Models in pipeline: LDA, RF, lSVM Metric: f1_macro Running BO for Linear Discriminant Analysis... Initial point: 1 -------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.774s Total time: 0.774s Initial point: 2 -------------------------------- Parameters --> {'solver': 'eigen', 'shrinkage': 0.3} Evaluation --> f1_macro: 0.6488 Time elapsed: 0.477s Total time: 1.251s Initial point: 3 -------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.019s Total time: 1.270s Iteration: 1 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.019s Total time: 1.485s Iteration: 2 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9754 Time elapsed: 0.024s Total time: 1.690s Iteration: 3 ------------------------------------ Parameters --> {'solver': 'eigen', 'shrinkage': 0.7} Evaluation --> f1_macro: 0.6951 Time elapsed: 0.020s Total time: 1.895s Iteration: 4 ------------------------------------ Parameters --> {'solver': 'lsqr', 'shrinkage': 1.0} Evaluation --> f1_macro: 0.7274 Time elapsed: 0.024s Total time: 2.107s Final results for Linear Discriminant Analysis: Bayesian Optimization --------------------------- Best hyperparameters: {'solver': 'svd'} Best score on the BO: 0.9754 Time elapsed: 2.240s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 1.0000 Time elapsed: 0.043s Bagging ----------------------------------------- Mean: 1.0000 Std: 0.0000 Time elapsed: 0.039s ------------------------------------------------- Total time: 2.324s Running BO for Random Forest... Initial point: 1 -------------------------------- Parameters --> {'n_estimators': 361, 'max_depth': 7, 'max_features': 0.7, 'criterion': 'gini', 'min_samples_split': 6, 'min_samples_leaf': 2, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.7} Evaluation --> f1_macro: 0.9377 Time elapsed: 0.497s Total time: 0.498s Initial point: 2 -------------------------------- Parameters --> {'n_estimators': 39, 'max_depth': 7, 'max_features': 0.6, 'criterion': 'gini', 'min_samples_split': 17, 'min_samples_leaf': 1, 'ccp_alpha': 0.035, 'bootstrap': True, 'max_samples': 0.8} Evaluation --> f1_macro: 0.9454 Time elapsed: 0.271s Total time: 0.769s Initial point: 3 -------------------------------- Parameters --> {'n_estimators': 62, 'max_depth': 9, 'max_features': 0.9, 'criterion': 'entropy', 'min_samples_split': 19, 'min_samples_leaf': 4, 'ccp_alpha': 0.005, 'bootstrap': False} Evaluation --> f1_macro: 0.8743 Time elapsed: 0.274s Total time: 1.044s Iteration: 1 ------------------------------------ Parameters --> {'n_estimators': 40, 'max_depth': 7, 'max_features': 0.6, 'criterion': 'gini', 'min_samples_split': 17, 'min_samples_leaf': 1, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.8} Evaluation --> f1_macro: 0.9229 Time elapsed: 0.243s Total time: 1.556s Iteration: 2 ------------------------------------ Parameters --> {'n_estimators': 500, 'max_depth': 3, 'max_features': 0.5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 1, 'ccp_alpha': 0.035, 'bootstrap': True, 'max_samples': 0.9} Evaluation --> f1_macro: 0.9377 Time elapsed: 0.624s Total time: 2.408s Iteration: 3 ------------------------------------ Parameters --> {'n_estimators': 500, 'max_depth': 3, 'max_features': 0.6, 'criterion': 'entropy', 'min_samples_split': 18, 'min_samples_leaf': 4, 'ccp_alpha': 0.02, 'bootstrap': False} Evaluation --> f1_macro: 0.9141 Time elapsed: 0.754s Total time: 3.437s Iteration: 4 ------------------------------------ Parameters --> {'n_estimators': 499, 'max_depth': 5, 'max_features': 0.5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 7, 'ccp_alpha': 0.015, 'bootstrap': True, 'max_samples': 0.5} Evaluation --> f1_macro: 0.9460 Time elapsed: 0.632s Total time: 4.321s Final results for Random Forest: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 499, 'max_depth': 5, 'max_features': 0.5, 'criterion': 'gini', 'min_samples_split': 2, 'min_samples_leaf': 7, 'ccp_alpha': 0.015, 'bootstrap': True, 'max_samples': 0.5} Best score on the BO: 0.9460 Time elapsed: 4.527s Fitting ----------------------------------------- Score on the training set: 0.9758 Score on the test set: 1.0000 Time elapsed: 1.150s Bagging ----------------------------------------- Mean: 0.9817 Std: 0.0184 Time elapsed: 6.119s ------------------------------------------------- Total time: 11.797s Running BO for Linear SVM... Initial point: 1 -------------------------------- Parameters --> {'C': 0.1, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9680 Time elapsed: 0.023s Total time: 0.024s Initial point: 2 -------------------------------- Parameters --> {'C': 0.1, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9913 Time elapsed: 0.020s Total time: 0.045s Initial point: 3 -------------------------------- Parameters --> {'C': 0.001, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9215 Time elapsed: 0.019s Total time: 0.065s Iteration: 1 ------------------------------------ Parameters --> {'C': 100, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9503 Time elapsed: 0.025s Total time: 0.282s Iteration: 2 ------------------------------------ Parameters --> {'C': 0.001, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.1626 Time elapsed: 0.024s Total time: 0.563s Iteration: 3 ------------------------------------ Parameters --> {'C': 100, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9503 Time elapsed: 0.021s Total time: 0.806s Iteration: 4 ------------------------------------ Parameters --> {'C': 100, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9503 Time elapsed: 0.021s Total time: 1.056s Final results for Linear SVM: Bayesian Optimization --------------------------- Best hyperparameters: {'C': 0.1, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Best score on the BO: 0.9913 Time elapsed: 1.247s Fitting ----------------------------------------- Score on the training set: 0.9842 Score on the test set: 1.0000 Time elapsed: 0.032s Bagging ----------------------------------------- Mean: 1.0000 Std: 0.0000 Time elapsed: 0.030s ------------------------------------------------- Total time: 1.309s Final results ================>> Duration: 15.434s Metric: f1_macro -------------------------------- Linear Discriminant Analysis --> 1.000 \u00b1 0.000 !! Random Forest --> 0.982 \u00b1 0.018 Linear SVM --> 1.000 \u00b1 0.000 !! Analyze the results atom.scores .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } model total_time score_train score_test fit_time bagging_mean bagging_std bagging_time 0 LDA 2.324s 1.000000 1.0 0.043s 1.000000 0.000000 0.039s 1 RF 11.797s 0.975759 1.0 1.150s 0.981706 0.018371 6.119s 2 lSVM 1.309s 0.984184 1.0 0.032s 1.000000 0.000000 0.030s # Show the results for a different metric atom.results('precision_macro') Final results ================>> Metric: precision_macro -------------------------------- Linear Discriminant Analysis --> 1.000 !! Random Forest --> 1.000 !! Linear SVM --> 1.000 !! atom.plot_bagging() Let's have a closer look at the Random Forest # Get the results on some other metrics print('Jaccard score:', atom.rf.jaccard_weighted) print('Recall score:', atom.rf.recall_macro) Jaccard score: 1.0 Recall score: 1.0 # Check the winner's confusion matrix atom.RF.plot_confusion_matrix() # Save the random forest class for production atom.RF.save('Random_Forest_class') Random Forest model subclass saved successfully!","title":"Multiclass classification"},{"location":"examples/#regression","text":"Download the abalone dataset from https://archive.ics.uci.edu/ml/datasets/Abalone . The goal of this dataset is to predict the age of abalone shells from physical measurements. Load the data # Import packages import pandas as pd from atom import ATOMRegressor # Load the abalone dataset X = pd.read_csv('../abalone.csv') # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex Length Diameter Height Whole weight Shucked weight Viscera weight Shell weight Rings 0 M 0.455 0.365 0.095 0.5140 0.2245 0.1010 0.150 15 1 M 0.350 0.265 0.090 0.2255 0.0995 0.0485 0.070 7 2 F 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9 3 M 0.440 0.365 0.125 0.5160 0.2155 0.1140 0.155 10 4 I 0.330 0.255 0.080 0.2050 0.0895 0.0395 0.055 7 # Initlaize ATOM for regression tasks and encode the categorical features atom = ATOMRegressor(X, y=\"Rings\", verbose=2, random_state=42) atom.encode() <<=============== ATOM ===============>> Initial data cleaning... Algorithm task: regression. Dataset stats ===================> Shape: (4177, 9) Categorical columns: 1 Scaled: False ---------------------------------- Size of training set: 2923 Size of test set: 1254 Encoding categorical features... # Plot the dataset's correlation matrix atom.plot_correlation() # Apply PCA for dimensionality reduction atom.feature_selection(strategy=\"pca\", n_features=6) atom.plot_PCA() atom.plot_components(figsize=(8, 6), filename='atom_PCA_plot') Performing feature selection... Run the pipeline atom.pipeline(['tree', 'bag', 'et'], metric='neg_mean_squared_error', max_iter=5, init_points=2, cv=1, bagging=5) Running pipeline =================> Models in pipeline: Tree, Bag, ET Metric: neg_mean_squared_error Running BO for Decision Tree... Final results for Decision Tree: Bayesian Optimization --------------------------- Best hyperparameters: {'criterion': 'mse', 'splitter': 'random', 'max_depth': 10, 'max_features': 0.5, 'min_samples_split': 2, 'min_samples_leaf': 20, 'ccp_alpha': 0.0} Best score on the BO: -6.6417 Time elapsed: 0.894s Fitting ----------------------------------------- Score on the training set: -10.0595 Score on the test set: -8.7809 Time elapsed: 0.024s Bagging ----------------------------------------- Mean: -7.5249 Std: 1.2204 Time elapsed: 0.013s ------------------------------------------------- Total time: 0.932s Running BO for Bagging Regressor... Final results for Bagging Regressor: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 93, 'max_samples': 0.5, 'max_features': 1.0, 'bootstrap': False, 'bootstrap_features': True} Best score on the BO: -5.2595 Time elapsed: 7.585s Fitting ----------------------------------------- Score on the training set: -1.4264 Score on the test set: -4.9367 Time elapsed: 0.971s Bagging ----------------------------------------- Mean: -5.0745 Std: 0.0345 Time elapsed: 3.621s ------------------------------------------------- Total time: 12.178s Running BO for Extra-Trees... Final results for Extra-Trees: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 159, 'max_depth': 10, 'max_features': 0.9, 'criterion': 'mae', 'min_samples_split': 10, 'min_samples_leaf': 15, 'ccp_alpha': 0.01, 'bootstrap': True, 'max_samples': 0.8} Best score on the BO: -6.2369 Time elapsed: 11.282s Fitting ----------------------------------------- Score on the training set: -7.2610 Score on the test set: -6.4164 Time elapsed: 3.024s Bagging ----------------------------------------- Mean: -6.2672 Std: 0.0772 Time elapsed: 15.529s ------------------------------------------------- Total time: 29.835s Final results ================>> Duration: 42.945s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -7.525 \u00b1 1.220 ~ Bagging Regressor --> -5.075 \u00b1 0.035 !! ~ Extra-Trees --> -6.267 \u00b1 0.077 ~","title":"Regression"},{"location":"examples/#successive-halving","text":"Import the boston dataset from sklearn.datasets . This is a small and easy to train dataset which goal is to predict house prices. Load the data # Import packages import numpy as np import pandas as pd from sklearn.datasets import load_boston from atom import ATOMRegressor # Load the dataset's features and targets dataset = load_boston() # Convert to pd.DataFrame to get the names of the features data = np.c_[dataset.data, dataset.target] columns = np.append(dataset.feature_names, [\"target\"]) data = pd.DataFrame(data, columns=columns) X = data.drop('target', axis=1) y = data['target'] # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 # Initialize ATOM atom = ATOMRegressor(X, y, verbose=1, random_state=42) # Select best features with the RFECV strategy atom.feature_selection('RFECV', solver='OLS', scoring='r2') atom.plot_RFECV() <<=============== ATOM ===============>> Algorithm task: regression. Run the pipeline # We can compare tree-based models via successive halving atom.successive_halving(['tree', 'bag', 'et', 'rf', 'lgb', 'catb'], metric='neg_mean_squared_error', max_iter=5, init_points=2, cv=1, bagging=5) Running pipeline =================> Metric: neg_mean_squared_error <<=============== Iteration 0 ==============>> Models in pipeline: Tree, Bag, ET, RF, LGB, CatB Percentage of data: 16.7% Size of training set: 58 Size of test set: 26 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:12<00:00, 2.04s/it] Final results ================>> Duration: 12.251s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -49.394 \u00b1 27.206 ~ Bagging Regressor --> -38.655 \u00b1 3.232 ~ Extra-Trees --> -49.144 \u00b1 13.045 ~ Random Forest --> -100.813 \u00b1 101.754 ~ LightGBM --> -31.724 \u00b1 8.447 !! ~ <<=============== Iteration 1 ==============>> Models in pipeline: Bag, LGB Percentage of data: 50.0% Size of training set: 177 Size of test set: 76 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2/2 [00:05<00:00, 2.58s/it] Final results ================>> Duration: 17.454s Metric: neg_mean_squared_error -------------------------------- Bagging Regressor --> -27.847 \u00b1 4.189 !! ~ LightGBM --> -32.049 \u00b1 6.159 ~ <<=============== Iteration 2 ==============>> Model in pipeline: Bag Percentage of data: 100.0% Size of training set: 354 Size of test set: 152 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:05<00:00, 5.73s/it] Final results ================>> Duration: 23.209s Metric: neg_mean_squared_error -------------------------------- Bagging Regressor --> -16.360 \u00b1 3.548 ~ atom.plot_successive_halving()","title":"Successive halving"},{"location":"examples/#train-sizing","text":"Download the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . This dataset tries to predict whether or not it will rain tomorrow by training a classification model on target RainTomorrow . Load the data # Import packages import numpy as np import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('../weatherAUS.csv') X = X.drop(['RISK_MM', 'Date'], axis=1) # Drop unrelated features # Let's have a look at the dataset X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed WindDir9am WindDir3pm ... Humidity9am Humidity3pm Pressure9am Pressure3pm Cloud9am Cloud3pm Temp9am Temp3pm RainToday RainTomorrow 0 Albury 13.4 22.9 0.6 NaN NaN W 44.0 W WNW ... 71.0 22.0 1007.7 1007.1 8.0 NaN 16.9 21.8 No No 1 Albury 7.4 25.1 0.0 NaN NaN WNW 44.0 NNW WSW ... 44.0 25.0 1010.6 1007.8 NaN NaN 17.2 24.3 No No 2 Albury 12.9 25.7 0.0 NaN NaN WSW 46.0 W WSW ... 38.0 30.0 1007.6 1008.7 NaN 2.0 21.0 23.2 No No 3 Albury 9.2 28.0 0.0 NaN NaN NE 24.0 SE E ... 45.0 16.0 1017.6 1012.8 NaN NaN 18.1 26.5 No No 4 Albury 17.5 32.3 1.0 NaN NaN W 41.0 ENE NW ... 82.0 33.0 1010.8 1006.0 7.0 8.0 17.8 29.7 No No 5 rows \u00d7 22 columns Run the pipeline # Initialize ATOM atom = ATOMClassifier(X, verbose=1, random_state=42) atom.impute(strat_num='median', strat_cat='most_frequent', min_frac_rows=0.8) atom.encode() # We can compare tree-based models via successive halving atom.train_sizing('lgb', metric='accuracy', max_iter=5, init_points=2, cv=3) <<=============== ATOM ===============>> Algorithm task: binary classification. Running pipeline =================> Model in pipeline: LGB Metric: accuracy <<=============== Iteration 0 ==============>> Percentage of data: 10.0% Size of training set: 8890 Size of test set: 3811 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:08<00:00, 8.79s/it] Final results ================>> Duration: 8.837s Metric: accuracy -------------------------------- LightGBM --> 0.845 <<=============== Iteration 1 ==============>> Percentage of data: 20.0% Size of training set: 17781 Size of test set: 7621 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:09<00:00, 9.97s/it] Final results ================>> Duration: 18.863s Metric: accuracy -------------------------------- LightGBM --> 0.837 <<=============== Iteration 2 ==============>> Percentage of data: 30.0% Size of training set: 26672 Size of test set: 11431 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:17<00:00, 17.26s/it] Final results ================>> Duration: 36.187s Metric: accuracy -------------------------------- LightGBM --> 0.852 <<=============== Iteration 3 ==============>> Percentage of data: 40.0% Size of training set: 35562 Size of test set: 15242 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:29<00:00, 29.42s/it] Final results ================>> Duration: 1m:05s Metric: accuracy -------------------------------- LightGBM --> 0.862 <<=============== Iteration 4 ==============>> Percentage of data: 50.0% Size of training set: 44454 Size of test set: 19052 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:24<00:00, 24.44s/it] Final results ================>> Duration: 1m:30s Metric: accuracy -------------------------------- LightGBM --> 0.857 <<=============== Iteration 5 ==============>> Percentage of data: 60.0% Size of training set: 53344 Size of test set: 22863 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:30<00:00, 30.59s/it] Final results ================>> Duration: 2m:01s Metric: accuracy -------------------------------- LightGBM --> 0.859 Processing: 0%| | 0/1 [00:00<?, ?it/s] <<=============== Iteration 6 ==============>> Percentage of data: 70.0% Size of training set: 62235 Size of test set: 26673 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:47<00:00, 47.88s/it] Final results ================>> Duration: 2m:50s Metric: accuracy -------------------------------- LightGBM --> 0.862 <<=============== Iteration 7 ==============>> Percentage of data: 80.0% Size of training set: 71126 Size of test set: 30483 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:58<00:00, 58.07s/it] Final results ================>> Duration: 3m:48s Metric: accuracy -------------------------------- LightGBM --> 0.854 <<=============== Iteration 8 ==============>> Percentage of data: 90.0% Size of training set: 80017 Size of test set: 34293 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:57<00:00, 57.22s/it] Final results ================>> Duration: 4m:46s Metric: accuracy -------------------------------- LightGBM --> 0.860 <<=============== Iteration 9 ==============>> Percentage of data: 100.0% Size of training set: 88907 Size of test set: 38104 Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [01:15<00:00, 75.39s/it] Final results ================>> Duration: 6m:02s Metric: accuracy -------------------------------- LightGBM --> 0.855 atom.plot_learning_curve()","title":"Train sizing"},{"location":"getting_started/","text":"Installation Intall ATOM easily using pip . pip install atom-ml Note Since atom was already taken, the name of the package in pypi is atom-ml ! Usage Call the ATOMClassifier or ATOMRegressor class and provide the data you want to use: from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y) atom = ATOMClassifier(X, y, log='auto', n_jobs=2, verbose=2) ATOM has multiple data cleaning methods to help you prepare the data for modelling: atom.impute(strat_num='knn', strat_cat='most_frequent', max_frac_rows=0.1) atom.encode(max_onehot=10, frac_to_other=0.05) atom.outliers(max_sigma=4) atom.balance(oversample=0.8, n_neighbors=15) atom.feature_selection(strategy='univariate', solver='chi2', max_features=0.9) Run the pipeline with different models: atom.pipeline(models=['LR', 'LDA', 'XGB', 'lSVM'], metric='f1', max_iter=10, max_time=1000, init_points=3, cv=4, bagging=10) Make plots and analyze results: atom.plot_bagging(filename='bagging_results.png') atom.lSVM.plot_probabilities(figsize=(9, 6)) atom.lda.plot_confusion_matrix(normalize=True)","title":"Getting started"},{"location":"getting_started/#installation","text":"Intall ATOM easily using pip . pip install atom-ml Note Since atom was already taken, the name of the package in pypi is atom-ml !","title":"Installation"},{"location":"getting_started/#usage","text":"Call the ATOMClassifier or ATOMRegressor class and provide the data you want to use: from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y) atom = ATOMClassifier(X, y, log='auto', n_jobs=2, verbose=2) ATOM has multiple data cleaning methods to help you prepare the data for modelling: atom.impute(strat_num='knn', strat_cat='most_frequent', max_frac_rows=0.1) atom.encode(max_onehot=10, frac_to_other=0.05) atom.outliers(max_sigma=4) atom.balance(oversample=0.8, n_neighbors=15) atom.feature_selection(strategy='univariate', solver='chi2', max_features=0.9) Run the pipeline with different models: atom.pipeline(models=['LR', 'LDA', 'XGB', 'lSVM'], metric='f1', max_iter=10, max_time=1000, init_points=3, cv=4, bagging=10) Make plots and analyze results: atom.plot_bagging(filename='bagging_results.png') atom.lSVM.plot_probabilities(figsize=(9, 6)) atom.lda.plot_confusion_matrix(normalize=True)","title":"Usage"},{"location":"license/","text":"MIT License Copyright (c) 2020 tvdboom Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#mit-license","text":"Copyright (c) 2020 tvdboom Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"}]}