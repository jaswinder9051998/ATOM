{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Automated Tool for Optimized Modelling (ATOM) is a python package designed for fast exploration and experimentation of supervised machine learning tasks. With just a few lines of code, you can perform basic data cleaning steps, feature selection and compare the performance of multiple models on a given dataset. ATOM should be able to provide quick insights on which algorithms perform best for the task at hand and provide an indication of the feasibility of the ML solution. This package supports binary classification, multiclass classification, and regression tasks. Note A data scientist with domain knowledge can outperform ATOM if he applies usecase-specific feature engineering or data cleaning steps! Possible steps taken by the ATOM pipeline: Data Cleaning Handle missing values Encode categorical features Balance the dataset Remove outliers Perform feature selection Remove features with too high collinearity Remove features with too low variance Select best features according to a chosen strategy Fit all selected models (either direct or via successive halving) Select hyperparameters using a Bayesian Optimization approach Perform bagging to assess the robustness of the model Analyze the results using the provided plotting functions!","title":"Home"},{"location":"api/","text":"ATOM class atom. ATOM (X, y=None, percentage=100, test_size=0.3, log=None, n_jobs=1, warnings=False, verbose=0, random_state=None, verbose=0) [source] Main class of the package. The ATOM class is a parent class of the ATOMClassifier and ATOMRegressor classes. These will inherit all methods and attributes described in this page. Note that contrary to scikit-learn's API, the ATOM object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. Warning Don't call the ATOM class directly! Use ATOMClassifier or ATOMRegressor depending on the task at hand. Click here for an example. The class initializer will label-encode the target column if its labels are not ordered integers. It will also apply some standard data cleaning steps unto the dataset. These steps include: Transforming the input data into a pd.DataFrame (if it wasn't one already) that can be accessed through the class' data attributes. Removing columns with prohibited data types ('datetime64', 'datetime64[ns]', 'timedelta[ns]'). Removing categorical columns with maximal cardinality (the number of unique values is equal to the number of instances. Usually the case for names, IDs, etc...). Removing columns with minimum cardinality (all values are the same). Removing rows with missing values in the target column. Parameters: X: dict, sequence, np.array or pd.DataFrame Dataset containing the features, with shape=(n_samples, n_features). y: string, sequence, np.array or pd.Series, optional (default=None) If None: the last column of X is selected as target column If string: name of the target column in X Else: data target column with shape=(n_samples,) percentage: int or float, optional (default=100) Percentage of the provided dataset to use. test_size: float, optional (default=0.3) Split fraction of the train and test set. log: string or None, optional (default=None) Name of the logging file. 'auto' for default name with date and time. None to not save any log. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If -1, use all available cores If < -1, use available_cores - 1 + n_jobs Beware that using multiple processes on the same machine may cause memory issues for large datasets. warnings: bool, optional (default=False) If False, it supresses all warnings. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything 1 to print minimum information 2 to print average information 3 to print maximum information random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by np.random. Data attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. Attributes: mapping: dict Dictionary of the target values mapped to their respective encoded integer. Only for classification tasks. errors: dict Dictionary of the encountered exceptions (if any) while fitting the models. winner: callable Model subclass that performed best on the test set. scores: pd.DataFrame Dataframe (or list of dataframes if successive_halving=True) of the results. Columns can include: model: model's name (acronym) total_time: time spent on this model score_train: metric score on the training set score_test: metric score on the test set fit_time: time spent fitting and predicting bagging_mean: mean score of the bagging's results bagging_std: standard deviation score of the bagging's results bagging_time: time spent on the bagging algorithm Utilities The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. stats Print out a list of basic statistics on the dataset. scale Scale all the features to mean=1 and std=0. update Update all data attributes. report Get an extensive profile analysis of the data. results Print final results for a specific metric. save Save the ATOM class to a pickle file. function atom.ATOM. stats () [source] Print out a list of basic statistics on the dataset. function atom.ATOM. scale () [source] Scale all the features to mean=1 and std=0. function atom.ATOM. update (df='dataset') [source] If you change any of the class' data attributes in between the pipeline, you should call this method to change all other data attributes to their correct values. Independent attributes are updated in unison, that is, setting df='X_train' will also update X_test, y_train and y_test, or df='train' will also update the test set, etc... This means that you can change both X_train and y_train and update them with one call of the method. Parameters: df: string, optional(default='dataset') Data attribute that has been changed. function atom.ATOM. report (df='dataset', rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for very large datasets. Dependency: pandas-profiling . Parameters: df: string, optional(default='dataset') Name of the data class attribute to get the profile from. rows: int or None, optional(default=None) Number of rows to process (randomly picked). None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. function atom.ATOM. results (metric=None) [source] Print the pipeline's final results for a specific metric. If a model shows a XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric needs it. Parameters: metric: string or None, optional (default=None) String of one of sklearn's predefined metrics. If None, the metric used to fit the pipeline is selected and the bagging results will be showed (if used). function atom.ATOM. save (filename=None) [source] Save the ATOM class to a pickle file. This method is also available for the model subclasses, e.g. atom.XGB.save(filename='ATOM_xgboost') . In this case, the model subclass is saved, instead of the ATOM class. Warning Remember that the class contains the complete dataset (and variations of it). This means the files can become very large for big datasets! Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. Data cleaning Before throwing your data in a model, it is crucial to apply some standard data cleaning steps. ATOM provides four data cleaning methods to handle missing values, categorical columns, outliers and unbalanced datasets. Calling on one of them will automatically apply the method on the dataset in the class and update the class' data attributes accordingly. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. impute Handle missing values in the dataset. encode Encode categorical columns. outliers Remove outliers from the training set. balance Balance the number of instances per target class. function atom.ATOM. impute (strat_num='remove', strat_cat='remove', max_frac_rows=0.5, max_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. Parameters: strat_num: str, int or float, optional (default='remove') Imputing strategy for numerical columns. Choose from: 'remove': remove row if any missing value 'mean': impute with mean of column 'median': impute with median of column 'knn': impute using a K-Nearest Neighbors approach 'most_frequent': impute with most frequent value int or float: impute with provided numerical value strat_cat: str, optional (default='remove') Imputing strategy for categorical columns. Choose from: 'remove': remove row if any missing value 'most_frequent': impute with most frequent value string: impute with provided string min_frac_rows: float, optional (default=0.5) Minimum fraction of non missing values in row. If less, the row is removed. min_frac_cols: float, optional (default=0.5) Minimum fraction of non missing values in column. If less, the column is removed. missing: int, float or list, optional (default=None) List of values to impute. None for default list: [None, np.NaN, np.inf, -np.inf, '', '?', 'NA', 'nan', 'inf']. function atom.ATOM. encode (max_onehot=10, frac_to_other=0) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: label-encoding for n_unique=2 one-hot-encoding for 2 < n_unique <= max_onehot target-encoding for n_unique > max_onehot It also replaces classes with low occurences with the value 'other' in order to prevent too high cardinality. Parameters: max_onehot: int or None, optional (default=10) Maximum number of unique values in a feature to perform one-hot-encoding. If None, it will never perform one-hot-encoding. frac_to_other: float, optional (default=0) Classes with less instances than n_rows * fraction_to_other are replaced with 'other'. function atom.ATOM. outliers (max_sigma=3, include_target=False) [source] Remove rows from the training set where at least one of the values lies further than max_sigma * standard_deviation away from the mean of the column. Parameters: max_sigma: int or float, optional (default=3) Maximum allowed standard deviations from the mean. include_target: bool, optional (default=False) Wether to include the target column when searching for outliers. function atom.ATOM. balance (oversample=None, undersample=None, n_neighbors=5) [source] Balance the number of instances per target class in the training set. If both oversampling and undersampling are used, they will be applied in that order. Only for classification tasks. Dependency: imbalanced-learn . Parameters: oversample: float, string or None, optional (default=None) Oversampling strategy using ADASYN . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'minority': resample only the minority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes undersample: float, string or None, optional (default=None) Undersampling strategy using NearMiss . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'majority': resample only the majority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes n_neighbors: int, optional (default=5) Number of nearest neighbors used for any of the algorithms. Feature selection To further pre-process the data you can create new non-linear features using a genetic algorithm or, if your dataset is too large, remove features using one of the provided strategies. feature_insertion Use a genetic algorithm to create new combinations of existing features. feature_selection Remove features according to the selected strategy. function atom.ATOM. feature_insertion (n_features=2, generations=20, population=500) [source] Use a genetic algorithm to create new combinations of existing features and add them to the original dataset in order to capture the non-linear relations between the original features. A dataframe containing the description of the newly generated features and their scores can be accessed through the genetic_features attribute. The algorithm is implemented using the Symbolic Transformer method, which can be accessed through the genetic_algorithm attribute. It is adviced to only use this method when fitting linear models. Dependency: gplearn . Parameters: n_features: int, optional (default=2) Maximum number of newly generated features (no more than 1% of the population). generations: int, optional (default=20) Number of generations to evolve. population: int, optional (default=500) Number of programs in each generation. function atom.ATOM. feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=0.98, **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. Note that the RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs. If the pipeline has already ran before running the RFECV, the scoring parameter will be set to the selected metric (if scoring=None). Parameters: strategy: string or None, optional (default=None) Feature selection strategy to use. Choose from: None: do not perform any feature selection algorithm 'univariate': perform a univariate F-test, from sklearn SelectKBest 'PCA': perform a principal component analysis, from sklearn PCA 'SFM': select best features from model, from sklearn SelectFromModel 'RFE': recursive feature eliminator, from sklearn RFE 'RFECV': RFE with cross-validated selection, from sklearn RFECV The sklearn objects can be found under the univariate , PCA , SFM , RFE or RFECV attributes of the class. solver: string, callable or None, optional (default=None) Solver or model to use for the feature selection strategy. See the sklearn documentation for an extended descrition of the choices. Select None for the default option per strategy (not applicable for SFM, RFE and RFECV). for 'univariate', choose from: 'f_classif' (default for classification tasks) 'f_regression' (default for regression tasks) 'mutual_info_classif' 'mutual_info_regression' 'chi2' Any function taking two arrays (X, y), and returning arrays (scores, pvalues). for 'PCA', choose from: 'auto' (default) 'full' 'arpack' 'randomized' for 'SFM': choose a base estimator from which the transformer is built. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFE': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFECV': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. n_features: int, float or None, optional (default=None) Number of features to select (except for RFECV, where it's the minimum number of features to select). if < 1: fraction of features to select if >= 1: number of features to select None to select all, or 1 for the RFECV max_frac_repeated: float or None, optional (default=1.) Remove features with the same value in at least this fraction of the total rows. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples. None to skip this step. max_correlation: float or None, optional (default=0.98) Minimum value of the Pearson correlation cofficient to identify correlated features. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. None to skip this step. **kwargs Any extra parameter for the PCA, SFM, RFE or RFECV. See the sklearn documentation for the available options. Pipeline The pipeline method is where the models are fitted to the data and their performance is evaluated according to the selected metric. For every model, the pipeline applies the following steps: The optimal hyperparameters are selectred using a Bayesian Optimization (BO) algorithm with gaussian process as kernel. The resulting score of each step of the BO is either computed by cross-validation on the complete training set or by randomly splitting the training set every iteration into a (sub) training set and a validation set. This process can create some data leakage but ensures a maximal use of the provided data. The test set, however, does not contain any leakage and will be used to determine the final score of every model. Note that, if the dataset is relatively small, the best score on the BO can consistently be lower than the final score on the test set (despite the leakage) due to the considerable fewer instances on which it is trained. Once the best hyperparameters are found, the model is trained again, now using the complete training set. After this, predictions are made on the test set. You can choose to evaluate the robustness of each model's applying a bagging algorithm, i.e. the model will be trained multiple times on a bootstrapped training set, returning a distribution of its performance on the test set. A couple of things to take into account: The metric implementation follows sklearn's API . This means that the implementation always tries to maximize the scorer, i.e. loss functions will be made negative. If an exception is encountered while fitting a model, the pipeline will automatically jump to the next model and save the exception in the errors attribute. When showing the final results, a !! indicates the highest score and a ~ indicates that the model is possibly overfitting (training set has a score at least 20% higher than the test set). The winning model subclass will be attached to the winner attribute. There are three methods to call for the pipeline. The pipeline method fits the models directly to the dataset. If you want to compare similar models, you can use the successive_halving method when running the pipeline. This technique fits N models to 1/N of the data. The best half are selected to go to the next iteration where the process is repeated. This continues until only one model remains, which is fitted on the complete dataset. Beware that a model's performance can depend greatly on the amount of data on which it is trained. For this reason we recommend only to use this technique with similar models, e.g. only using tree-based models. The train_sizing method fits the models on subsets of the training data. This can be used to examine the optimum size of the dataset needed for a satisfying performance. pipeline Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. function atom.ATOM. pipeline (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_iter=0, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. skip_iter: int, optional (default=0) Skip last skip_iter iterations of the successive halving. Will be ignored if successive_halving=False. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspcae(0.1, 1.0, 10), max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. train_sizes: sequence, optional (default=np.linspace(0.1, 1.0, 10)) Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set. Otherwise it is interpreted as absolute sizes of the training sets. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. Model subclass After running the pipeline method, a class for every selected model is created and attached to the main ATOM class as an attribute. These classes can be called upon using the models' acronyms, e.g. atom.LGB . Lowercase calls are also allowed for this attribute, e.g. atom.lgb . The model subclasses contain a variety of methods and attributes to help you understand how every specific model performed. The majority of the plots can be called directly from the subclasses. For example, to plot the ROC for the LightGBM model we could type atom.lgb.plot_ROC() . You can also save the whole subclass to a pickle file using the save method, e.g. atom.rf.save('random_forest') , or only save the best fitted model with the save_model method, e.g. atom.rf.save_model('random_forest_model') . You can also call for any of the sklearn pre-defined metrics, (e.g. atom.ET.recall ) or for any of the following custom metrics: tn (true negatives), fp (false positives), fn (false negatives), tp (true positives), tpr (true positive rate), fpr (false positive rate), sup (support/predicted positive rate) or lift . The rest of the available attributes can be found hereunder: Parameters: error: string Any exception encountered by the model. BO: dict Dictionary containing the information of every step taken by the BO. Keys include: 'params': Parameters used for the model 'score': Score of the chosen metric 'time': Time spent on this iteration 'total_time': Time spent since the start of the BO best_params: dict Dictionary of the best combination of hyperparameters found by the BO. best_model: callable Model object that performed best on the test set. Not fitted. best_model_fit: callable Model object that performed best on the test set. Fitted to the complete training set. predict_train: list Predictions of the model on the training set. predict_test: list Predictions of the model on the test set. predict_proba_train: list Predict probabilities of the model on the training set. Only for models with a `predict_proba` method. predict_proba_test: list Predict probabilities of the model on the test set. Only for models with a `predict_proba` method. decision_function_train: list Decision function scores on the training set. Only for models with a `decision_function` method. decision_function_test: list Decision function scores on the test set. Only for models with a `decision_function` method. score_bo: float Best score of the model on the Bayesian Optimization algorithm. score_train: float Metric score of the model on the training set. score_test: float Metric score of the model on the test set. bagging_scores: np.ndarray Array of the bagging's results. permutations: dict Dictionary of the permutation's results (if `plot_permutation_importance` was used). Plots The ATOM class provides a variety of plot methods to analyze the results of the pipeline. To use the plots to compare the results of multiple models, you can call them directly from the main class using the models parameter, e.g. atom.plot_PRC(models=['LDA', 'LGB']) . To call the plot for a single model, you can either fill the model in the models parameter (e.g. atom.plot_PRC(models='LDA') ) or call the from the model subclass (e.g. atom.LDA.plot_PRC() ). These two examples will render the same plot. Note that the latter approach is not available for the plot_correlation , plot_PCA , plot_components and plot_RFECV methods since they are unrelated to the models fitted in the pipeline. Note Remember that if successive halving=True, only the last fitted model is saved in the model subclass. Avoid plotting models from different iterations together since this can lead to misleading insights. The plots aesthetics can be customized using various classmethods . plot_correlation Correlation matrix plot of the data. plot_PCA Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per component. plot_RFECV Plot the scores obtained by the estimator on the RFECV. plot_bagging Plot a boxplot of the bagging's results. plot_successive_halving Plot the models' scores per iteration of the successive halving. plot_learning_curve Plot the model's learning curve: score vs training samples. plot_ROC Plot the Receiver Operating Characteristics curve. plot_PRC Plot the precision-recall curve. plot_permutation_importance Plot the feature permutation importance of models. plot_feature_importance Plot the feature permutation importance of models. plot_permutation_importance Plot tree-based model's normalized feature importances. plot_confusion_matrix Plot a model's confusion matrix. plot_threshold Plot performance metric(s) against threshold values. plot_probabilities Plot the probabilities of the different classes of belonging to the target class. plot_calibration Plot the calibration curve for a binary classifier. plot_gains Plot the cumulative gains curve. plot_lift Plot the lift curve. function atom.ATOM. plot_correlation (title=None, figsize=(10, 10), filename=None, display=True) [source] Correlation matrix plot of the dataset. Ignores non-numeric columns. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PCA (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of componenets. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: show: int or None, optional (default=None) Number of components to show. If None, the selected number of componenets are plotted. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_RFECV (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the scores obtained by the estimator fitted on every subset of the data. Only if RFECV was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_bagging (models=None, title=None, figsize=None, filename=None, display=True) [source] Plot a boxplot of the bagging's results. Only available if the models were fitted using bagging>0. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size the to number of models. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_successive_halving (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot of the models' scores per iteration of the successive halving. Only available if the models were fitted via successive_halving. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_learning_curve (models=None, train_sizes=np.linspace(0.1, 1.0, 10), cv=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the model's learning curve: score vs number of training samples. Only available if the models were fitted via train_sizing. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_ROC (models=None, title=None, figsize=(10, 6)), filename=None, display=True) [source] Plot the Receiver Operating Characteristics curve. The legend shows the Area Under the ROC Curve (AUC) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PRC (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the precision-recall curve. The legend shows the average precision (AP) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_permutation_importance (models=None, show=None, n_repeats=10, title=None, figsize=None, filename=None, display=True) [source] Plot the feature permutation importance of models. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. n_repeats: int, optional (default=10) Number of times to permute each feature. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_feature_importance (models=None, show=None, title=None, figsize=None, filename=None, display=True) [source] Plot a tree-based model's normalized feature importance. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_confusion_matrix (models=None, normalize=False, title=None, figsize=(8, 8), filename=None, display=True) [source] For 1 model: plot it's confusion matrix in a heatmap. For >1 models: compare TP, FP, FN and TN in a barplot. Not supported for multiclass classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. normalize: bool, optional (default=False) Wether to normalize the matrix. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(8, 8)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_threshold (models=None, metric=None, steps=100, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot performance metric(s) against multiple threshold values. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. metric: string, callable, sequence or None, optional (default=None) Metric(s) to plot. These can be one of the pre-defined sklearn scorers as string, a metric function or a sklearn scorer object. If None, the metric used to fit the pipeline is used. steps: int, optional (default=100) Number of thresholds measured. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_probabilities (models=None, target=1, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot a function of the probability of the classes of being the target class. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. target: int or string, optional (default=1) Probability of being that class (as index or name). title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_calibration (models=None, n_bins=10, title=None, figsize=(10, 10), filename=None, display=True) [source] Plot the calibration curve for a binary classifier. Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class. This figure shows two plots: the calibration curve and a distribution of all predicted probabilities of the classifier. Code snippets from https://scikit-learn.org/stable/auto_examples/ calibration/plot_calibration_curve.html . Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. n_bins: int, optional (default=10) Number of bins for the calibration calculation and the histogram. Minimum of 5 required. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_gains (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the cumulative gains curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_lift (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the lift curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. Plot customization The plotting aesthetics can be customized with the use of the @classmethods described hereunder, e.g. ATOMClassifier.set_style('white') . set_style Change the seaborn plotting style. set_palette Change the seaborn color palette. set_title_fontsize Change the fontsize of the plot's title. set_label_fontsize Change the fontsize of the plot's labels and legends. set_tick_fontsize Change the fontsize of the plot's ticks. classmethod ATOM. set_style (style='darkgrid') [source] Change the plotting style. See the seaborn documentation . Parameters: style: string, optional (default='darkgrid') Style to change to. Available options are: 'darkgrid', 'whitegrid', 'dark', 'white', and 'ticks'. classmethod ATOM. set_palette (palette='GnBu_d') [source] Change the plotting palette. See the seaborn documentation for the available options. Parameters: palette: string, optional (default='GnBu_d') Palette to change to. classmethod ATOM. set_title_fontsize (fontsize=20) [source] Change the fontsize of the plot's title. Parameters: fontsize: int, optional (default=20) Fontsize to change to. classmethod ATOM. set_label_fontsize (fontsize=16) [source] Change the fontsize of the plot's labels and legends. Parameters: fontsize: int, optional (default=16) Fontsize to change to. classmethod ATOM. set_tick_fontsize (fontsize=12) [source] Change the fontsize of the plot's ticks. Parameters: fontsize: int, optional (default=12) Fontsize to change to.","title":"API"},{"location":"api/#atom","text":"class atom. ATOM (X, y=None, percentage=100, test_size=0.3, log=None, n_jobs=1, warnings=False, verbose=0, random_state=None, verbose=0) [source] Main class of the package. The ATOM class is a parent class of the ATOMClassifier and ATOMRegressor classes. These will inherit all methods and attributes described in this page. Note that contrary to scikit-learn's API, the ATOM object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. Warning Don't call the ATOM class directly! Use ATOMClassifier or ATOMRegressor depending on the task at hand. Click here for an example. The class initializer will label-encode the target column if its labels are not ordered integers. It will also apply some standard data cleaning steps unto the dataset. These steps include: Transforming the input data into a pd.DataFrame (if it wasn't one already) that can be accessed through the class' data attributes. Removing columns with prohibited data types ('datetime64', 'datetime64[ns]', 'timedelta[ns]'). Removing categorical columns with maximal cardinality (the number of unique values is equal to the number of instances. Usually the case for names, IDs, etc...). Removing columns with minimum cardinality (all values are the same). Removing rows with missing values in the target column. Parameters: X: dict, sequence, np.array or pd.DataFrame Dataset containing the features, with shape=(n_samples, n_features). y: string, sequence, np.array or pd.Series, optional (default=None) If None: the last column of X is selected as target column If string: name of the target column in X Else: data target column with shape=(n_samples,) percentage: int or float, optional (default=100) Percentage of the provided dataset to use. test_size: float, optional (default=0.3) Split fraction of the train and test set. log: string or None, optional (default=None) Name of the logging file. 'auto' for default name with date and time. None to not save any log. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If -1, use all available cores If < -1, use available_cores - 1 + n_jobs Beware that using multiple processes on the same machine may cause memory issues for large datasets. warnings: bool, optional (default=False) If False, it supresses all warnings. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything 1 to print minimum information 2 to print average information 3 to print maximum information random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by np.random. Data attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. Attributes: mapping: dict Dictionary of the target values mapped to their respective encoded integer. Only for classification tasks. errors: dict Dictionary of the encountered exceptions (if any) while fitting the models. winner: callable Model subclass that performed best on the test set. scores: pd.DataFrame Dataframe (or list of dataframes if successive_halving=True) of the results. Columns can include: model: model's name (acronym) total_time: time spent on this model score_train: metric score on the training set score_test: metric score on the test set fit_time: time spent fitting and predicting bagging_mean: mean score of the bagging's results bagging_std: standard deviation score of the bagging's results bagging_time: time spent on the bagging algorithm","title":"ATOM"},{"location":"api/#utilities","text":"The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. stats Print out a list of basic statistics on the dataset. scale Scale all the features to mean=1 and std=0. update Update all data attributes. report Get an extensive profile analysis of the data. results Print final results for a specific metric. save Save the ATOM class to a pickle file. function atom.ATOM. stats () [source] Print out a list of basic statistics on the dataset. function atom.ATOM. scale () [source] Scale all the features to mean=1 and std=0. function atom.ATOM. update (df='dataset') [source] If you change any of the class' data attributes in between the pipeline, you should call this method to change all other data attributes to their correct values. Independent attributes are updated in unison, that is, setting df='X_train' will also update X_test, y_train and y_test, or df='train' will also update the test set, etc... This means that you can change both X_train and y_train and update them with one call of the method. Parameters: df: string, optional(default='dataset') Data attribute that has been changed. function atom.ATOM. report (df='dataset', rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for very large datasets. Dependency: pandas-profiling . Parameters: df: string, optional(default='dataset') Name of the data class attribute to get the profile from. rows: int or None, optional(default=None) Number of rows to process (randomly picked). None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. function atom.ATOM. results (metric=None) [source] Print the pipeline's final results for a specific metric. If a model shows a XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric needs it. Parameters: metric: string or None, optional (default=None) String of one of sklearn's predefined metrics. If None, the metric used to fit the pipeline is selected and the bagging results will be showed (if used). function atom.ATOM. save (filename=None) [source] Save the ATOM class to a pickle file. This method is also available for the model subclasses, e.g. atom.XGB.save(filename='ATOM_xgboost') . In this case, the model subclass is saved, instead of the ATOM class. Warning Remember that the class contains the complete dataset (and variations of it). This means the files can become very large for big datasets! Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name.","title":"Utilities"},{"location":"api/#data-cleaning","text":"Before throwing your data in a model, it is crucial to apply some standard data cleaning steps. ATOM provides four data cleaning methods to handle missing values, categorical columns, outliers and unbalanced datasets. Calling on one of them will automatically apply the method on the dataset in the class and update the class' data attributes accordingly. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. impute Handle missing values in the dataset. encode Encode categorical columns. outliers Remove outliers from the training set. balance Balance the number of instances per target class. function atom.ATOM. impute (strat_num='remove', strat_cat='remove', max_frac_rows=0.5, max_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. Parameters: strat_num: str, int or float, optional (default='remove') Imputing strategy for numerical columns. Choose from: 'remove': remove row if any missing value 'mean': impute with mean of column 'median': impute with median of column 'knn': impute using a K-Nearest Neighbors approach 'most_frequent': impute with most frequent value int or float: impute with provided numerical value strat_cat: str, optional (default='remove') Imputing strategy for categorical columns. Choose from: 'remove': remove row if any missing value 'most_frequent': impute with most frequent value string: impute with provided string min_frac_rows: float, optional (default=0.5) Minimum fraction of non missing values in row. If less, the row is removed. min_frac_cols: float, optional (default=0.5) Minimum fraction of non missing values in column. If less, the column is removed. missing: int, float or list, optional (default=None) List of values to impute. None for default list: [None, np.NaN, np.inf, -np.inf, '', '?', 'NA', 'nan', 'inf']. function atom.ATOM. encode (max_onehot=10, frac_to_other=0) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: label-encoding for n_unique=2 one-hot-encoding for 2 < n_unique <= max_onehot target-encoding for n_unique > max_onehot It also replaces classes with low occurences with the value 'other' in order to prevent too high cardinality. Parameters: max_onehot: int or None, optional (default=10) Maximum number of unique values in a feature to perform one-hot-encoding. If None, it will never perform one-hot-encoding. frac_to_other: float, optional (default=0) Classes with less instances than n_rows * fraction_to_other are replaced with 'other'. function atom.ATOM. outliers (max_sigma=3, include_target=False) [source] Remove rows from the training set where at least one of the values lies further than max_sigma * standard_deviation away from the mean of the column. Parameters: max_sigma: int or float, optional (default=3) Maximum allowed standard deviations from the mean. include_target: bool, optional (default=False) Wether to include the target column when searching for outliers. function atom.ATOM. balance (oversample=None, undersample=None, n_neighbors=5) [source] Balance the number of instances per target class in the training set. If both oversampling and undersampling are used, they will be applied in that order. Only for classification tasks. Dependency: imbalanced-learn . Parameters: oversample: float, string or None, optional (default=None) Oversampling strategy using ADASYN . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'minority': resample only the minority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes undersample: float, string or None, optional (default=None) Undersampling strategy using NearMiss . Choose from: None: don't oversample float: fraction of minority/majority classes (only for binary classif.) 'majority': resample only the majority class 'not minority': resample all but minority class 'not majority': resample all but majority class 'all': resample all classes n_neighbors: int, optional (default=5) Number of nearest neighbors used for any of the algorithms.","title":"Data cleaning"},{"location":"api/#feature-selection","text":"To further pre-process the data you can create new non-linear features using a genetic algorithm or, if your dataset is too large, remove features using one of the provided strategies. feature_insertion Use a genetic algorithm to create new combinations of existing features. feature_selection Remove features according to the selected strategy. function atom.ATOM. feature_insertion (n_features=2, generations=20, population=500) [source] Use a genetic algorithm to create new combinations of existing features and add them to the original dataset in order to capture the non-linear relations between the original features. A dataframe containing the description of the newly generated features and their scores can be accessed through the genetic_features attribute. The algorithm is implemented using the Symbolic Transformer method, which can be accessed through the genetic_algorithm attribute. It is adviced to only use this method when fitting linear models. Dependency: gplearn . Parameters: n_features: int, optional (default=2) Maximum number of newly generated features (no more than 1% of the population). generations: int, optional (default=20) Number of generations to evolve. population: int, optional (default=500) Number of programs in each generation. function atom.ATOM. feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=0.98, **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. Note that the RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs. If the pipeline has already ran before running the RFECV, the scoring parameter will be set to the selected metric (if scoring=None). Parameters: strategy: string or None, optional (default=None) Feature selection strategy to use. Choose from: None: do not perform any feature selection algorithm 'univariate': perform a univariate F-test, from sklearn SelectKBest 'PCA': perform a principal component analysis, from sklearn PCA 'SFM': select best features from model, from sklearn SelectFromModel 'RFE': recursive feature eliminator, from sklearn RFE 'RFECV': RFE with cross-validated selection, from sklearn RFECV The sklearn objects can be found under the univariate , PCA , SFM , RFE or RFECV attributes of the class. solver: string, callable or None, optional (default=None) Solver or model to use for the feature selection strategy. See the sklearn documentation for an extended descrition of the choices. Select None for the default option per strategy (not applicable for SFM, RFE and RFECV). for 'univariate', choose from: 'f_classif' (default for classification tasks) 'f_regression' (default for regression tasks) 'mutual_info_classif' 'mutual_info_regression' 'chi2' Any function taking two arrays (X, y), and returning arrays (scores, pvalues). for 'PCA', choose from: 'auto' (default) 'full' 'arpack' 'randomized' for 'SFM': choose a base estimator from which the transformer is built. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFE': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. for 'RFECV': choose a supervised learning estimator. The estimator must have either a feature_importances_ or coef_ attribute after fitting. You can use a model from the pipeline . No default option. n_features: int, float or None, optional (default=None) Number of features to select (except for RFECV, where it's the minimum number of features to select). if < 1: fraction of features to select if >= 1: number of features to select None to select all, or 1 for the RFECV max_frac_repeated: float or None, optional (default=1.) Remove features with the same value in at least this fraction of the total rows. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples. None to skip this step. max_correlation: float or None, optional (default=0.98) Minimum value of the Pearson correlation cofficient to identify correlated features. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. None to skip this step. **kwargs Any extra parameter for the PCA, SFM, RFE or RFECV. See the sklearn documentation for the available options.","title":"Feature selection"},{"location":"api/#pipeline","text":"The pipeline method is where the models are fitted to the data and their performance is evaluated according to the selected metric. For every model, the pipeline applies the following steps: The optimal hyperparameters are selectred using a Bayesian Optimization (BO) algorithm with gaussian process as kernel. The resulting score of each step of the BO is either computed by cross-validation on the complete training set or by randomly splitting the training set every iteration into a (sub) training set and a validation set. This process can create some data leakage but ensures a maximal use of the provided data. The test set, however, does not contain any leakage and will be used to determine the final score of every model. Note that, if the dataset is relatively small, the best score on the BO can consistently be lower than the final score on the test set (despite the leakage) due to the considerable fewer instances on which it is trained. Once the best hyperparameters are found, the model is trained again, now using the complete training set. After this, predictions are made on the test set. You can choose to evaluate the robustness of each model's applying a bagging algorithm, i.e. the model will be trained multiple times on a bootstrapped training set, returning a distribution of its performance on the test set. A couple of things to take into account: The metric implementation follows sklearn's API . This means that the implementation always tries to maximize the scorer, i.e. loss functions will be made negative. If an exception is encountered while fitting a model, the pipeline will automatically jump to the next model and save the exception in the errors attribute. When showing the final results, a !! indicates the highest score and a ~ indicates that the model is possibly overfitting (training set has a score at least 20% higher than the test set). The winning model subclass will be attached to the winner attribute. There are three methods to call for the pipeline. The pipeline method fits the models directly to the dataset. If you want to compare similar models, you can use the successive_halving method when running the pipeline. This technique fits N models to 1/N of the data. The best half are selected to go to the next iteration where the process is repeated. This continues until only one model remains, which is fitted on the complete dataset. Beware that a model's performance can depend greatly on the amount of data on which it is trained. For this reason we recommend only to use this technique with similar models, e.g. only using tree-based models. The train_sizing method fits the models on subsets of the training data. This can be used to examine the optimum size of the dataset needed for a satisfying performance. pipeline Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. function atom.ATOM. pipeline (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_iter=0, max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. skip_iter: int, optional (default=0) Skip last skip_iter iterations of the successive halving. Will be ignored if successive_halving=False. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. function atom.ATOM. train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspcae(0.1, 1.0, 10), max_iter=0, max_time=np.inf, init_points=5, plot_bo=False, cv=3, bagging=None) [source] Parameters: models: string or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): 'GNB' for Gaussian Na\u00efve Bayes Only for classification tasks. No hyperparameter tuning. 'MNB' for Multinomial Na\u00efve Bayes Only for classification tasks. 'BNB' for Bernoulli Na\u00efve Bayes Only for classification tasks. 'GP' for Gaussian Process classifier / regressor No hyperparameter tuning. 'OLS' for Ordinary Least Squares Only for regression tasks. No hyperparameter tuning. 'Ridge' for Ridge Linear classifier / regressor Only for regression tasks. 'Lasso' for Lasso Linear Regression Only for regression tasks. 'EN' for ElasticNet Linear Regression Only for regression tasks. 'BR' for Bayesian Regression Only for regression tasks. Uses ridge regularization. 'LR' for Logistic Regression Only for classification tasks. 'LDA' for Linear Discriminant Analysis Only for classification tasks. 'QDA' for Quadratic Discriminant Analysis Only for classification tasks. 'KNN' for K-Nearest Neighbors classifier / regressor 'Tree' for a single Decision Tree classifier / regressor 'Bag' for Bagging classifier / regressor Uses a decision tree as base estimator. 'ET' for Extra-Trees classifier / regressor 'RF' for Random Forest classifier / regressor 'AdaB' for AdaBoost classifier / regressor Uses a decision tree as base estimator. 'GBM' for Gradient Boosting Machine classifier / regressor 'XGB' for XGBoost classifier / regressor Only available if package is installed. 'LGB' for LightGBM classifier / regressor Only available if package is installed. 'CatB' for CatBoost classifier / regressor Only available if package is installed. 'lSVM' for Linear Support Vector Machine classifier / regressor Uses a one-vs-rest strategy for multiclass classification tasks. 'kSVM' for Kernel (non-linear) Support Vector Machine classifier / regressor Uses a one-vs-one strategy for multiclass classification tasks. 'PA' for Passive Aggressive classifier / regressor 'SGD' for Stochastic Gradient Descent classifier / regressor 'MLP' for Multilayer Perceptron classifier / regressor Can have between one and three hidden layers. metric: string or callable, optional (default=None) Metric on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If None, ATOM will try to use any metric it already has in the pipeline. If it hasn't got any, a default metric per task is selected: 'f1' for binary classification 'f1_weighted' for multiclas classification 'r2' for regression greater_is_better: bool, optional (default=True) Wether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. needs_proba: bool, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method! Will be ignored if the metric is a string or a scorer. needs_threshold: bool, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. train_sizes: sequence, optional (default=np.linspace(0.1, 1.0, 10)) Relative or absolute numbers of training examples that will be used to generate the learning curve. If the dtype is float, it is regarded as a fraction of the maximum size of the training set. Otherwise it is interpreted as absolute sizes of the training sets. max_iter: int or sequence, optional (default=0) Maximum number of iterations of the BO. If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. max_time: int, float or sequence, optional (default=np.inf) Maximum time allowed for the BO per model (in seconds). If 0, skip the BO and fit the model on its default parameters. If sequence, the n-th value will apply to the n-th model in the pipeline. init_points: int or sequence, optional (default=5) Initial number of tests of the BO before fitting the surrogate function. If 1, the default models' hyperparameters will be used. If sequence, the n-th value will apply to the n-th model in the pipeline. cv: int or sequence, optional (default=3) Strategy to fit and score the model selected after every step of the BO. if 1, randomly split into a train and validation set if >1, perform a k-fold cross validation on the training set plot_bo: bool, optional (default=False) Wether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using jupyter notebook! bagging: int or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed.","title":"Pipeline"},{"location":"api/#model-subclass","text":"After running the pipeline method, a class for every selected model is created and attached to the main ATOM class as an attribute. These classes can be called upon using the models' acronyms, e.g. atom.LGB . Lowercase calls are also allowed for this attribute, e.g. atom.lgb . The model subclasses contain a variety of methods and attributes to help you understand how every specific model performed. The majority of the plots can be called directly from the subclasses. For example, to plot the ROC for the LightGBM model we could type atom.lgb.plot_ROC() . You can also save the whole subclass to a pickle file using the save method, e.g. atom.rf.save('random_forest') , or only save the best fitted model with the save_model method, e.g. atom.rf.save_model('random_forest_model') . You can also call for any of the sklearn pre-defined metrics, (e.g. atom.ET.recall ) or for any of the following custom metrics: tn (true negatives), fp (false positives), fn (false negatives), tp (true positives), tpr (true positive rate), fpr (false positive rate), sup (support/predicted positive rate) or lift . The rest of the available attributes can be found hereunder: Parameters: error: string Any exception encountered by the model. BO: dict Dictionary containing the information of every step taken by the BO. Keys include: 'params': Parameters used for the model 'score': Score of the chosen metric 'time': Time spent on this iteration 'total_time': Time spent since the start of the BO best_params: dict Dictionary of the best combination of hyperparameters found by the BO. best_model: callable Model object that performed best on the test set. Not fitted. best_model_fit: callable Model object that performed best on the test set. Fitted to the complete training set. predict_train: list Predictions of the model on the training set. predict_test: list Predictions of the model on the test set. predict_proba_train: list Predict probabilities of the model on the training set. Only for models with a `predict_proba` method. predict_proba_test: list Predict probabilities of the model on the test set. Only for models with a `predict_proba` method. decision_function_train: list Decision function scores on the training set. Only for models with a `decision_function` method. decision_function_test: list Decision function scores on the test set. Only for models with a `decision_function` method. score_bo: float Best score of the model on the Bayesian Optimization algorithm. score_train: float Metric score of the model on the training set. score_test: float Metric score of the model on the test set. bagging_scores: np.ndarray Array of the bagging's results. permutations: dict Dictionary of the permutation's results (if `plot_permutation_importance` was used).","title":"Model subclass"},{"location":"api/#plots","text":"The ATOM class provides a variety of plot methods to analyze the results of the pipeline. To use the plots to compare the results of multiple models, you can call them directly from the main class using the models parameter, e.g. atom.plot_PRC(models=['LDA', 'LGB']) . To call the plot for a single model, you can either fill the model in the models parameter (e.g. atom.plot_PRC(models='LDA') ) or call the from the model subclass (e.g. atom.LDA.plot_PRC() ). These two examples will render the same plot. Note that the latter approach is not available for the plot_correlation , plot_PCA , plot_components and plot_RFECV methods since they are unrelated to the models fitted in the pipeline. Note Remember that if successive halving=True, only the last fitted model is saved in the model subclass. Avoid plotting models from different iterations together since this can lead to misleading insights. The plots aesthetics can be customized using various classmethods . plot_correlation Correlation matrix plot of the data. plot_PCA Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per component. plot_RFECV Plot the scores obtained by the estimator on the RFECV. plot_bagging Plot a boxplot of the bagging's results. plot_successive_halving Plot the models' scores per iteration of the successive halving. plot_learning_curve Plot the model's learning curve: score vs training samples. plot_ROC Plot the Receiver Operating Characteristics curve. plot_PRC Plot the precision-recall curve. plot_permutation_importance Plot the feature permutation importance of models. plot_feature_importance Plot the feature permutation importance of models. plot_permutation_importance Plot tree-based model's normalized feature importances. plot_confusion_matrix Plot a model's confusion matrix. plot_threshold Plot performance metric(s) against threshold values. plot_probabilities Plot the probabilities of the different classes of belonging to the target class. plot_calibration Plot the calibration curve for a binary classifier. plot_gains Plot the cumulative gains curve. plot_lift Plot the lift curve. function atom.ATOM. plot_correlation (title=None, figsize=(10, 10), filename=None, display=True) [source] Correlation matrix plot of the dataset. Ignores non-numeric columns. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PCA (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of componenets. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. Only if a Principal Component Analysis was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: show: int or None, optional (default=None) Number of components to show. If None, the selected number of componenets are plotted. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_RFECV (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the scores obtained by the estimator fitted on every subset of the data. Only if RFECV was applied on the dataset through the feature_selection method. Can't be called from the model subclasses. Parameters: title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_bagging (models=None, title=None, figsize=None, filename=None, display=True) [source] Plot a boxplot of the bagging's results. Only available if the models were fitted using bagging>0. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size the to number of models. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_successive_halving (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot of the models' scores per iteration of the successive halving. Only available if the models were fitted via successive_halving. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_learning_curve (models=None, train_sizes=np.linspace(0.1, 1.0, 10), cv=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the model's learning curve: score vs number of training samples. Only available if the models were fitted via train_sizing. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_ROC (models=None, title=None, figsize=(10, 6)), filename=None, display=True) [source] Plot the Receiver Operating Characteristics curve. The legend shows the Area Under the ROC Curve (AUC) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_PRC (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the precision-recall curve. The legend shows the average precision (AP) score. Only for binary classification tasks. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_permutation_importance (models=None, show=None, n_repeats=10, title=None, figsize=None, filename=None, display=True) [source] Plot the feature permutation importance of models. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. n_repeats: int, optional (default=10) Number of times to permute each feature. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_feature_importance (models=None, show=None, title=None, figsize=None, filename=None, display=True) [source] Plot a tree-based model's normalized feature importance. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None for all. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_confusion_matrix (models=None, normalize=False, title=None, figsize=(8, 8), filename=None, display=True) [source] For 1 model: plot it's confusion matrix in a heatmap. For >1 models: compare TP, FP, FN and TN in a barplot. Not supported for multiclass classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. normalize: bool, optional (default=False) Wether to normalize the matrix. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(8, 8)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_threshold (models=None, metric=None, steps=100, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot performance metric(s) against multiple threshold values. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. metric: string, callable, sequence or None, optional (default=None) Metric(s) to plot. These can be one of the pre-defined sklearn scorers as string, a metric function or a sklearn scorer object. If None, the metric used to fit the pipeline is used. steps: int, optional (default=100) Number of thresholds measured. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_probabilities (models=None, target=1, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot a function of the probability of the classes of being the target class. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. target: int or string, optional (default=1) Probability of being that class (as index or name). title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_calibration (models=None, n_bins=10, title=None, figsize=(10, 10), filename=None, display=True) [source] Plot the calibration curve for a binary classifier. Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class. This figure shows two plots: the calibration curve and a distribution of all predicted probabilities of the classifier. Code snippets from https://scikit-learn.org/stable/auto_examples/ calibration/plot_calibration_curve.html . Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. n_bins: int, optional (default=10) Number of bins for the calibration calculation and the histogram. Minimum of 5 required. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_gains (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the cumulative gains curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot. function atom.ATOM. plot_lift (models=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the lift curve. Only for binary classification. Parameters: models: string, sequence or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. title: string or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: string or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Wether to render the plot.","title":"Plots"},{"location":"api/#plot-customization","text":"The plotting aesthetics can be customized with the use of the @classmethods described hereunder, e.g. ATOMClassifier.set_style('white') . set_style Change the seaborn plotting style. set_palette Change the seaborn color palette. set_title_fontsize Change the fontsize of the plot's title. set_label_fontsize Change the fontsize of the plot's labels and legends. set_tick_fontsize Change the fontsize of the plot's ticks. classmethod ATOM. set_style (style='darkgrid') [source] Change the plotting style. See the seaborn documentation . Parameters: style: string, optional (default='darkgrid') Style to change to. Available options are: 'darkgrid', 'whitegrid', 'dark', 'white', and 'ticks'. classmethod ATOM. set_palette (palette='GnBu_d') [source] Change the plotting palette. See the seaborn documentation for the available options. Parameters: palette: string, optional (default='GnBu_d') Palette to change to. classmethod ATOM. set_title_fontsize (fontsize=20) [source] Change the fontsize of the plot's title. Parameters: fontsize: int, optional (default=20) Fontsize to change to. classmethod ATOM. set_label_fontsize (fontsize=16) [source] Change the fontsize of the plot's labels and legends. Parameters: fontsize: int, optional (default=16) Fontsize to change to. classmethod ATOM. set_tick_fontsize (fontsize=12) [source] Change the fontsize of the plot's ticks. Parameters: fontsize: int, optional (default=12) Fontsize to change to.","title":"Plot customization"},{"location":"dependencies/","text":"Python As of the moment, ATOM supports Python 3.6 , 3.7 and 3.8 . Packages ATOM is built on top of several existing Python libraries. The required packages are necessary for it's correct functioning. Additionnaly, you can install some optional packages needed for specific methods or to use machine learning models not provided by sklearn. Required numpy (>=1.17.2) scipy (>=1.4.1) pandas (>=1.0.1) scikit-learn (>=0.22) tabulate (>=0.8.6) tqdm (>=4.35.0) typeguard (>=2.7.1) gpyopt (>=1.2.5) matplotlib (>=3.1.0) seaborn (>=0.9.0) Optional pandas-profiling (>=2.3.0) imbalanced-learn (>=0.5.0) gplearn (>=0.4.1) xgboost (>=0.90) lightgbm (>=2.3.0) catboost (>=0.19.1)","title":"Dependencies"},{"location":"dependencies/#python","text":"As of the moment, ATOM supports Python 3.6 , 3.7 and 3.8 .","title":"Python"},{"location":"dependencies/#packages","text":"ATOM is built on top of several existing Python libraries. The required packages are necessary for it's correct functioning. Additionnaly, you can install some optional packages needed for specific methods or to use machine learning models not provided by sklearn. Required numpy (>=1.17.2) scipy (>=1.4.1) pandas (>=1.0.1) scikit-learn (>=0.22) tabulate (>=0.8.6) tqdm (>=4.35.0) typeguard (>=2.7.1) gpyopt (>=1.2.5) matplotlib (>=3.1.0) seaborn (>=0.9.0) Optional pandas-profiling (>=2.3.0) imbalanced-learn (>=0.5.0) gplearn (>=0.4.1) xgboost (>=0.90) lightgbm (>=2.3.0) catboost (>=0.19.1)","title":"Packages"},{"location":"examples/","text":"Binary classification Download the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . This dataset tries to predict whether or not it will rain tomorrow by training a classification model on target RainTomorrow . Load the data # Import packages import numpy as np import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('../weatherAUS.csv') X = X.drop(['RISK_MM', 'Date'], axis=1) # Drop unrelated features Run the pipeline # Call ATOM using only a percentage of the complete dataset (for explanatory purposes) atom = ATOMClassifier(X, y=\"RainTomorrow\", percentage=5, log='auto', n_jobs=2, verbose=3) <<=============== ATOM ===============>> Parallel processing with 2 cores. Initial data cleaning... --> Dropping 45 duplicate rows. Algorithm task: binary classification. Dataset stats ===================> Shape: (7107, 22) Missing values: 15680 Categorical columns: 5 Scaled: False ---------------------------------- Size of training set: 4974 Size of test set: 2133 ---------------------------------- Class balance: No:Yes <==> 3.4:1.0 Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 5502 | 3854 | 1648 | | 1: Yes | 1605 | 1120 | 485 | # If we change a column during the pre-processing, # we need to call the update method to update all data attributes atom.X['MaxTemp'] = np.log(atom.X['MaxTemp']) # MaxTemp has now been changed for atom.X, but not in atom.X_train, atom.dataset, etc... # To do so, we use the update method... atom.update('X') assert atom.X['MaxTemp'].equals(atom.dataset['MaxTemp']) # Impute missing values atom.impute(strat_num='knn', strat_cat='remove', max_frac_rows=0.8) Imputing missing values... --> Removing 741 rows for containing too many missing values. --> Imputing 3 missing values using the KNN imputer in feature MinTemp. --> Imputing 4 missing values using the KNN imputer in feature MaxTemp. --> Imputing 43 missing values using the KNN imputer in feature Rainfall. --> Imputing 2315 missing values using the KNN imputer in feature Evaporation. --> Imputing 2661 missing values using the KNN imputer in feature Sunshine. --> Removing 222 rows due to missing values in feature WindGustDir. --> Imputing 221 missing values using the KNN imputer in feature WindGustSpeed. --> Removing 327 rows due to missing values in feature WindDir9am. --> Removing 24 rows due to missing values in feature WindDir3pm. --> Imputing 6 missing values using the KNN imputer in feature WindSpeed9am. --> Imputing 2 missing values using the KNN imputer in feature WindSpeed3pm. --> Imputing 25 missing values using the KNN imputer in feature Humidity9am. --> Imputing 55 missing values using the KNN imputer in feature Humidity3pm. --> Imputing 56 missing values using the KNN imputer in feature Pressure9am. --> Imputing 51 missing values using the KNN imputer in feature Pressure3pm. --> Imputing 2118 missing values using the KNN imputer in feature Cloud9am. --> Imputing 2253 missing values using the KNN imputer in feature Cloud3pm. --> Imputing 5 missing values using the KNN imputer in feature Temp9am. --> Imputing 32 missing values using the KNN imputer in feature Temp3pm. --> Removing 43 rows due to missing values in feature RainToday. # Encode the categorical features atom.encode(max_onehot=10, frac_to_other=0.04) Encoding categorical features... --> Target-encoding feature Location. Contains 1 unique categories. --> Target-encoding feature WindGustDir. Contains 16 unique categories. --> Target-encoding feature WindDir9am. Contains 16 unique categories. --> Target-encoding feature WindDir3pm. Contains 16 unique categories. --> Label-encoding feature RainToday. Contains 2 unique categories. # Perform undersampling of the majority class to balance the dataset atom.balance(undersample=0.8) Performing undersampling... --> Removing 249 rows from class No. # Remove outliers from the training set atom.outliers(max_sigma=5) Handling outliers... --> Dropping 18 rows due to outliers. # Select only the best 10 features atom.feature_selection(strategy=\"univariate\", max_features=15, max_correlation=0.8) # See which features were removed due to collinearity atom.collinear Performing feature selection... --> Feature Location was removed due to low variance: 0.00. --> Feature Pressure3pm was removed due to collinearity with another feature. --> Feature Temp9am was removed due to collinearity with another feature. --> Feature Temp3pm was removed due to collinearity with another feature. --> Feature MinTemp was removed after the univariate test (score: 9.36 p-value: 0.00). --> Feature Evaporation was removed after the univariate test (score: 27.00 p-value: 0.00). .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } drop_feature correlated_feature correlation_value 0 Pressure3pm Pressure9am 0.95413 1 Temp9am MinTemp, MaxTemp 0.9201, 0.89643 2 Temp3pm MaxTemp, Temp9am 0.9587, 0.87527 # Change the verbosity of ATOM to not print too much details while fitting atom.verbose = 2 # Let's use a custom metric def f2_score(y_true, y_pred): return fbeta_score(y_true, y_pred, beta=2) # Let's compare the performance of various gradient boosting algorithms atom.pipeline(['gbm', 'lgb', 'catb'], metric=f2_score, max_iter=5, init_points=5, cv=1, bagging=5) Running pipeline =================> Models in pipeline: GBM, LGB, CatB Metric: f2_score Running BO for Gradient Boosting Machine... Final results for Gradient Boosting Machine: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 414, 'learning_rate': 1.0, 'subsample': 0.5, 'max_depth': 2, 'max_features': 0.8, 'criterion': 'mse', 'min_samples_split': 12, 'min_samples_leaf': 1, 'ccp_alpha': 0.0} Best score on the BO: 0.7485 Time elapsed: 37.958s Fitting ----------------------------------------- Score on the training set: 0.8465 Score on the test set: 0.5824 Time elapsed: 0.796s Bagging ----------------------------------------- Mean: 0.5587 Std: 0.0105 Time elapsed: 3.562s ------------------------------------------------- Total time: 42.316s Running BO for LightGBM... Final results for LightGBM: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 345, 'learning_rate': 0.6, 'max_depth': 3, 'num_leaves': 24, 'min_child_weight': 9, 'min_child_samples': 17, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 0.0, 'reg_lambda': 0.1} Best score on the BO: 0.7583 Time elapsed: 3.261s Fitting ----------------------------------------- Score on the training set: 0.9937 Score on the test set: 0.6182 Time elapsed: 0.187s Bagging ----------------------------------------- Mean: 0.6169 Std: 0.0197 Time elapsed: 0.370s ------------------------------------------------- Total time: 3.819s Running BO for CatBoost... Final results for CatBoost: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 499, 'learning_rate': 0.09, 'max_depth': 9, 'subsample': 0.7, 'colsample_bylevel': 0.8, 'reg_lambda': 100.0} Best score on the BO: 0.7714 Time elapsed: 14.712s Fitting ----------------------------------------- Score on the training set: 0.9390 Score on the test set: 0.6365 Time elapsed: 3.890s Bagging ----------------------------------------- Mean: 0.6374 Std: 0.0083 Time elapsed: 19.245s ------------------------------------------------- Total time: 37.847s Final results ================>> Duration: 1m:23s Metric: f2_score -------------------------------- Gradient Boosting Machine --> 0.559 \u00b1 0.010 ~ LightGBM --> 0.617 \u00b1 0.020 ~ CatBoost --> 0.637 \u00b1 0.008 !! ~ Analyze the results # Let's have a look at the best model print('And the winner is...', atom.winner.longname) print('Score on the training set: ', atom.winner.score_train) print('Score on the test set: ', atom.winner.score_test) And the winner is... CatBoost Score on the training set: 0.9390495867768595 Score on the test set: 0.6364787840405319 # Make some plots to analyze the results atom.winner.plot_confusion_matrix(normalize=True, figsize=(7, 7), filename='confusion_matrix.png') atom.winner.plot_probabilities() # Change plots aesthetics ATOMClassifier.set_style('whitegrid') ATOMClassifier.set_title_fontsize(24) atom.plot_ROC(models=('LGB', 'CatB'), title=\"ROC for the LightGBM vs CatBoost model\") atom.plot_PRC(title=\"PRC comparison of the models\") atom.catb.plot_threshold(metric=['f1', 'accuracy', 'average_precision'], steps=50, filename='thresholds.png') Multiclass classification Import the wine dataset from sklearn.datasets . This is a small and easy to train dataset which goal is to classify wines into three groups (which cultivator it's from) using features based on the results of chemical analysis. Load the data # Import packages import numpy as np import pandas as pd from sklearn.datasets load_wine from atom.atom import ATOMClassifier # Load the dataset's features and targets dataset = load_wine() # Convert to pd.DtaFrame to get the names of the features data = np.c_[dataset.data, dataset.target] columns = np.append(dataset.feature_names, [\"target\"]) data = pd.DataFrame(data, columns=columns) X = data.drop('target', axis=1) y = data['target'] Run the pipeline # Call ATOMclass for ML task exploration atom = ATOMClassifier(X, y, n_jobs=-1, verbose=3) # Fit the pipeline with the selected models atom.pipeline(models=['LDA','RF', 'lSVM'], metric='f1_macro', max_iter=4, init_points=3, cv=3, bagging=10) <<=============== ATOM ===============>> Parallel processing with 4 cores. Initial data cleaning... Algorithm task: multiclass classification. Number of classes: 3. Dataset stats ===================> Shape: (178, 14) Scaled: False ---------------------------------- Size of training set: 124 Size of test set: 54 ---------------------------------- Instances in target per class: | | total | train_set | test_set | |---:|---------:|-------------:|------------:| | 0 | 59 | 42 | 17 | | 1 | 71 | 47 | 24 | | 2 | 48 | 35 | 13 | Running pipeline =================> Models in pipeline: LDA, RF, lSVM Metric: f1_macro Running BO for Linear Discriminant Analysis... Initial point: 1 -------------------------------- Parameters --> {'solver': 'lsqr', 'shrinkage': 0.9} Evaluation --> f1_macro: 0.6787 Time elapsed: 0.815s Total time: 0.816s Initial point: 2 -------------------------------- Parameters --> {'solver': 'lsqr', 'shrinkage': 0.8} Evaluation --> f1_macro: 0.6865 Time elapsed: 0.505s Total time: 1.320s Initial point: 3 -------------------------------- Parameters --> {'solver': 'eigen', 'shrinkage': 0.7} Evaluation --> f1_macro: 0.6667 Time elapsed: 0.021s Total time: 1.341s Iteration: 1 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9753 Time elapsed: 0.020s Total time: 1.560s Iteration: 2 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9753 Time elapsed: 0.026s Total time: 1.796s Final results for Linear Discriminant Analysis: Bayesian Optimization --------------------------- Best hyperparameters: {'solver': 'svd'} Best score on the BO: 0.9753 Time elapsed: 1.936s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 0.9617 Time elapsed: 0.079s Bagging ----------------------------------------- Mean: 0.9788 Std: 0.0159 Time elapsed: 0.035s ------------------------------------------------- Total time: 2.050s Running BO for Random Forest... Initial point: 1 -------------------------------- Parameters --> {'n_estimators': 460, 'max_depth': 5, 'max_features': 0.9, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 20, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.7} Evaluation --> f1_macro: 0.8673 Time elapsed: 0.835s Total time: 0.836s Initial point: 2 -------------------------------- Parameters --> {'n_estimators': 210, 'max_depth': 6, 'max_features': 0.5, 'criterion': 'entropy', 'min_samples_split': 11, 'min_samples_leaf': 14, 'ccp_alpha': 0.025, 'bootstrap': False} Evaluation --> f1_macro: 0.9357 Time elapsed: 0.449s Total time: 1.286s Initial point: 3 -------------------------------- Parameters --> {'n_estimators': 155, 'max_depth': 7, 'max_features': 0.7, 'criterion': 'entropy', 'min_samples_split': 18, 'min_samples_leaf': 13, 'ccp_alpha': 0.02, 'bootstrap': False} Evaluation --> f1_macro: 0.8638 Time elapsed: 0.405s Total time: 1.691s Iteration: 1 ------------------------------------ Parameters --> {'n_estimators': 460, 'max_depth': 6, 'max_features': 0.9, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 20, 'ccp_alpha': 0.035, 'bootstrap': True, 'max_samples': 0.7} Evaluation --> f1_macro: 0.9073 Time elapsed: 0.827s Total time: 2.801s Iteration: 2 ------------------------------------ Parameters --> {'n_estimators': 20, 'max_depth': 3, 'max_features': 0.7, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 18, 'ccp_alpha': 0.015, 'bootstrap': False} Evaluation --> f1_macro: 0.8953 Time elapsed: 0.234s Total time: 3.362s Iteration: 3 ------------------------------------ Parameters --> {'n_estimators': 20, 'max_depth': 8, 'max_features': 0.6, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 3, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.6} Evaluation --> f1_macro: 0.9512 Time elapsed: 0.231s Total time: 3.822s Iteration: 4 ------------------------------------ Parameters --> {'n_estimators': 20, 'max_depth': 9, 'max_features': 1.0, 'criterion': 'entropy', 'min_samples_split': 20, 'min_samples_leaf': 7, 'ccp_alpha': 0.02, 'bootstrap': False} Evaluation --> f1_macro: 0.8560 Time elapsed: 0.235s Total time: 4.563s Final results for Random Forest: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 20, 'max_depth': 8, 'max_features': 0.6, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 3, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.6} Best score on the BO: 0.9512 Time elapsed: 4.790s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 0.9448 Time elapsed: 5.671s Bagging ----------------------------------------- Mean: 0.9240 Std: 0.0274 Time elapsed: 2.345s ------------------------------------------------- Total time: 12.806s Running BO for Linear SVM... Initial point: 1 -------------------------------- Parameters --> {'C': 0.01, 'loss': 'squared_hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9833 Time elapsed: 0.031s Total time: 0.031s Initial point: 2 -------------------------------- Parameters --> {'C': 0.001, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9290 Time elapsed: 0.016s Total time: 0.047s Initial point: 3 -------------------------------- Parameters --> {'C': 0.001, 'loss': 'squared_hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9601 Time elapsed: 0.031s Total time: 0.078s Iteration: 1 ------------------------------------ Parameters --> {'C': 10, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9842 Time elapsed: 0.028s Total time: 0.359s Iteration: 2 ------------------------------------ Parameters --> {'C': 100, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9842 Time elapsed: 0.025s Total time: 0.730s Iteration: 3 ------------------------------------ Parameters --> {'C': 100, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9842 Time elapsed: 0.016s Total time: 1.059s Final results for Linear SVM: Bayesian Optimization --------------------------- Best hyperparameters: {'C': 10.0, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Best score on the BO: 0.9842 Time elapsed: 1.230s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 0.9617 Time elapsed: 0.047s Bagging ----------------------------------------- Mean: 0.9498 Std: 0.0117 Time elapsed: 0.101s ------------------------------------------------- Total time: 1.379s Final results ================>> Duration: 16.238s Metric: f1_macro -------------------------------- Linear Discriminant Analysis --> 0.979 \u00b1 0.016 !! Random Forest --> 0.924 \u00b1 0.027 Linear SVM --> 0.950 \u00b1 0.012 Analyze the results atom.scores .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } model total_time score_train score_test fit_time bagging_mean bagging_std bagging_time 0 LDA 2.050s 1.0 0.961698 0.079s 0.978848 0.015898 0.035s 1 RF 12.806s 1.0 0.944813 5.671s 0.923975 0.027393 2.345s 2 lSVM 1.379s 1.0 0.961698 0.047s 0.949818 0.011717 0.101s # Show the results for a different metric atom.results('precision_macro') Final results ================>> Metric: precision_macro -------------------------------- Linear Discriminant Analysis --> 0.956 !! Random Forest --> 0.941 Linear SVM --> 0.956 !! atom.plot_bagging() Let's have a closer look at the Random Forest # Get the results on some other metrics print('Jaccard score:', atom.rf.jaccard_weighted) print('Recall score:', atom.rf.recall_macro) Jaccard score: 0.8960493827160495 Recall score: 0.9526143790849674 # Plot the feature importance and compare it to the permutation importance of the LDA atom.rf.plot_feature_importance(show=10) atom.lda.plot_permutation_importance(show=10) # Save the random forest class for production atom.RF.save('Random_Forest_class') Random Forest model subclass saved successfully! Regression Download the abalone dataset from https://archive.ics.uci.edu/ml/datasets/Abalone . The goal of this dataset is to predict the age of abalone shells from physical measurements. Load the data # Import packages import pandas as pd from atom import ATOMRegressor # Load the abalone dataset X = pd.read_csv('../abalone.csv') atom = ATOMRegressor(X, y=\"Rings\", percentage=10, warnings=False, verbose=1, random_state=42) # Encode categorical features atom.encode() # Apply PCA for dimensionality reduction atom.feature_selection(strategy=\"pca\", max_features=6) atom.plot_PCA(figsize=(8, 6), filename='atom_PCA_plot') <<=============== ATOM ===============>> Algorithm task: regression. Run the pipeline # Let's compare tree-based models using a successive halving approach atom.pipeline(['tree', 'bag', 'et', 'rf', 'gbm', 'lgb'], successive_halving=True, metric='neg_mean_squared_error', max_iter=5, init_points=5, cv=1, bagging=5) Running pipeline =================> Metric: neg_mean_squared_error <<=============== Iteration 0 ==============>> Models in pipeline: Tree, Bag, ET, RF, GBM, LGB Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:25<00:00, 4.18s/it] Final results ================>> Duration: 25.079s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -9.479 \u00b1 0.667 !! ~ Bagging Regressor --> -11.409 \u00b1 2.167 ~ Extra-Trees --> -11.788 \u00b1 1.270 ~ Random Forest --> -11.441 \u00b1 1.059 ~ Gradient Boosting Machine --> -11.044 \u00b1 2.575 ~ LightGBM --> -12.929 \u00b1 3.211 ~ <<=============== Iteration 1 ==============>> Models in pipeline: Tree, Bag, GBM Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:12<00:00, 4.03s/it] Final results ================>> Duration: 37.229s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -11.110 \u00b1 5.487 ~ Bagging Regressor --> -6.780 \u00b1 1.605 !! ~ Gradient Boosting Machine --> -8.079 \u00b1 0.545 ~ <<=============== Iteration 2 ==============>> Model in pipeline: Bag Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:10<00:00, 10.36s/it] Final results ================>> Duration: 47.619s Metric: neg_mean_squared_error -------------------------------- Bagging Regressor --> -4.925 \u00b1 0.403 ~ Analyze the results # Plot successive halving results atom.plot_successive_halving()","title":"Examples"},{"location":"examples/#binary-classification","text":"Download the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . This dataset tries to predict whether or not it will rain tomorrow by training a classification model on target RainTomorrow . Load the data # Import packages import numpy as np import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('../weatherAUS.csv') X = X.drop(['RISK_MM', 'Date'], axis=1) # Drop unrelated features Run the pipeline # Call ATOM using only a percentage of the complete dataset (for explanatory purposes) atom = ATOMClassifier(X, y=\"RainTomorrow\", percentage=5, log='auto', n_jobs=2, verbose=3) <<=============== ATOM ===============>> Parallel processing with 2 cores. Initial data cleaning... --> Dropping 45 duplicate rows. Algorithm task: binary classification. Dataset stats ===================> Shape: (7107, 22) Missing values: 15680 Categorical columns: 5 Scaled: False ---------------------------------- Size of training set: 4974 Size of test set: 2133 ---------------------------------- Class balance: No:Yes <==> 3.4:1.0 Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 5502 | 3854 | 1648 | | 1: Yes | 1605 | 1120 | 485 | # If we change a column during the pre-processing, # we need to call the update method to update all data attributes atom.X['MaxTemp'] = np.log(atom.X['MaxTemp']) # MaxTemp has now been changed for atom.X, but not in atom.X_train, atom.dataset, etc... # To do so, we use the update method... atom.update('X') assert atom.X['MaxTemp'].equals(atom.dataset['MaxTemp']) # Impute missing values atom.impute(strat_num='knn', strat_cat='remove', max_frac_rows=0.8) Imputing missing values... --> Removing 741 rows for containing too many missing values. --> Imputing 3 missing values using the KNN imputer in feature MinTemp. --> Imputing 4 missing values using the KNN imputer in feature MaxTemp. --> Imputing 43 missing values using the KNN imputer in feature Rainfall. --> Imputing 2315 missing values using the KNN imputer in feature Evaporation. --> Imputing 2661 missing values using the KNN imputer in feature Sunshine. --> Removing 222 rows due to missing values in feature WindGustDir. --> Imputing 221 missing values using the KNN imputer in feature WindGustSpeed. --> Removing 327 rows due to missing values in feature WindDir9am. --> Removing 24 rows due to missing values in feature WindDir3pm. --> Imputing 6 missing values using the KNN imputer in feature WindSpeed9am. --> Imputing 2 missing values using the KNN imputer in feature WindSpeed3pm. --> Imputing 25 missing values using the KNN imputer in feature Humidity9am. --> Imputing 55 missing values using the KNN imputer in feature Humidity3pm. --> Imputing 56 missing values using the KNN imputer in feature Pressure9am. --> Imputing 51 missing values using the KNN imputer in feature Pressure3pm. --> Imputing 2118 missing values using the KNN imputer in feature Cloud9am. --> Imputing 2253 missing values using the KNN imputer in feature Cloud3pm. --> Imputing 5 missing values using the KNN imputer in feature Temp9am. --> Imputing 32 missing values using the KNN imputer in feature Temp3pm. --> Removing 43 rows due to missing values in feature RainToday. # Encode the categorical features atom.encode(max_onehot=10, frac_to_other=0.04) Encoding categorical features... --> Target-encoding feature Location. Contains 1 unique categories. --> Target-encoding feature WindGustDir. Contains 16 unique categories. --> Target-encoding feature WindDir9am. Contains 16 unique categories. --> Target-encoding feature WindDir3pm. Contains 16 unique categories. --> Label-encoding feature RainToday. Contains 2 unique categories. # Perform undersampling of the majority class to balance the dataset atom.balance(undersample=0.8) Performing undersampling... --> Removing 249 rows from class No. # Remove outliers from the training set atom.outliers(max_sigma=5) Handling outliers... --> Dropping 18 rows due to outliers. # Select only the best 10 features atom.feature_selection(strategy=\"univariate\", max_features=15, max_correlation=0.8) # See which features were removed due to collinearity atom.collinear Performing feature selection... --> Feature Location was removed due to low variance: 0.00. --> Feature Pressure3pm was removed due to collinearity with another feature. --> Feature Temp9am was removed due to collinearity with another feature. --> Feature Temp3pm was removed due to collinearity with another feature. --> Feature MinTemp was removed after the univariate test (score: 9.36 p-value: 0.00). --> Feature Evaporation was removed after the univariate test (score: 27.00 p-value: 0.00). .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } drop_feature correlated_feature correlation_value 0 Pressure3pm Pressure9am 0.95413 1 Temp9am MinTemp, MaxTemp 0.9201, 0.89643 2 Temp3pm MaxTemp, Temp9am 0.9587, 0.87527 # Change the verbosity of ATOM to not print too much details while fitting atom.verbose = 2 # Let's use a custom metric def f2_score(y_true, y_pred): return fbeta_score(y_true, y_pred, beta=2) # Let's compare the performance of various gradient boosting algorithms atom.pipeline(['gbm', 'lgb', 'catb'], metric=f2_score, max_iter=5, init_points=5, cv=1, bagging=5) Running pipeline =================> Models in pipeline: GBM, LGB, CatB Metric: f2_score Running BO for Gradient Boosting Machine... Final results for Gradient Boosting Machine: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 414, 'learning_rate': 1.0, 'subsample': 0.5, 'max_depth': 2, 'max_features': 0.8, 'criterion': 'mse', 'min_samples_split': 12, 'min_samples_leaf': 1, 'ccp_alpha': 0.0} Best score on the BO: 0.7485 Time elapsed: 37.958s Fitting ----------------------------------------- Score on the training set: 0.8465 Score on the test set: 0.5824 Time elapsed: 0.796s Bagging ----------------------------------------- Mean: 0.5587 Std: 0.0105 Time elapsed: 3.562s ------------------------------------------------- Total time: 42.316s Running BO for LightGBM... Final results for LightGBM: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 345, 'learning_rate': 0.6, 'max_depth': 3, 'num_leaves': 24, 'min_child_weight': 9, 'min_child_samples': 17, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 0.0, 'reg_lambda': 0.1} Best score on the BO: 0.7583 Time elapsed: 3.261s Fitting ----------------------------------------- Score on the training set: 0.9937 Score on the test set: 0.6182 Time elapsed: 0.187s Bagging ----------------------------------------- Mean: 0.6169 Std: 0.0197 Time elapsed: 0.370s ------------------------------------------------- Total time: 3.819s Running BO for CatBoost... Final results for CatBoost: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 499, 'learning_rate': 0.09, 'max_depth': 9, 'subsample': 0.7, 'colsample_bylevel': 0.8, 'reg_lambda': 100.0} Best score on the BO: 0.7714 Time elapsed: 14.712s Fitting ----------------------------------------- Score on the training set: 0.9390 Score on the test set: 0.6365 Time elapsed: 3.890s Bagging ----------------------------------------- Mean: 0.6374 Std: 0.0083 Time elapsed: 19.245s ------------------------------------------------- Total time: 37.847s Final results ================>> Duration: 1m:23s Metric: f2_score -------------------------------- Gradient Boosting Machine --> 0.559 \u00b1 0.010 ~ LightGBM --> 0.617 \u00b1 0.020 ~ CatBoost --> 0.637 \u00b1 0.008 !! ~ Analyze the results # Let's have a look at the best model print('And the winner is...', atom.winner.longname) print('Score on the training set: ', atom.winner.score_train) print('Score on the test set: ', atom.winner.score_test) And the winner is... CatBoost Score on the training set: 0.9390495867768595 Score on the test set: 0.6364787840405319 # Make some plots to analyze the results atom.winner.plot_confusion_matrix(normalize=True, figsize=(7, 7), filename='confusion_matrix.png') atom.winner.plot_probabilities() # Change plots aesthetics ATOMClassifier.set_style('whitegrid') ATOMClassifier.set_title_fontsize(24) atom.plot_ROC(models=('LGB', 'CatB'), title=\"ROC for the LightGBM vs CatBoost model\") atom.plot_PRC(title=\"PRC comparison of the models\") atom.catb.plot_threshold(metric=['f1', 'accuracy', 'average_precision'], steps=50, filename='thresholds.png')","title":"Binary classification"},{"location":"examples/#multiclass-classification","text":"Import the wine dataset from sklearn.datasets . This is a small and easy to train dataset which goal is to classify wines into three groups (which cultivator it's from) using features based on the results of chemical analysis. Load the data # Import packages import numpy as np import pandas as pd from sklearn.datasets load_wine from atom.atom import ATOMClassifier # Load the dataset's features and targets dataset = load_wine() # Convert to pd.DtaFrame to get the names of the features data = np.c_[dataset.data, dataset.target] columns = np.append(dataset.feature_names, [\"target\"]) data = pd.DataFrame(data, columns=columns) X = data.drop('target', axis=1) y = data['target'] Run the pipeline # Call ATOMclass for ML task exploration atom = ATOMClassifier(X, y, n_jobs=-1, verbose=3) # Fit the pipeline with the selected models atom.pipeline(models=['LDA','RF', 'lSVM'], metric='f1_macro', max_iter=4, init_points=3, cv=3, bagging=10) <<=============== ATOM ===============>> Parallel processing with 4 cores. Initial data cleaning... Algorithm task: multiclass classification. Number of classes: 3. Dataset stats ===================> Shape: (178, 14) Scaled: False ---------------------------------- Size of training set: 124 Size of test set: 54 ---------------------------------- Instances in target per class: | | total | train_set | test_set | |---:|---------:|-------------:|------------:| | 0 | 59 | 42 | 17 | | 1 | 71 | 47 | 24 | | 2 | 48 | 35 | 13 | Running pipeline =================> Models in pipeline: LDA, RF, lSVM Metric: f1_macro Running BO for Linear Discriminant Analysis... Initial point: 1 -------------------------------- Parameters --> {'solver': 'lsqr', 'shrinkage': 0.9} Evaluation --> f1_macro: 0.6787 Time elapsed: 0.815s Total time: 0.816s Initial point: 2 -------------------------------- Parameters --> {'solver': 'lsqr', 'shrinkage': 0.8} Evaluation --> f1_macro: 0.6865 Time elapsed: 0.505s Total time: 1.320s Initial point: 3 -------------------------------- Parameters --> {'solver': 'eigen', 'shrinkage': 0.7} Evaluation --> f1_macro: 0.6667 Time elapsed: 0.021s Total time: 1.341s Iteration: 1 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9753 Time elapsed: 0.020s Total time: 1.560s Iteration: 2 ------------------------------------ Parameters --> {'solver': 'svd'} Evaluation --> f1_macro: 0.9753 Time elapsed: 0.026s Total time: 1.796s Final results for Linear Discriminant Analysis: Bayesian Optimization --------------------------- Best hyperparameters: {'solver': 'svd'} Best score on the BO: 0.9753 Time elapsed: 1.936s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 0.9617 Time elapsed: 0.079s Bagging ----------------------------------------- Mean: 0.9788 Std: 0.0159 Time elapsed: 0.035s ------------------------------------------------- Total time: 2.050s Running BO for Random Forest... Initial point: 1 -------------------------------- Parameters --> {'n_estimators': 460, 'max_depth': 5, 'max_features': 0.9, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 20, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.7} Evaluation --> f1_macro: 0.8673 Time elapsed: 0.835s Total time: 0.836s Initial point: 2 -------------------------------- Parameters --> {'n_estimators': 210, 'max_depth': 6, 'max_features': 0.5, 'criterion': 'entropy', 'min_samples_split': 11, 'min_samples_leaf': 14, 'ccp_alpha': 0.025, 'bootstrap': False} Evaluation --> f1_macro: 0.9357 Time elapsed: 0.449s Total time: 1.286s Initial point: 3 -------------------------------- Parameters --> {'n_estimators': 155, 'max_depth': 7, 'max_features': 0.7, 'criterion': 'entropy', 'min_samples_split': 18, 'min_samples_leaf': 13, 'ccp_alpha': 0.02, 'bootstrap': False} Evaluation --> f1_macro: 0.8638 Time elapsed: 0.405s Total time: 1.691s Iteration: 1 ------------------------------------ Parameters --> {'n_estimators': 460, 'max_depth': 6, 'max_features': 0.9, 'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 20, 'ccp_alpha': 0.035, 'bootstrap': True, 'max_samples': 0.7} Evaluation --> f1_macro: 0.9073 Time elapsed: 0.827s Total time: 2.801s Iteration: 2 ------------------------------------ Parameters --> {'n_estimators': 20, 'max_depth': 3, 'max_features': 0.7, 'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 18, 'ccp_alpha': 0.015, 'bootstrap': False} Evaluation --> f1_macro: 0.8953 Time elapsed: 0.234s Total time: 3.362s Iteration: 3 ------------------------------------ Parameters --> {'n_estimators': 20, 'max_depth': 8, 'max_features': 0.6, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 3, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.6} Evaluation --> f1_macro: 0.9512 Time elapsed: 0.231s Total time: 3.822s Iteration: 4 ------------------------------------ Parameters --> {'n_estimators': 20, 'max_depth': 9, 'max_features': 1.0, 'criterion': 'entropy', 'min_samples_split': 20, 'min_samples_leaf': 7, 'ccp_alpha': 0.02, 'bootstrap': False} Evaluation --> f1_macro: 0.8560 Time elapsed: 0.235s Total time: 4.563s Final results for Random Forest: Bayesian Optimization --------------------------- Best hyperparameters: {'n_estimators': 20, 'max_depth': 8, 'max_features': 0.6, 'criterion': 'entropy', 'min_samples_split': 14, 'min_samples_leaf': 3, 'ccp_alpha': 0.03, 'bootstrap': True, 'max_samples': 0.6} Best score on the BO: 0.9512 Time elapsed: 4.790s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 0.9448 Time elapsed: 5.671s Bagging ----------------------------------------- Mean: 0.9240 Std: 0.0274 Time elapsed: 2.345s ------------------------------------------------- Total time: 12.806s Running BO for Linear SVM... Initial point: 1 -------------------------------- Parameters --> {'C': 0.01, 'loss': 'squared_hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9833 Time elapsed: 0.031s Total time: 0.031s Initial point: 2 -------------------------------- Parameters --> {'C': 0.001, 'loss': 'hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9290 Time elapsed: 0.016s Total time: 0.047s Initial point: 3 -------------------------------- Parameters --> {'C': 0.001, 'loss': 'squared_hinge', 'dual': True, 'penalty': 'l2'} Evaluation --> f1_macro: 0.9601 Time elapsed: 0.031s Total time: 0.078s Iteration: 1 ------------------------------------ Parameters --> {'C': 10, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9842 Time elapsed: 0.028s Total time: 0.359s Iteration: 2 ------------------------------------ Parameters --> {'C': 100, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9842 Time elapsed: 0.025s Total time: 0.730s Iteration: 3 ------------------------------------ Parameters --> {'C': 100, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Evaluation --> f1_macro: 0.9842 Time elapsed: 0.016s Total time: 1.059s Final results for Linear SVM: Bayesian Optimization --------------------------- Best hyperparameters: {'C': 10.0, 'loss': 'squared_hinge', 'dual': False, 'penalty': 'l1'} Best score on the BO: 0.9842 Time elapsed: 1.230s Fitting ----------------------------------------- Score on the training set: 1.0000 Score on the test set: 0.9617 Time elapsed: 0.047s Bagging ----------------------------------------- Mean: 0.9498 Std: 0.0117 Time elapsed: 0.101s ------------------------------------------------- Total time: 1.379s Final results ================>> Duration: 16.238s Metric: f1_macro -------------------------------- Linear Discriminant Analysis --> 0.979 \u00b1 0.016 !! Random Forest --> 0.924 \u00b1 0.027 Linear SVM --> 0.950 \u00b1 0.012 Analyze the results atom.scores .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } model total_time score_train score_test fit_time bagging_mean bagging_std bagging_time 0 LDA 2.050s 1.0 0.961698 0.079s 0.978848 0.015898 0.035s 1 RF 12.806s 1.0 0.944813 5.671s 0.923975 0.027393 2.345s 2 lSVM 1.379s 1.0 0.961698 0.047s 0.949818 0.011717 0.101s # Show the results for a different metric atom.results('precision_macro') Final results ================>> Metric: precision_macro -------------------------------- Linear Discriminant Analysis --> 0.956 !! Random Forest --> 0.941 Linear SVM --> 0.956 !! atom.plot_bagging() Let's have a closer look at the Random Forest # Get the results on some other metrics print('Jaccard score:', atom.rf.jaccard_weighted) print('Recall score:', atom.rf.recall_macro) Jaccard score: 0.8960493827160495 Recall score: 0.9526143790849674 # Plot the feature importance and compare it to the permutation importance of the LDA atom.rf.plot_feature_importance(show=10) atom.lda.plot_permutation_importance(show=10) # Save the random forest class for production atom.RF.save('Random_Forest_class') Random Forest model subclass saved successfully!","title":"Multiclass classification"},{"location":"examples/#regression","text":"Download the abalone dataset from https://archive.ics.uci.edu/ml/datasets/Abalone . The goal of this dataset is to predict the age of abalone shells from physical measurements. Load the data # Import packages import pandas as pd from atom import ATOMRegressor # Load the abalone dataset X = pd.read_csv('../abalone.csv') atom = ATOMRegressor(X, y=\"Rings\", percentage=10, warnings=False, verbose=1, random_state=42) # Encode categorical features atom.encode() # Apply PCA for dimensionality reduction atom.feature_selection(strategy=\"pca\", max_features=6) atom.plot_PCA(figsize=(8, 6), filename='atom_PCA_plot') <<=============== ATOM ===============>> Algorithm task: regression. Run the pipeline # Let's compare tree-based models using a successive halving approach atom.pipeline(['tree', 'bag', 'et', 'rf', 'gbm', 'lgb'], successive_halving=True, metric='neg_mean_squared_error', max_iter=5, init_points=5, cv=1, bagging=5) Running pipeline =================> Metric: neg_mean_squared_error <<=============== Iteration 0 ==============>> Models in pipeline: Tree, Bag, ET, RF, GBM, LGB Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:25<00:00, 4.18s/it] Final results ================>> Duration: 25.079s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -9.479 \u00b1 0.667 !! ~ Bagging Regressor --> -11.409 \u00b1 2.167 ~ Extra-Trees --> -11.788 \u00b1 1.270 ~ Random Forest --> -11.441 \u00b1 1.059 ~ Gradient Boosting Machine --> -11.044 \u00b1 2.575 ~ LightGBM --> -12.929 \u00b1 3.211 ~ <<=============== Iteration 1 ==============>> Models in pipeline: Tree, Bag, GBM Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:12<00:00, 4.03s/it] Final results ================>> Duration: 37.229s Metric: neg_mean_squared_error -------------------------------- Decision Tree --> -11.110 \u00b1 5.487 ~ Bagging Regressor --> -6.780 \u00b1 1.605 !! ~ Gradient Boosting Machine --> -8.079 \u00b1 0.545 ~ <<=============== Iteration 2 ==============>> Model in pipeline: Bag Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:10<00:00, 10.36s/it] Final results ================>> Duration: 47.619s Metric: neg_mean_squared_error -------------------------------- Bagging Regressor --> -4.925 \u00b1 0.403 ~ Analyze the results # Plot successive halving results atom.plot_successive_halving()","title":"Regression"},{"location":"getting_started/","text":"Installation Intall ATOM easily using pip . pip install atom-ml Note Since atom was already taken, the name of the package in pypi is atom-ml ! Usage Call the ATOMClassifier or ATOMRegressor class and provide the data you want to use: from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y) atom = ATOMClassifier(X, y, log='auto', n_jobs=2, verbose=2) ATOM has multiple data cleaning methods to help you prepare the data for modelling: atom.impute(strat_num='knn', strat_cat='most_frequent', max_frac_rows=0.1) atom.encode(max_onehot=10, frac_to_other=0.05) atom.outliers(max_sigma=4) atom.balance(oversample=0.8, n_neighbors=15) atom.feature_selection(strategy='univariate', solver='chi2', max_features=0.9) Run the pipeline with different models: atom.pipeline(models=['LR', 'LDA', 'XGB', 'lSVM'], metric='f1', max_iter=10, max_time=1000, init_points=3, cv=4, bagging=10) Make plots and analyze results: atom.plot_bagging(filename='bagging_results.png') atom.lSVM.plot_probabilities(figsize=(9, 6)) atom.lda.plot_confusion_matrix(normalize=True)","title":"Getting started"},{"location":"getting_started/#installation","text":"Intall ATOM easily using pip . pip install atom-ml Note Since atom was already taken, the name of the package in pypi is atom-ml !","title":"Installation"},{"location":"getting_started/#usage","text":"Call the ATOMClassifier or ATOMRegressor class and provide the data you want to use: from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y) atom = ATOMClassifier(X, y, log='auto', n_jobs=2, verbose=2) ATOM has multiple data cleaning methods to help you prepare the data for modelling: atom.impute(strat_num='knn', strat_cat='most_frequent', max_frac_rows=0.1) atom.encode(max_onehot=10, frac_to_other=0.05) atom.outliers(max_sigma=4) atom.balance(oversample=0.8, n_neighbors=15) atom.feature_selection(strategy='univariate', solver='chi2', max_features=0.9) Run the pipeline with different models: atom.pipeline(models=['LR', 'LDA', 'XGB', 'lSVM'], metric='f1', max_iter=10, max_time=1000, init_points=3, cv=4, bagging=10) Make plots and analyze results: atom.plot_bagging(filename='bagging_results.png') atom.lSVM.plot_probabilities(figsize=(9, 6)) atom.lda.plot_confusion_matrix(normalize=True)","title":"Usage"},{"location":"license/","text":"MIT License Copyright (c) 2020 tvdboom Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#mit-license","text":"Copyright (c) 2020 tvdboom Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"}]}