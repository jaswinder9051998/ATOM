{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Automated Tool for Optimized Modelling There is no magic formula in data science that can tell us which type of machine learning algorithm will perform best for a specific use-case. Different models are better suited for different types of data and different problems. At best, you can follow some rough guide on how to approach problems with regard to which model to try on your data, but these are often more confusing than helpful. Best practices tell us to start with a simple model (e.g. linear regression) and build up to more complicated models (e.g. logistic regression -> random forest -> multi-layer perceptron) if you are not satisfied with the results. Unfortunately, different models require different data cleaning steps, different type/amount of features, tuning a new set of hyperparameters, etc. Refactoring the code for this purpose can be quite boring and time consuming. Because of this, many data scientists end up just using the model best known to them and fine-tuning this particular model without ever trying different ones. This can result in poor performance (because the model is just not the right one for the task) or in poor time management (because you could have achieved a similar performance with a simpler/faster model). ATOM is here to help us solve these issues. With just a few lines of code, you can perform basic data cleaning steps, select relevant features and compare the performance of multiple models on a given dataset. ATOM should be able to provide quick insights on which algorithms perform best for the task at hand and provide an indication of the feasibility of the ML solution. It is important to realize that ATOM is not here to replace all the work a data scientist has to do before getting his model into production. ATOM doesn't spit out production-ready models just by tuning some parameters in its API. After helping you to determine the right model, you will most probably need to fine-tune it using use-case specific features and data cleaning steps in order to achieve maximum performance. So, this sounds a bit like AutoML, how is ATOM different than auto-sklearn or TPOT ? Well, ATOM does AutoML in the sense that it helps you find the best model for a specific task, but contrary to the aforementioned packages, it does not actively search for the best model. It simply runs all of them and let you pick the one that you think suites you best. AutoML packages are often black boxes: if you provide data, it will magically return a working model. Although it works great, they often produce complicated pipelines with low explainability, hard to sell to the business. In this, ATOM excels. Every step of the pipeline is accounted for, and using the provided plotting methods, it\u2019s easy to demonstrate why a model is better/worse than the other. Note A data scientist with domain knowledge can outperform ATOM if he applies usecase-specific feature engineering or data cleaning steps! Example steps taken by ATOM's pipeline: Data Cleaning Handle missing values Encode categorical features Remove outliers Balance the dataset Feature engineering Create new non-linear features Remove multi-collinear features Remove features with too low variance Select the most promising features based on a statistical test Train and validate multiple models Select hyperparameters using a Bayesian Optimization approach Train and test the models on the provided data Perform bagging to assess the robustness of the output Analyze the results Get the model scores on various metrics Make plots to compare the model performances Release history Version 4.2.0 Possibility to add custom models to the pipeline using ATOMModel . Compatibility with deep learning models. New get_class_weight utility method. Added the sample_weight parameter to the score method. New ways to initialize the data in the training instances. The n_rows parameter in ATOMLoader is deprecated in favour of the new data input formats. The test_size parameter now also allows integer values. Renamed categories to classes to be consistent with sklearn's API. The class property now returns a pd.DataFrame of the number of rows per target class in the train, test and complete dataset. Possibility to add custom parameters to an estimator's fit method through est_params . Successive halving and Train sizing now both allow subsequent runs from atom without losing previous information. Bug fix where ATOMLoader wouldn't encode the target column during transformation. Added the Utilities and Deep learning example notebooks. Compatibility with python 3.9 . Version 4.1.0 Added the est_params parameter to customize the parameters passed to every model's estimator. Following skopt's API, the n_random_starts parameter is deprecated in favour of n_initial_points . The Balancer class now allows you to use any of the strategies from imblearn . New utility attributes to inspect the dataset. Four new models: CatNB , CNB , ARD and RNN . Added the models section to the documentation. Small changes in log outputs. Bug fixes and performance improvements. Version 4.0.1 Bug fix where the DFS strategy in FeatureGenerator was not deterministic for a fixed random state. Bug fix where subsequent runs with the same metric failed. Added the license file to the package's installer. Typo fixes in documentation. Version 4.0.0 Bayesian optimization package changed from GpyOpt to skopt . Complete revision of the model's hyperparameters. Four SHAP plots can now be called directly from an ATOM pipeline. Two new plots for regression tasks. New plot_pipeline and pipeline attribute to access all transformers. Possibility to determine transformer parameters per method. New calibration method and plot . Metrics can now be added as scorers or functions with signature metric(y, y_pred, **kwargs). Implementation of multi-metric runs. Possibility to choose which metric to plot. Early stopping for models that allow in-training evaluation. Added the ATOMLoader function to load saved atom instances and directly apply all data transformations. The \"remove\" strategy in the data cleaning parameters is deprecated in favour of \"drop\". Implemented the DFS strategy in FeatureGenerator . All training classes now inherit from BaseEstimator. Added multiple new example notebooks. Tests coverage up to 100%. Completely new documentation page. Bug fixes and performance improvements.","title":"Home"},{"location":"#automated-tool-for-optimized-modelling","text":"There is no magic formula in data science that can tell us which type of machine learning algorithm will perform best for a specific use-case. Different models are better suited for different types of data and different problems. At best, you can follow some rough guide on how to approach problems with regard to which model to try on your data, but these are often more confusing than helpful. Best practices tell us to start with a simple model (e.g. linear regression) and build up to more complicated models (e.g. logistic regression -> random forest -> multi-layer perceptron) if you are not satisfied with the results. Unfortunately, different models require different data cleaning steps, different type/amount of features, tuning a new set of hyperparameters, etc. Refactoring the code for this purpose can be quite boring and time consuming. Because of this, many data scientists end up just using the model best known to them and fine-tuning this particular model without ever trying different ones. This can result in poor performance (because the model is just not the right one for the task) or in poor time management (because you could have achieved a similar performance with a simpler/faster model). ATOM is here to help us solve these issues. With just a few lines of code, you can perform basic data cleaning steps, select relevant features and compare the performance of multiple models on a given dataset. ATOM should be able to provide quick insights on which algorithms perform best for the task at hand and provide an indication of the feasibility of the ML solution. It is important to realize that ATOM is not here to replace all the work a data scientist has to do before getting his model into production. ATOM doesn't spit out production-ready models just by tuning some parameters in its API. After helping you to determine the right model, you will most probably need to fine-tune it using use-case specific features and data cleaning steps in order to achieve maximum performance. So, this sounds a bit like AutoML, how is ATOM different than auto-sklearn or TPOT ? Well, ATOM does AutoML in the sense that it helps you find the best model for a specific task, but contrary to the aforementioned packages, it does not actively search for the best model. It simply runs all of them and let you pick the one that you think suites you best. AutoML packages are often black boxes: if you provide data, it will magically return a working model. Although it works great, they often produce complicated pipelines with low explainability, hard to sell to the business. In this, ATOM excels. Every step of the pipeline is accounted for, and using the provided plotting methods, it\u2019s easy to demonstrate why a model is better/worse than the other. Note A data scientist with domain knowledge can outperform ATOM if he applies usecase-specific feature engineering or data cleaning steps! Example steps taken by ATOM's pipeline: Data Cleaning Handle missing values Encode categorical features Remove outliers Balance the dataset Feature engineering Create new non-linear features Remove multi-collinear features Remove features with too low variance Select the most promising features based on a statistical test Train and validate multiple models Select hyperparameters using a Bayesian Optimization approach Train and test the models on the provided data Perform bagging to assess the robustness of the output Analyze the results Get the model scores on various metrics Make plots to compare the model performances","title":"Automated Tool for Optimized Modelling"},{"location":"#release-history","text":"","title":"Release history"},{"location":"#version-420","text":"Possibility to add custom models to the pipeline using ATOMModel . Compatibility with deep learning models. New get_class_weight utility method. Added the sample_weight parameter to the score method. New ways to initialize the data in the training instances. The n_rows parameter in ATOMLoader is deprecated in favour of the new data input formats. The test_size parameter now also allows integer values. Renamed categories to classes to be consistent with sklearn's API. The class property now returns a pd.DataFrame of the number of rows per target class in the train, test and complete dataset. Possibility to add custom parameters to an estimator's fit method through est_params . Successive halving and Train sizing now both allow subsequent runs from atom without losing previous information. Bug fix where ATOMLoader wouldn't encode the target column during transformation. Added the Utilities and Deep learning example notebooks. Compatibility with python 3.9 .","title":"Version 4.2.0"},{"location":"#version-410","text":"Added the est_params parameter to customize the parameters passed to every model's estimator. Following skopt's API, the n_random_starts parameter is deprecated in favour of n_initial_points . The Balancer class now allows you to use any of the strategies from imblearn . New utility attributes to inspect the dataset. Four new models: CatNB , CNB , ARD and RNN . Added the models section to the documentation. Small changes in log outputs. Bug fixes and performance improvements.","title":"Version 4.1.0"},{"location":"#version-401","text":"Bug fix where the DFS strategy in FeatureGenerator was not deterministic for a fixed random state. Bug fix where subsequent runs with the same metric failed. Added the license file to the package's installer. Typo fixes in documentation.","title":"Version 4.0.1"},{"location":"#version-400","text":"Bayesian optimization package changed from GpyOpt to skopt . Complete revision of the model's hyperparameters. Four SHAP plots can now be called directly from an ATOM pipeline. Two new plots for regression tasks. New plot_pipeline and pipeline attribute to access all transformers. Possibility to determine transformer parameters per method. New calibration method and plot . Metrics can now be added as scorers or functions with signature metric(y, y_pred, **kwargs). Implementation of multi-metric runs. Possibility to choose which metric to plot. Early stopping for models that allow in-training evaluation. Added the ATOMLoader function to load saved atom instances and directly apply all data transformations. The \"remove\" strategy in the data cleaning parameters is deprecated in favour of \"drop\". Implemented the DFS strategy in FeatureGenerator . All training classes now inherit from BaseEstimator. Added multiple new example notebooks. Tests coverage up to 100%. Completely new documentation page. Bug fixes and performance improvements.","title":"Version 4.0.0"},{"location":"dependencies/","text":"Python As of the moment, ATOM supports Python 3.6 , 3.7 , 3.8 and 3.9 . Packages ATOM is built on top of several existing Python libraries. The required packages are necessary for it's correct functioning. Additionally, you can install some optional packages to use machine learning estimators not provided by sklearn. Required numpy (>=1.17.2) scipy (>=1.4.1) pandas (>=1.0.3) tqdm (>=4.35.0) joblib (>=0.16.0) typeguard (>=2.7.1) tabulate (>=0.8.6) scikit-learn (>=0.23.1) scikit-optimize (>=0.7.4) pandas-profiling (>=2.3.0) category-encoders (>=2.1.0) imbalanced-learn (>=0.5.0) featuretools (>=0.17.0) gplearn (>=0.4.1) matplotlib (>=3.3.0) seaborn (>=0.9.0) shap (>=0.36.0) Optional xgboost (>=0.90) lightgbm (>=2.3.0) catboost (>=0.19.1) Support ATOM recognizes the support from JetBrains by providing core project contributors with a set of developer tools free of charge.","title":"Dependencies"},{"location":"dependencies/#python","text":"As of the moment, ATOM supports Python 3.6 , 3.7 , 3.8 and 3.9 .","title":"Python"},{"location":"dependencies/#packages","text":"ATOM is built on top of several existing Python libraries. The required packages are necessary for it's correct functioning. Additionally, you can install some optional packages to use machine learning estimators not provided by sklearn.","title":"Packages"},{"location":"dependencies/#required","text":"numpy (>=1.17.2) scipy (>=1.4.1) pandas (>=1.0.3) tqdm (>=4.35.0) joblib (>=0.16.0) typeguard (>=2.7.1) tabulate (>=0.8.6) scikit-learn (>=0.23.1) scikit-optimize (>=0.7.4) pandas-profiling (>=2.3.0) category-encoders (>=2.1.0) imbalanced-learn (>=0.5.0) featuretools (>=0.17.0) gplearn (>=0.4.1) matplotlib (>=3.3.0) seaborn (>=0.9.0) shap (>=0.36.0)","title":"Required"},{"location":"dependencies/#optional","text":"xgboost (>=0.90) lightgbm (>=2.3.0) catboost (>=0.19.1)","title":"Optional"},{"location":"dependencies/#support","text":"ATOM recognizes the support from JetBrains by providing core project contributors with a set of developer tools free of charge.","title":"Support"},{"location":"getting_started/","text":"Installation Note Since atom was already taken, download the package under the name atom-ml ! Intall ATOM's newest release easily via pip : $ pip install -U atom-ml or via conda : $ conda install -c conda-forge atom-ml Usage Call the ATOMClassifier or ATOMRegressor class and provide the data you want to use: from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y) atom = ATOMClassifier(X, y, logger=\"auto\", n_jobs=2, verbose=2) ATOM has multiple data cleaning methods to help you prepare the data for modelling: atom.impute(strat_num=\"knn\", strat_cat=\"most_frequent\", min_frac_rows=0.1) atom.encode(strategy=\"Target\", max_onehot=8, frac_to_other=0.05) atom.feature_selection(strategy=\"PCA\", n_features=12) Train and evaluate the models you want to compare: atom.run( models=[\"LR\", \"LDA\", \"XGB\", \"lSVM\"], metric=\"f1\", n_calls=25, n_initial_points=10, bagging=4 ) Make plots to analyze the results: atom.plot_bagging(figsize=(9, 6), filename=\"bagging_results.png\") atom.LDA.plot_confusion_matrix(normalize=True, filename=\"cm.png\")","title":"Getting started"},{"location":"getting_started/#installation","text":"Note Since atom was already taken, download the package under the name atom-ml ! Intall ATOM's newest release easily via pip : $ pip install -U atom-ml or via conda : $ conda install -c conda-forge atom-ml","title":"Installation"},{"location":"getting_started/#usage","text":"Call the ATOMClassifier or ATOMRegressor class and provide the data you want to use: from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y) atom = ATOMClassifier(X, y, logger=\"auto\", n_jobs=2, verbose=2) ATOM has multiple data cleaning methods to help you prepare the data for modelling: atom.impute(strat_num=\"knn\", strat_cat=\"most_frequent\", min_frac_rows=0.1) atom.encode(strategy=\"Target\", max_onehot=8, frac_to_other=0.05) atom.feature_selection(strategy=\"PCA\", n_features=12) Train and evaluate the models you want to compare: atom.run( models=[\"LR\", \"LDA\", \"XGB\", \"lSVM\"], metric=\"f1\", n_calls=25, n_initial_points=10, bagging=4 ) Make plots to analyze the results: atom.plot_bagging(figsize=(9, 6), filename=\"bagging_results.png\") atom.LDA.plot_confusion_matrix(normalize=True, filename=\"cm.png\")","title":"Usage"},{"location":"license/","text":"MIT License Copyright (c) 2020 tvdboom Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#mit-license","text":"Copyright (c) 2020 tvdboom Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"user_guide/","text":"Introduction There is no magic formula in data science that can tell us which type of machine learning algorithm will perform best for a specific use-case. Different models are better suited for different types of data and different problems. At best, you can follow some rough guide on how to approach problems with regard to which model to try on your data, but these are often more confusing than helpful. Best practices tell us to start with a simple model (e.g. linear regression) and build up to more complicated models (e.g. logistic regression -> random forest -> multi-layer perceptron) if you are not satisfied with the results. Unfortunately, different models require different data cleaning steps, different type/amount of features, tuning a new set of hyperparameters, etc. Refactoring the code for this purpose can be quite boring and time consuming. Because of this, many data scientists end up just using the model best known to them and fine-tuning this particular model without ever trying different ones. This can result in poor performance (because the model is just not the right one for the task) or in poor time management (because you could have achieved a similar performance with a simpler/faster model). ATOM is here to help us solve these issues. With just a few lines of code, you can perform basic data cleaning steps, select relevant features and compare the performance of multiple models on a given dataset. ATOM should be able to provide quick insights on which algorithms perform best for the task at hand and provide an indication of the feasibility of the ML solution. It is important to realize that ATOM is not here to replace all the work a data scientist has to do before getting his model into production. ATOM doesn't spit out production-ready models just by tuning some parameters in its API. After helping you to determine the right model, you will most probably need to fine-tune it using use-case specific features and data cleaning steps in order to achieve maximum performance. So, this sounds a bit like AutoML, how is ATOM different than auto-sklearn or TPOT ? Well, ATOM does AutoML in the sense that it helps you find the best model for a specific task, but contrary to the aforementioned packages, it does not actively search for the best model. It simply runs all of them and let you pick the one that you think suites you best. AutoML packages are often black boxes: if you provide data, it will magically return a working model. Although it works great, they often produce complicated pipelines with low explainability, hard to sell to the business. In this, ATOM excels. Every step of the pipeline is accounted for, and using the provided plotting methods, it\u2019s easy to demonstrate why a model is better/worse than the other. Nomenclature In this documentation we will consistently use terms to refer to certain concepts related to the ATOM package. ATOM : Refers to this package. task : Refers to one of the three supervised machine learning approaches that ATOM supports: binary classification multiclass classification regression class : Refers to one of the unique values in a column, e.g. a binary classifier has 2 classes in the target column. array-like : One-dimensional array of variable type list, tuple, np.array or pd.Series. atom : Refers to an ATOMClassifier or ATOMRegressor instance (note that all examples use it as variable name for the instance). model : Refers to one of the model instances. pipeline : Refers to the collection of data cleaning, feature engineering and training steps performed by atom . missing values : Refers to the values in the missing attribute. categorical columns : Refers to all columns with dtype.kind not in ifu . estimator : Actual estimator corresponding to a model. Implemented by an external package. BO : Bayesian optimization algorithm used for hyperparameter optimization. training : Refers to an instance of one of the classes that train and evaluate the models. The classes are: ATOMClassifier ATOMRegressor TrainerClassifier TrainerRegressor SuccessiveHalvingClassifier SuccessiveHavingRegressor TrainSizingClassifier TrainSizingRegressor Note Note that atom instances are also training instances! First steps You can quickly install atom using pip or conda , see the installation guide . ATOM contains a variety of classes to perform data cleaning, feature engineering, model training and much more. The easiest way to use all these classes on the same dataset is through one of the main classes: ATOMClassifier for binary or multiclass classification tasks. ATOMRegressor for regression tasks. These two classes are convenient wrappers for all the possibilities this package provides. Like a Pipeline , they assemble several steps that can be cross-validated together while setting different parameters. There are some important differences with sklearn's API: atom is initialized with the data you want to manipulate. This data can be accessed at any moment through atom 's data attributes . The classes in ATOM's API are reached through atom 's methods. For example, calling the encode method, will initialize an Encoder instance, fit it on the training set and transform the whole dataset. The transformations are applied immediately after calling the method (there is no fit method). This approach gives the user a clearer overview and more control over every step in the pipeline. The pipeline does not have to end with an estimator. ATOM can be just for data cleaning or feature engineering purposes only. Let's get started with an example! First, initialize atom and provide it the data you want to use. You can either input a dataset and let ATOM split the train and test set or provide a train and test set already splitted. Note that if a dataframe is provided, the indices will be reset by atom . atom = ATOMClassifier(X, y, test_size=0.25) Apply data cleaning methods through the class. For example, calling the impute method will handle all missing values in the dataset. atom.impute(strat_num=\"median\", strat_cat=\"most_frequent\", min_frac_rows=0.1) Select the best hyperparameters and fit a Random Forest and AdaBoost model. atom.run([\"RF\", \"AdaB\"], metric=\"accuracy\", n_calls=25, n_initial_points=10) Analyze the results: atom.feature_importances(show=10, filename=\"feature_importance_plot\") atom.plot_prc(title=\"Precision-recall curve comparison plot\") Data cleaning More often than not, you need to do some data cleaning before fitting your dataset to a model. Usually, this involves importing different libraries and writing many lines of code. Since ATOM is all about fast exploration and experimentation, it provides various data cleaning classes to apply the most common transformations fast and easy. Scaling the feature set Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). The Scaler class scales data to mean=0 and std=1. It can be accessed from atom through the scale method. Standard data cleaning There are many data cleaning steps that are useful to perform on any dataset before modelling. These are general rules that apply almost on every use-case and every task. The Cleaner class is a convenient tool to apply such steps. It can be accessed from atom through the clean method. Use the class' parameters to choose which transformations to perform. The available steps are: Remove columns with prohibited data types. Strip categorical features from white spaces. Remove categorical columns with maximal cardinality. Remove columns with minimum cardinality. Remove rows with missing values in the target column. Encode the target column. Imputing missing values For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with ATOM's models which assume that all values in an array are numerical, and that all have and hold meaning. The Imputer class handles missing values in the dataset by either dropping or imputing the value. It can be accessed from atom through the impute method. Tip Use atom 's missing attribute for an overview of the missing values in the dataset. Encoding categorical features Many datasets will contain categorical features. Their variables are typically stored as text values which represent various traits. Some examples include color (\u201cRed\u201d, \u201cYellow\u201d, \u201cBlue\u201d), size (\u201cSmall\u201d, \u201cMedium\u201d, \u201cLarge\u201d) or geographic designations (city or country). Regardless of what the value is used for, the challenge is determining how to use this data in the analysis. ATOM's models don't support direct manipulation of this kind of data. Use the Encoder class to encode categorical features to numerical values. It can be accessed from atom through the encode method. Tip Use atom 's categorical attribute for a list of the categorical columns in the dataset. Handling outliers When modeling, it is important to clean the data sample to ensure that the observations best represent the problem. Sometimes a dataset can contain extreme values that are outside the range of what is expected and unlike the other data. These are called outliers. Often, machine learning modeling and model skill in general can be improved by understanding and even removing these outlier values. The Outliers class can drop or impute outliers in the dataset. It can be accessed from atom through the outliers method. Balancing the data One of the common issues found in datasets that are used for classification is imbalanced classes. Data imbalance usually reflects an unequal distribution of classes within a dataset. For example, in a credit card fraud detection dataset, most of the transactions are non-fraud and a very few cases are fraud. This leaves us with a very unbalanced ratio of fraud vs non-fraud cases. The Balancer class can oversample the minority class or undersample the majority class. It can be accessed from atom through the balance method. Feature engineering \"Applied machine learning\" is basically feature engineering. ~ Andrew Ng. Feature engineering is the process of creating new features from the existing ones, in order to capture relationships with the target column that the first set of features didn't had on their own. This process is very important to improve the performance of machine learning algorithms. Although feature engineering works best when the data scientist applies use-case specific transformations, there are ways to do this in an automated manner, without prior domain knowledge. One of the problems of creating new features without human expert intervention, is that many of the newly created features can be useless, i.e. they do not help the algorithm to make better predictions. Even worse, having useless features can drop your performance. To avoid this, we perform feature selection, a process in which we select the relevant features in the dataset. See here an example. Generating new features The FeatureGenerator class creates new non-linear features based on the original feature set. It can be accessed from atom through the feature_generation method. You can choose between two strategies: Deep Feature Synthesis and Genetic Feature Generation. Deep Feature Synthesis Deep feature synthesis (DFS) applies the selected operators on the features in the dataset. For example, if the operator is \"log\", it will create the new feature LOG(old_feature) and if the operator is \"mul\", it will create the new feature old_feature_1 x old_feature_2 . The operators can be chosen through the operators parameter. Available options are: add: Sum two features together. sub: Subtract two features from each other. mul: Multiply two features with each other. div: Divide two features with each other. srqt: Take the square root of a feature. log: Take the logarithm of a feature. sin: Calculate the sine of a feature. cos: Calculate the cosine of a feature. tan: Calculate the tangent of a feature. ATOM's implementation of DFS uses the featuretools package. Tip DFS can create many new features and not all of them will be useful. Use FeatureSelector to reduce the number of features! Warning Using the div, log or sqrt operators can return new features with inf or NaN values. Check the warnings that may pop up or use atom 's missing property. Warning When using DFS with n_jobs>1 , make sure to protect your code with if __name__ == \"__main__\" . Featuretools uses dask , which uses python multiprocessing for parallelization. The spawn method on multiprocessing starts a new python process, which requires it to import the __main__ module before it can do its task. Genetic Feature Generation Genetic feature generation (GFG) uses genetic programming , a branch of evolutionary programming, to determine which features are successful and create new ones based on those. Where DFS\" method can be seen as some kind of \"brute force\" for feature engineering, GFG tries to improve its features with every generation of the algorithm. GFG uses the same operators as DFS, but instead of only applying the transformations once, it evolves them further, creating complicated non-linear combinations of features with many transformations. The new features are given the name Feature N for the N-th feature. You can access the genetic feature's fitness and description (how they are calculated) through the genetic_features attribute. ATOM uses the SymbolicTransformer class from the gplearn package for the genetic algorithm. Read more about this implementation here . Warning GFG can be slow for very large populations! Selecting useful features The FeatureSelector class provides tooling to select the relevant features from a dataset. It can be accessed from atom through the feature_selection method. The following strategies are implemented: univariate, PCA, SFM, RFE and RFECV. Univariate Univariate feature selection works by selecting the best features based on univariate statistical F-test. The test is provided via the solver parameter. It takes any function taking two arrays (X, y), and returning arrays (scores, p-values). Read more in sklearn's documentation . Principal Components Analysis Applying PCA will reduce the dimensionality of the dataset by maximizing the variance of each dimension. The new features will be called Component 0, Component 1, etc... The dataset will be scaled before applying the transformation (if it wasn't already). Read more in sklearn's documentation . Selection from model SFM uses an estimator with feature_importances_ or coef_ attributes to select the best features in a dataset based on importance weights. The estimator is provided through the solver parameter and can be already fitted. ATOM allows you to use one its pre-defined models , e.g. solver=\"RF\" . If you didn't call the FeatureSelector through atom , don't forget to indicate the estimator's task adding _class or _reg after the name, e.g. RF_class to use a random forest classifier. Read more in sklearn's documentation . Recursive feature elimination Select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached. Note that, since RFE needs to fit the model again every iteration, this method can be fairly slow. RFECV applies the same algorithm as RFE but uses a cross-validated metric (under the scoring parameter, see RFECV ) to assess every step's performance. Also, where RFE returns the number of features selected by n_features , RFECV returns the number of features that achieved the optimal score on the specified metric. Note that this is not always equal to the amount specified by n_features . Read more in sklearn's documentation . Removing features with low variance Variance is the expectation of the squared deviation of a random variable from its mean. Features with low variance have many values repeated, which means the model will not learn much from them. FeatureSelector removes all features where the same value is repeated in at least max_frac_repeated fraction of the rows. The default option is to remove a feature if all values in it are the same. Read more in sklearn's documentation . Removing features with multi-collinearity Two features that are highly correlated are redundant, i.e. two will not contribute more to the model than only one of them. FeatureSelector will drop a feature that has a Pearson correlation coefficient larger than max_correlation with another feature. A correlation of 1 means the two columns are equal. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. Tip Use the plot_feature_importance method to examine how much a specific feature contributes to the final predictions. If the model doesn't have a feature_importances_ attribute, use plot_permutation_importance instead. Warning The RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs. Models Predefined models ATOM provides 31 models for classification and regression tasks that can be used to fit the data in the pipeline. After fitting, every model class is attached to the training instance as an attribute. We refer to these \"subclasses\" as models (see the nomenclature ). The classes contain a variety of attributes and methods to help you understand how the underlying estimator performed. They can be accessed using the models\" acronyms, e.g. atom.LGB to access the LightGBM's model . The available models and their corresponding acronyms are: \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Classification/Regression \"Lasso\" for Lasso Regression \"EN\" for Elastic Net \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost \"LGB\" for LightGBM \"CatB\" for CatBoost \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron Custom models It is also possible to use your own models in ATOM's pipeline. For example, imagine we want to use sklearn's Lars estimator (note that is not included in ATOM's predefined models ). There are two ways to achieve this: Using ATOMModel (recommended). With this approach you can pass the required model characteristics to the pipeline. from sklearn.linear_model import Lars from atom import ATOMRegressor, ATOMModel model = ATOMModel(models=Lars, fullname=\"Lars Regression\", needs_scaling=True, type=\"linear\") atom = ATOMRegressor(X, y) atom.run(model) Using the estimator's class or an instance of the class. This approach will also call ATOMModel under the hood, but it will leave its parameters to their default values. from sklearn.linear_model import Lars from atom import ATOMRegressor, ATOMModel atom = ATOMRegressor(X, y) atom.run(models=Lars) Additional things to take into account: Custom models are not restricted to sklearn estimators, but they should follow sklearn's API, i.e. have a fit and predict method. Parameter customization (for the initializer) is only possible for custom models which provide an estimator's class or an instance that has a set_params() method, i.e. its a child class of BaseEstimator . Hyperparameter optimization for custom models is ignored unless appropriate dimensions are provided through bo_params . If the estimator has a n_jobs and/or random_state parameter that is left to its default value, it will automatically adopt the values from the training instance it's called from. Deep learning Deep learning models can be used through ATOM's custom models as long as they follow sklearn's API. For example, models implemented with the Keras package should use the sklearn wrappers KerasClassifier and kerasRegressor . Many deep learning models, for example in computer vision and natural language processing, use datasets with more than 2 dimensions, e.g. image data can have shape (n_samples, length, width, rgb). These data structures are not intended to store in a 2 dimensional pandas dataframe. Since ATOM requires a dataframe as instance for the dataset, multidimensional data sets are stored in a single column called \"Features\" where every row contains one (multidimensional) sample. Click here for an example. Note that, because of this, the data cleaning , feature engineering and some of the plotting methods are unavailable for deep learning datasets. Tip You can also use lowercase to call the models , e.g. atom.lgb.plot_roc() . Warning The models should not be initialized by the user! Only use them through the training instances. Training The training phase is where the models are fitted and evaluated. After this, the models are attached to the training instance and you can use the plotting and predicting methods. The pipeline applies the following steps iteratively for all models: The optimal hyperparameters are selected. The model is trained on the training set and evaluated on the test set. The bagging algorithm is applied. There are three approaches to run the training. Direct training: TrainerClassifier TrainerRegressor Training via successive halving : SuccessiveHalvingClassifier SuccessiveHavingRegressor Training via train sizing : TrainSizingClassifier TrainSizingRegressor The direct fashion repeats the aforementioned steps only once, while the other two approaches repeats them more than once. Every approach can be directly called from atom through the run , successive_halving and train_sizing methods respectively. Every approach should be called from an independent instance of atom . Subsequent runs from different approaches will remove all information from previous trainings from the pipeline. You can, however, rerun the same approach multiple times. In that case, the results are combined. Note that if you rerun the same model, only the last model is saved. For example, here atom will \"forget\" the successive halving run. atom = ATOMClassifier(X, y) atom.successive_halving([\"Tree\", \"Bag\"]) atom.run(\"LGB\") In this case, both the Ridge and Lasso regressors are kept in the pipeline. atom = ATOMRegressor(X, y) atom.run(\"Ridge\") atom.run(\"Lasso\") Note Reruns are only allowed if the same metric is used. Leaving the metric parameter empty after the first run will automatically use the one in the pipeline. Additional things to take into account: Models are called through their acronyms , e.g. atom.run(models=\"RF\") will train a Random Forest. If an exception is encountered while fitting an estimator, the pipeline will automatically skip the model and jump to the next model and save the exception in the errors attribute. Note that in that case there will be no model for that estimator. When showing the final results, a ! indicates the highest score and a ~ indicates that the model is possibly overfitting (training set has a score at least 20% higher than the test set). The winning model (the one with the highest mean_bagging or metric_test ) will be attached to the winner attribute. Metric ATOM uses sklearn's scorers for model selection and evaluation. A scorer consists of a metric function and some parameters that define the scorer's properties such as it's a score or loss function or if the function needs probability estimates or rounded predictions (see make_scorer ). ATOM lets you define the scorer for the pipeline in three ways: The metric parameter is one of sklearn's predefined scorers (as string). The metric parameter is a score (or loss) function with signature metric(y, y_pred, **kwargs). In this case, use the greater_is_better , needs_proba and needs_threshold parameters to specify the scorer's properties. The metric parameter is a scorer object. Note that all scorers follow the convention that higher return values are better than lower return values. Thus metrics which measure the distance between the model and the data (i.e. loss functions), like max_error or mean_squared_error , will return the negated value of the metric. Custom scorer acronyms Since some of sklearn's scorers have quite long names and ATOM is all about lazy fast experimentation, the package provides acronyms for some of the most commonly used ones. These acronyms are case insensitive can be used for the metric parameter instead of the scorer's full name, e.g. atom.run(\"LR\", metric=\"BA\") will use balanced_accuracy . The available acronyms are: \"AP\" for \"average_precision\" \"BA\" for \"balanced_accuracy\" \"AUC\" for \"roc_auc\" \"EV\" for \"explained_variance\" \"ME\" for \"max_error\" \"MAE\" for \"neg_mean_absolute_error\" \"MSE\" for \"neg_mean_squared_error\" \"RMSE\" for \"neg_root_mean_squared_error\" \"MSLE\" for \"neg_mean_squared_log_error\" \"MEDAE\" for \"neg_median_absolute_error\" \"POISSON\" for \"neg_mean_poisson_deviance\" \"GAMMA\" for \"neg_mean_gamma_deviance\" Multi-metric runs Sometimes it is useful to measure the performance of the models in more than one way. ATOM lets you run the pipeline with multiple metrics at the same time. To do so, provide the metric parameter with a list of desired metrics, e.g. atom.run(\"LDA\", metric=[\"r2\", \"mse\"]) . If you provide metric functions, don't forget to also provide lists to the greater_is_better , needs_proba and needs_threshold parameters, where the n-th value in the list corresponds to the n-th function. If you leave them as a single value, that value will apply to every provided metric. When fitting multi-metric runs, the resulting scores will return a list of metrics. For example, if you provided three metrics to the pipeline, atom.knn.metric_bo could return [0.8734, 0.6672, 0.9001]. It is also important to note that only the first metric of a multi-metric run is used to evaluate every step of the bayesian optimization and to select the winning model. Tip Some plots let you choose which of the metrics to show using the metric parameter. Parameter customization By default, the parameters every estimator uses are the same default parameters they get from their respective packages. To select different ones, use est_params . There are two ways to add custom parameters to the models: adding them directly to the dictionary as key-value pairs or through multiple dicts with the model names as keys. Adding the parameters directly to est_params will share them across all models in the pipeline. In this example, both the XGBoost and the LightGBM model will use n_estimators=200. Make sure all the models do have the specified parameters or an exception will be raised! atom.run([\"XGB\", \"LGB\"], est_params={\"n_estimators\": 200}) To specify parameters per model, use the model name as key and a dict of the parameters as value. In this example, the XGBoost model will use n_estimators=200 and the Multi-layer Perceptron will use one hidden layer with 75 neurons. atom.run([\"XGB\", \"MLP\"], est_params={\"XGB\": {\"n_estimators\": 200}, \"MLP\": {\"hidden_layer_sizes\": (75,)}}) Some estimators allow you to pass extra parameters to the fit method (besides X and y). This can be done adding _fit at the end of the parameter. For example, to change XGBoost's verbosity, we can run: atom.run(\"XGB\", est_params={\"verbose_fit\": True} Note If a parameter is specified through est_params , it will be ignored by the bayesian optimization! Hyperparameter optimization In order to achieve maximum performance, we need to tune an estimator's hyperparameters before training it. ATOM provides hyperparameter tuning using a bayesian optimization (BO) approach implemented by skopt . The BO is optimized on the first metric provided with the metric parameter. Each step is either computed by cross-validation on the complete training set or by randomly splitting the training set every iteration into a (sub) training set and a validation set. This process can create some data leakage but ensures maximal use of the provided data. The test set, however, does not contain any leakage and will be used to determine the final score of every model. Note that, if the dataset is relatively small, the BO's best score can consistently be lower than the final score on the test set (despite the leakage) due to the considerable fewer instances on which it is trained. There are many possibilities to tune the BO to your liking. Use n_calls and n_initial_points to determine the number of iterations that are performed randomly at the start (exploration) and the number of iterations spent optimizing (exploitation). If n_calls is equal to n_initial_points , every iteration of the BO will select its hyperparameters randomly. This means the algorithm is technically performing a random search . Note The n_calls parameter includes the iterations in n_initial_points , i.e. calling atom.run(\"LR\", n_calls=20, n_intial_points=10) will run 20 iterations of which the first 10 are random. Note If n_initial_points=1 , the first trial will be equal to the estimator's default parameters. Other settings can be changed through the bo_params parameter, a dictionary where every key-value combination can be used to further customize the BO. By default, the hyperparameters and corresponding dimensions per model are predefined by ATOM. Use the dimensions key to use custom ones. Just like with est_params , you can share the same dimensions across models or use a dictionary with the model names as keys to specify the dimensions for every individual model. Note that the provided search space dimensions must be compliant with skopt's API. atom.run(\"LR\", n_calls=10, bo_params={\"dimensions\": [Integer(100, 1000, name=\"max_iter\")]}) The majority of skopt's callbacks to stop the optimizer early can be accessed through bo_params . You can include other callbacks using the callbacks key. atom.run(\"LR\", n_calls=10, bo_params={\"max_time\": 1000, \"callbacks\": custom_callback()}) You can also include other optimizer's parameters as key-value pairs. atom.run(\"LR\", n_calls=10, bo_params={\"acq_func\": \"EI\"}) Bagging After fitting the estimator, you can asses the robustness of the model using bootstrap aggregating (bagging). This technique creates several new data sets selecting random samples from the training set (with replacement) and evaluates them on the test set. This way we get a distribution of the performance of the model. The number of sets can be chosen through the bagging parameter. Tip Use the plot_bagging method to plot the bagging scores in a convenient boxplot. Early stopping XGBoost , LightGBM and CatBoost allow in-training evaluation. This means that the estimator is evaluated after every round of the training, and that the training is stopped early if it didn't improve in the last early_stopping rounds. This can save the pipeline much time that would otherwise be wasted on an estimator that is unlikely to improve further. Note that this technique will be applied both during the BO and at the final fit on the complete training set. There are two ways to apply early stopping on these models: Through the early_stopping key in bo_params . This approach applies early stopping to all models in the pipeline and allows the input of a fraction of the total number of rounds. Filling the early_stopping_rounds parameter directly in est_params . Don't forget to add _fit to the parameter to call it from the fit method. After fitting, the model will get the evals attribute, a dictionary of the train and test performances per round (also if early stopping wasn't applied). Click here for an example pipeline using early stopping. Tip Use the plot_evals method to plot the in-training evaluation on the train and test set. Repeating models If you want to fit the same model multiple times in a pipeline, add a tag after the acronym when calling the models. atom.run(models=[\"RF1\", \"RF2\"], est_params={\"RF1\": {\"n_estimators\": 100}, \"RF2\": {\"n_estimators\": 200}}) This pipeline will run two Random Forest models, one with 100 and the other with 200 decision trees. The models can be accessed through atom.rf1 and atom.rf2 . This can be useful to test how the same model performs with different parameters or different data sets. Successive halving Successive halving is a bandit-based algorithm that fits N models to 1/N of the data. The best half are selected to go to the next iteration where the process is repeated. This continues until only one model remains, which is fitted on the complete dataset. Beware that a model's performance can depend greatly on the amount of data on which it is trained. For this reason, we recommend only to use this technique with similar models, e.g. only using tree-based models. Use successive halving through the SuccessiveHalvingClassifier / SuccessiveHalvingRegressor classes or from atom via the successive_halving method. After running the pipeline, the results attribute will be multi-index, where the first index indicates the iteration and the second the model's acronym. Tip Use the plot_successive_halving method to see every model's performance per iteration of the successive halving. Train sizing When training models, there is usually a trade-off between model performance and computation time that is regulated by the number of samples in the training set. Train sizing can be used to create insights in this trade-off and help determine the optimal size of the training set, fitting the models multiple times, ever increasing the number of samples in the training set. Use train sizing through the TrainSizingClassifier / TrainSizingRegressor classes or from atom via the train_sizing method. The number of iterations and the number of samples per training can be specified with the train_sizes parameter. After running the pipeline, the results attribute will be multi-index, where the first index indicates the iteration and the second the model's acronym. Tip Use the plot_learning_curve method to see the model's performance per size of the training set. Predicting After running a successful pipeline, it is possible you would like to apply all used transformations onto new data, or make predictions using one of the trained models. Just like a sklearn estimator, you can call the prediction methods from a fitted training instance, e.g. atom.predict(X) . Calling the method without specifying a model will use the winning model in the pipeline (under attribute winner ). To use a different model, simply call the method from a model , e.g. atom.KNN.predict(X) . If called from atom , the prediction methods will transform the provided data through all the transformers in the pipeline before making the predictions. By default, this excludes outlier handling and balancing the dataset since these steps should only be applied on the training set. Use the method's kwargs to select which transformations to use in every call. The available prediction methods are a selection of the most common methods for estimators in sklearn's API: transform Transform new data through all the pre-processing steps in the pipeline. predict Transform the data and make predictions on new data. predict_proba Transform the data and make probabilistic predictions on new data. predict_log_proba Transform the data and make logarithmic probability predictions on new data. decision_function Transform the data and evaluate the decision function on new data. score Transform the data and return the model's score on new data. Except for transform, the prediction methods can be calculated on the train and test set. You can access them through the model 's prediction attributes, e.g. atom.mnb.predict_train or atom.mnb.predict_test . Keep in mind that the results are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Note Many of the plots use the prediction attributes. This can considerably increase the size of the class for large datasets. Use the reset_prediction_attributes method if you need to free some memory! Plots After fitting the models to the data, it's time to analyze the results. ATOM provides many plotting methods to compare the model performances. Descriptions and examples can be found in the API section. ATOM uses the packages matplotlib , seaborn and shap for plotting. The plot methods can be called from a training directly, e.g. atom.plot_roc() , or from one of the models , e.g. atom.LGB.plot_roc() . If called from training , it will make the plot for all models in the pipeline. This can be useful to compare the results of multiple models. If called from a model , it will make the plot for only that model. Use this option if you want information just for that specific model or to make a plot less crowded. Parameters Apart from the plot-specific parameters they may have, all plots have four parameters in common: The title parameter allows you to add a custom title to the plot. The figsize parameter adjust the plot's size. The filename parameter is used to save the plot. The display parameter determines whether the plot is rendered. Aesthetics The plot aesthetics can be customized using the plot attributes, e.g. atom.style = \"white\" . These attributes can be called from any instance with plotting methods. Note that the plot attributes are attached to the class and not the instance. This means that changing the attribute will also change it for all other instances in the module. ATOM's default values are: style: \"darkgrid\" palette: \"GnBu_r_d\" title_fontsize: 20 label_fontsize: 16 tick_fontsize: 12 SHAP The SHAP (SHapley Additive exPlanations) python package uses a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions. ATOM implements methods to plot 5 of shap's plotting functions directly from its API. The explainer will be chosen automatically based on the model's type. For kernelExplainer, the data used to estimate the expected values is the complete training set when <100 rows, else its summarized with a set of 10 weighted K-means, each weighted by the number of points they represent. The five plots are: force_plot , dependence_plot , summary_plot , decision_plot and waterfall_plot . Since the plots are not made by ATOM, we can't draw multiple models in the same figure. Selecting more than one model will raise an exception. To avoid this, call the plot from a model , e.g. atom.xgb.force_plot() . Note You can recognize the SHAP plots by the fact that they end (instead of start) with plot. Available plots A list of available plots can be find hereunder. Note that not all plots can be called from every class and that their availability can depend on the task at hand. plot_correlation Plot the data's correlation matrix. plot_pipeline Plot a diagram of every estimator in atom's pipeline. plot_pca Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per components. plot_rfecv Plot the RFECV results. plot_successive_halving Plot of the models\" scores per iteration of the successive halving. plot_learning_curve Plot the model's learning curve. plot_bagging Plot a boxplot of the bagging's results. plot_bo Plot the bayesian optimization scoring. plot_evals Plot evaluation curves for the train and test set. plot_roc Plot the Receiver Operating Characteristics curve. plot_prc Plot the precision-recall curve. plot_permutation_importance Plot the feature permutation importance of models. plot_feature_importance Plot a tree-based model's feature importance. plot_partial_dependence Plot the partial dependence of features. plot_errors Plot a model's prediction errors. plot_residuals Plot a model's residuals. plot_confusion_matrix Plot a model's confusion matrix. plot_threshold Plot metric performances against threshold values. plot_probabilities Plot the probability distribution of the classes in the target column. plot_calibration Plot the calibration curve for a binary classifier. plot_gains Plot the cumulative gains curve. plot_lift Plot the lift curve. force_plot Plot SHAP's force plot. dependence_plot Plot SHAP's dependence plot. summary_plot Plot SHAP's summary plot. decision_plot Plot SHAP's decision plot. waterfall_plot Plot SHAP's waterfall plot.","title":"User guide"},{"location":"user_guide/#introduction","text":"There is no magic formula in data science that can tell us which type of machine learning algorithm will perform best for a specific use-case. Different models are better suited for different types of data and different problems. At best, you can follow some rough guide on how to approach problems with regard to which model to try on your data, but these are often more confusing than helpful. Best practices tell us to start with a simple model (e.g. linear regression) and build up to more complicated models (e.g. logistic regression -> random forest -> multi-layer perceptron) if you are not satisfied with the results. Unfortunately, different models require different data cleaning steps, different type/amount of features, tuning a new set of hyperparameters, etc. Refactoring the code for this purpose can be quite boring and time consuming. Because of this, many data scientists end up just using the model best known to them and fine-tuning this particular model without ever trying different ones. This can result in poor performance (because the model is just not the right one for the task) or in poor time management (because you could have achieved a similar performance with a simpler/faster model). ATOM is here to help us solve these issues. With just a few lines of code, you can perform basic data cleaning steps, select relevant features and compare the performance of multiple models on a given dataset. ATOM should be able to provide quick insights on which algorithms perform best for the task at hand and provide an indication of the feasibility of the ML solution. It is important to realize that ATOM is not here to replace all the work a data scientist has to do before getting his model into production. ATOM doesn't spit out production-ready models just by tuning some parameters in its API. After helping you to determine the right model, you will most probably need to fine-tune it using use-case specific features and data cleaning steps in order to achieve maximum performance. So, this sounds a bit like AutoML, how is ATOM different than auto-sklearn or TPOT ? Well, ATOM does AutoML in the sense that it helps you find the best model for a specific task, but contrary to the aforementioned packages, it does not actively search for the best model. It simply runs all of them and let you pick the one that you think suites you best. AutoML packages are often black boxes: if you provide data, it will magically return a working model. Although it works great, they often produce complicated pipelines with low explainability, hard to sell to the business. In this, ATOM excels. Every step of the pipeline is accounted for, and using the provided plotting methods, it\u2019s easy to demonstrate why a model is better/worse than the other.","title":"Introduction"},{"location":"user_guide/#nomenclature","text":"In this documentation we will consistently use terms to refer to certain concepts related to the ATOM package. ATOM : Refers to this package. task : Refers to one of the three supervised machine learning approaches that ATOM supports: binary classification multiclass classification regression class : Refers to one of the unique values in a column, e.g. a binary classifier has 2 classes in the target column. array-like : One-dimensional array of variable type list, tuple, np.array or pd.Series. atom : Refers to an ATOMClassifier or ATOMRegressor instance (note that all examples use it as variable name for the instance). model : Refers to one of the model instances. pipeline : Refers to the collection of data cleaning, feature engineering and training steps performed by atom . missing values : Refers to the values in the missing attribute. categorical columns : Refers to all columns with dtype.kind not in ifu . estimator : Actual estimator corresponding to a model. Implemented by an external package. BO : Bayesian optimization algorithm used for hyperparameter optimization. training : Refers to an instance of one of the classes that train and evaluate the models. The classes are: ATOMClassifier ATOMRegressor TrainerClassifier TrainerRegressor SuccessiveHalvingClassifier SuccessiveHavingRegressor TrainSizingClassifier TrainSizingRegressor Note Note that atom instances are also training instances!","title":"Nomenclature"},{"location":"user_guide/#first-steps","text":"You can quickly install atom using pip or conda , see the installation guide . ATOM contains a variety of classes to perform data cleaning, feature engineering, model training and much more. The easiest way to use all these classes on the same dataset is through one of the main classes: ATOMClassifier for binary or multiclass classification tasks. ATOMRegressor for regression tasks. These two classes are convenient wrappers for all the possibilities this package provides. Like a Pipeline , they assemble several steps that can be cross-validated together while setting different parameters. There are some important differences with sklearn's API: atom is initialized with the data you want to manipulate. This data can be accessed at any moment through atom 's data attributes . The classes in ATOM's API are reached through atom 's methods. For example, calling the encode method, will initialize an Encoder instance, fit it on the training set and transform the whole dataset. The transformations are applied immediately after calling the method (there is no fit method). This approach gives the user a clearer overview and more control over every step in the pipeline. The pipeline does not have to end with an estimator. ATOM can be just for data cleaning or feature engineering purposes only. Let's get started with an example! First, initialize atom and provide it the data you want to use. You can either input a dataset and let ATOM split the train and test set or provide a train and test set already splitted. Note that if a dataframe is provided, the indices will be reset by atom . atom = ATOMClassifier(X, y, test_size=0.25) Apply data cleaning methods through the class. For example, calling the impute method will handle all missing values in the dataset. atom.impute(strat_num=\"median\", strat_cat=\"most_frequent\", min_frac_rows=0.1) Select the best hyperparameters and fit a Random Forest and AdaBoost model. atom.run([\"RF\", \"AdaB\"], metric=\"accuracy\", n_calls=25, n_initial_points=10) Analyze the results: atom.feature_importances(show=10, filename=\"feature_importance_plot\") atom.plot_prc(title=\"Precision-recall curve comparison plot\")","title":"First steps"},{"location":"user_guide/#data-cleaning","text":"More often than not, you need to do some data cleaning before fitting your dataset to a model. Usually, this involves importing different libraries and writing many lines of code. Since ATOM is all about fast exploration and experimentation, it provides various data cleaning classes to apply the most common transformations fast and easy.","title":"Data cleaning"},{"location":"user_guide/#scaling-the-feature-set","text":"Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). The Scaler class scales data to mean=0 and std=1. It can be accessed from atom through the scale method.","title":"Scaling the feature set"},{"location":"user_guide/#standard-data-cleaning","text":"There are many data cleaning steps that are useful to perform on any dataset before modelling. These are general rules that apply almost on every use-case and every task. The Cleaner class is a convenient tool to apply such steps. It can be accessed from atom through the clean method. Use the class' parameters to choose which transformations to perform. The available steps are: Remove columns with prohibited data types. Strip categorical features from white spaces. Remove categorical columns with maximal cardinality. Remove columns with minimum cardinality. Remove rows with missing values in the target column. Encode the target column.","title":"Standard data cleaning"},{"location":"user_guide/#imputing-missing-values","text":"For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets however are incompatible with ATOM's models which assume that all values in an array are numerical, and that all have and hold meaning. The Imputer class handles missing values in the dataset by either dropping or imputing the value. It can be accessed from atom through the impute method. Tip Use atom 's missing attribute for an overview of the missing values in the dataset.","title":"Imputing missing values"},{"location":"user_guide/#encoding-categorical-features","text":"Many datasets will contain categorical features. Their variables are typically stored as text values which represent various traits. Some examples include color (\u201cRed\u201d, \u201cYellow\u201d, \u201cBlue\u201d), size (\u201cSmall\u201d, \u201cMedium\u201d, \u201cLarge\u201d) or geographic designations (city or country). Regardless of what the value is used for, the challenge is determining how to use this data in the analysis. ATOM's models don't support direct manipulation of this kind of data. Use the Encoder class to encode categorical features to numerical values. It can be accessed from atom through the encode method. Tip Use atom 's categorical attribute for a list of the categorical columns in the dataset.","title":"Encoding categorical features"},{"location":"user_guide/#handling-outliers","text":"When modeling, it is important to clean the data sample to ensure that the observations best represent the problem. Sometimes a dataset can contain extreme values that are outside the range of what is expected and unlike the other data. These are called outliers. Often, machine learning modeling and model skill in general can be improved by understanding and even removing these outlier values. The Outliers class can drop or impute outliers in the dataset. It can be accessed from atom through the outliers method.","title":"Handling outliers"},{"location":"user_guide/#balancing-the-data","text":"One of the common issues found in datasets that are used for classification is imbalanced classes. Data imbalance usually reflects an unequal distribution of classes within a dataset. For example, in a credit card fraud detection dataset, most of the transactions are non-fraud and a very few cases are fraud. This leaves us with a very unbalanced ratio of fraud vs non-fraud cases. The Balancer class can oversample the minority class or undersample the majority class. It can be accessed from atom through the balance method.","title":"Balancing the data"},{"location":"user_guide/#feature-engineering","text":"\"Applied machine learning\" is basically feature engineering. ~ Andrew Ng. Feature engineering is the process of creating new features from the existing ones, in order to capture relationships with the target column that the first set of features didn't had on their own. This process is very important to improve the performance of machine learning algorithms. Although feature engineering works best when the data scientist applies use-case specific transformations, there are ways to do this in an automated manner, without prior domain knowledge. One of the problems of creating new features without human expert intervention, is that many of the newly created features can be useless, i.e. they do not help the algorithm to make better predictions. Even worse, having useless features can drop your performance. To avoid this, we perform feature selection, a process in which we select the relevant features in the dataset. See here an example.","title":"Feature engineering"},{"location":"user_guide/#generating-new-features","text":"The FeatureGenerator class creates new non-linear features based on the original feature set. It can be accessed from atom through the feature_generation method. You can choose between two strategies: Deep Feature Synthesis and Genetic Feature Generation. Deep Feature Synthesis Deep feature synthesis (DFS) applies the selected operators on the features in the dataset. For example, if the operator is \"log\", it will create the new feature LOG(old_feature) and if the operator is \"mul\", it will create the new feature old_feature_1 x old_feature_2 . The operators can be chosen through the operators parameter. Available options are: add: Sum two features together. sub: Subtract two features from each other. mul: Multiply two features with each other. div: Divide two features with each other. srqt: Take the square root of a feature. log: Take the logarithm of a feature. sin: Calculate the sine of a feature. cos: Calculate the cosine of a feature. tan: Calculate the tangent of a feature. ATOM's implementation of DFS uses the featuretools package. Tip DFS can create many new features and not all of them will be useful. Use FeatureSelector to reduce the number of features! Warning Using the div, log or sqrt operators can return new features with inf or NaN values. Check the warnings that may pop up or use atom 's missing property. Warning When using DFS with n_jobs>1 , make sure to protect your code with if __name__ == \"__main__\" . Featuretools uses dask , which uses python multiprocessing for parallelization. The spawn method on multiprocessing starts a new python process, which requires it to import the __main__ module before it can do its task. Genetic Feature Generation Genetic feature generation (GFG) uses genetic programming , a branch of evolutionary programming, to determine which features are successful and create new ones based on those. Where DFS\" method can be seen as some kind of \"brute force\" for feature engineering, GFG tries to improve its features with every generation of the algorithm. GFG uses the same operators as DFS, but instead of only applying the transformations once, it evolves them further, creating complicated non-linear combinations of features with many transformations. The new features are given the name Feature N for the N-th feature. You can access the genetic feature's fitness and description (how they are calculated) through the genetic_features attribute. ATOM uses the SymbolicTransformer class from the gplearn package for the genetic algorithm. Read more about this implementation here . Warning GFG can be slow for very large populations!","title":"Generating new features"},{"location":"user_guide/#selecting-useful-features","text":"The FeatureSelector class provides tooling to select the relevant features from a dataset. It can be accessed from atom through the feature_selection method. The following strategies are implemented: univariate, PCA, SFM, RFE and RFECV. Univariate Univariate feature selection works by selecting the best features based on univariate statistical F-test. The test is provided via the solver parameter. It takes any function taking two arrays (X, y), and returning arrays (scores, p-values). Read more in sklearn's documentation . Principal Components Analysis Applying PCA will reduce the dimensionality of the dataset by maximizing the variance of each dimension. The new features will be called Component 0, Component 1, etc... The dataset will be scaled before applying the transformation (if it wasn't already). Read more in sklearn's documentation . Selection from model SFM uses an estimator with feature_importances_ or coef_ attributes to select the best features in a dataset based on importance weights. The estimator is provided through the solver parameter and can be already fitted. ATOM allows you to use one its pre-defined models , e.g. solver=\"RF\" . If you didn't call the FeatureSelector through atom , don't forget to indicate the estimator's task adding _class or _reg after the name, e.g. RF_class to use a random forest classifier. Read more in sklearn's documentation . Recursive feature elimination Select features by recursively considering smaller and smaller sets of features. First, the estimator is trained on the initial set of features and the importance of each feature is obtained either through a coef_ attribute or through a feature_importances_ attribute. Then, the least important features are pruned from current set of features. That procedure is recursively repeated on the pruned set until the desired number of features to select is eventually reached. Note that, since RFE needs to fit the model again every iteration, this method can be fairly slow. RFECV applies the same algorithm as RFE but uses a cross-validated metric (under the scoring parameter, see RFECV ) to assess every step's performance. Also, where RFE returns the number of features selected by n_features , RFECV returns the number of features that achieved the optimal score on the specified metric. Note that this is not always equal to the amount specified by n_features . Read more in sklearn's documentation . Removing features with low variance Variance is the expectation of the squared deviation of a random variable from its mean. Features with low variance have many values repeated, which means the model will not learn much from them. FeatureSelector removes all features where the same value is repeated in at least max_frac_repeated fraction of the rows. The default option is to remove a feature if all values in it are the same. Read more in sklearn's documentation . Removing features with multi-collinearity Two features that are highly correlated are redundant, i.e. two will not contribute more to the model than only one of them. FeatureSelector will drop a feature that has a Pearson correlation coefficient larger than max_correlation with another feature. A correlation of 1 means the two columns are equal. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. Tip Use the plot_feature_importance method to examine how much a specific feature contributes to the final predictions. If the model doesn't have a feature_importances_ attribute, use plot_permutation_importance instead. Warning The RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs.","title":"Selecting useful features"},{"location":"user_guide/#models","text":"","title":"Models"},{"location":"user_guide/#predefined-models","text":"ATOM provides 31 models for classification and regression tasks that can be used to fit the data in the pipeline. After fitting, every model class is attached to the training instance as an attribute. We refer to these \"subclasses\" as models (see the nomenclature ). The classes contain a variety of attributes and methods to help you understand how the underlying estimator performed. They can be accessed using the models\" acronyms, e.g. atom.LGB to access the LightGBM's model . The available models and their corresponding acronyms are: \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Classification/Regression \"Lasso\" for Lasso Regression \"EN\" for Elastic Net \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost \"LGB\" for LightGBM \"CatB\" for CatBoost \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron","title":"Predefined models"},{"location":"user_guide/#custom-models","text":"It is also possible to use your own models in ATOM's pipeline. For example, imagine we want to use sklearn's Lars estimator (note that is not included in ATOM's predefined models ). There are two ways to achieve this: Using ATOMModel (recommended). With this approach you can pass the required model characteristics to the pipeline. from sklearn.linear_model import Lars from atom import ATOMRegressor, ATOMModel model = ATOMModel(models=Lars, fullname=\"Lars Regression\", needs_scaling=True, type=\"linear\") atom = ATOMRegressor(X, y) atom.run(model) Using the estimator's class or an instance of the class. This approach will also call ATOMModel under the hood, but it will leave its parameters to their default values. from sklearn.linear_model import Lars from atom import ATOMRegressor, ATOMModel atom = ATOMRegressor(X, y) atom.run(models=Lars) Additional things to take into account: Custom models are not restricted to sklearn estimators, but they should follow sklearn's API, i.e. have a fit and predict method. Parameter customization (for the initializer) is only possible for custom models which provide an estimator's class or an instance that has a set_params() method, i.e. its a child class of BaseEstimator . Hyperparameter optimization for custom models is ignored unless appropriate dimensions are provided through bo_params . If the estimator has a n_jobs and/or random_state parameter that is left to its default value, it will automatically adopt the values from the training instance it's called from.","title":"Custom models"},{"location":"user_guide/#deep-learning","text":"Deep learning models can be used through ATOM's custom models as long as they follow sklearn's API. For example, models implemented with the Keras package should use the sklearn wrappers KerasClassifier and kerasRegressor . Many deep learning models, for example in computer vision and natural language processing, use datasets with more than 2 dimensions, e.g. image data can have shape (n_samples, length, width, rgb). These data structures are not intended to store in a 2 dimensional pandas dataframe. Since ATOM requires a dataframe as instance for the dataset, multidimensional data sets are stored in a single column called \"Features\" where every row contains one (multidimensional) sample. Click here for an example. Note that, because of this, the data cleaning , feature engineering and some of the plotting methods are unavailable for deep learning datasets. Tip You can also use lowercase to call the models , e.g. atom.lgb.plot_roc() . Warning The models should not be initialized by the user! Only use them through the training instances.","title":"Deep learning"},{"location":"user_guide/#training","text":"The training phase is where the models are fitted and evaluated. After this, the models are attached to the training instance and you can use the plotting and predicting methods. The pipeline applies the following steps iteratively for all models: The optimal hyperparameters are selected. The model is trained on the training set and evaluated on the test set. The bagging algorithm is applied. There are three approaches to run the training. Direct training: TrainerClassifier TrainerRegressor Training via successive halving : SuccessiveHalvingClassifier SuccessiveHavingRegressor Training via train sizing : TrainSizingClassifier TrainSizingRegressor The direct fashion repeats the aforementioned steps only once, while the other two approaches repeats them more than once. Every approach can be directly called from atom through the run , successive_halving and train_sizing methods respectively. Every approach should be called from an independent instance of atom . Subsequent runs from different approaches will remove all information from previous trainings from the pipeline. You can, however, rerun the same approach multiple times. In that case, the results are combined. Note that if you rerun the same model, only the last model is saved. For example, here atom will \"forget\" the successive halving run. atom = ATOMClassifier(X, y) atom.successive_halving([\"Tree\", \"Bag\"]) atom.run(\"LGB\") In this case, both the Ridge and Lasso regressors are kept in the pipeline. atom = ATOMRegressor(X, y) atom.run(\"Ridge\") atom.run(\"Lasso\") Note Reruns are only allowed if the same metric is used. Leaving the metric parameter empty after the first run will automatically use the one in the pipeline. Additional things to take into account: Models are called through their acronyms , e.g. atom.run(models=\"RF\") will train a Random Forest. If an exception is encountered while fitting an estimator, the pipeline will automatically skip the model and jump to the next model and save the exception in the errors attribute. Note that in that case there will be no model for that estimator. When showing the final results, a ! indicates the highest score and a ~ indicates that the model is possibly overfitting (training set has a score at least 20% higher than the test set). The winning model (the one with the highest mean_bagging or metric_test ) will be attached to the winner attribute.","title":"Training"},{"location":"user_guide/#metric","text":"ATOM uses sklearn's scorers for model selection and evaluation. A scorer consists of a metric function and some parameters that define the scorer's properties such as it's a score or loss function or if the function needs probability estimates or rounded predictions (see make_scorer ). ATOM lets you define the scorer for the pipeline in three ways: The metric parameter is one of sklearn's predefined scorers (as string). The metric parameter is a score (or loss) function with signature metric(y, y_pred, **kwargs). In this case, use the greater_is_better , needs_proba and needs_threshold parameters to specify the scorer's properties. The metric parameter is a scorer object. Note that all scorers follow the convention that higher return values are better than lower return values. Thus metrics which measure the distance between the model and the data (i.e. loss functions), like max_error or mean_squared_error , will return the negated value of the metric. Custom scorer acronyms Since some of sklearn's scorers have quite long names and ATOM is all about lazy fast experimentation, the package provides acronyms for some of the most commonly used ones. These acronyms are case insensitive can be used for the metric parameter instead of the scorer's full name, e.g. atom.run(\"LR\", metric=\"BA\") will use balanced_accuracy . The available acronyms are: \"AP\" for \"average_precision\" \"BA\" for \"balanced_accuracy\" \"AUC\" for \"roc_auc\" \"EV\" for \"explained_variance\" \"ME\" for \"max_error\" \"MAE\" for \"neg_mean_absolute_error\" \"MSE\" for \"neg_mean_squared_error\" \"RMSE\" for \"neg_root_mean_squared_error\" \"MSLE\" for \"neg_mean_squared_log_error\" \"MEDAE\" for \"neg_median_absolute_error\" \"POISSON\" for \"neg_mean_poisson_deviance\" \"GAMMA\" for \"neg_mean_gamma_deviance\" Multi-metric runs Sometimes it is useful to measure the performance of the models in more than one way. ATOM lets you run the pipeline with multiple metrics at the same time. To do so, provide the metric parameter with a list of desired metrics, e.g. atom.run(\"LDA\", metric=[\"r2\", \"mse\"]) . If you provide metric functions, don't forget to also provide lists to the greater_is_better , needs_proba and needs_threshold parameters, where the n-th value in the list corresponds to the n-th function. If you leave them as a single value, that value will apply to every provided metric. When fitting multi-metric runs, the resulting scores will return a list of metrics. For example, if you provided three metrics to the pipeline, atom.knn.metric_bo could return [0.8734, 0.6672, 0.9001]. It is also important to note that only the first metric of a multi-metric run is used to evaluate every step of the bayesian optimization and to select the winning model. Tip Some plots let you choose which of the metrics to show using the metric parameter.","title":"Metric"},{"location":"user_guide/#parameter-customization","text":"By default, the parameters every estimator uses are the same default parameters they get from their respective packages. To select different ones, use est_params . There are two ways to add custom parameters to the models: adding them directly to the dictionary as key-value pairs or through multiple dicts with the model names as keys. Adding the parameters directly to est_params will share them across all models in the pipeline. In this example, both the XGBoost and the LightGBM model will use n_estimators=200. Make sure all the models do have the specified parameters or an exception will be raised! atom.run([\"XGB\", \"LGB\"], est_params={\"n_estimators\": 200}) To specify parameters per model, use the model name as key and a dict of the parameters as value. In this example, the XGBoost model will use n_estimators=200 and the Multi-layer Perceptron will use one hidden layer with 75 neurons. atom.run([\"XGB\", \"MLP\"], est_params={\"XGB\": {\"n_estimators\": 200}, \"MLP\": {\"hidden_layer_sizes\": (75,)}}) Some estimators allow you to pass extra parameters to the fit method (besides X and y). This can be done adding _fit at the end of the parameter. For example, to change XGBoost's verbosity, we can run: atom.run(\"XGB\", est_params={\"verbose_fit\": True} Note If a parameter is specified through est_params , it will be ignored by the bayesian optimization!","title":"Parameter customization"},{"location":"user_guide/#hyperparameter-optimization","text":"In order to achieve maximum performance, we need to tune an estimator's hyperparameters before training it. ATOM provides hyperparameter tuning using a bayesian optimization (BO) approach implemented by skopt . The BO is optimized on the first metric provided with the metric parameter. Each step is either computed by cross-validation on the complete training set or by randomly splitting the training set every iteration into a (sub) training set and a validation set. This process can create some data leakage but ensures maximal use of the provided data. The test set, however, does not contain any leakage and will be used to determine the final score of every model. Note that, if the dataset is relatively small, the BO's best score can consistently be lower than the final score on the test set (despite the leakage) due to the considerable fewer instances on which it is trained. There are many possibilities to tune the BO to your liking. Use n_calls and n_initial_points to determine the number of iterations that are performed randomly at the start (exploration) and the number of iterations spent optimizing (exploitation). If n_calls is equal to n_initial_points , every iteration of the BO will select its hyperparameters randomly. This means the algorithm is technically performing a random search . Note The n_calls parameter includes the iterations in n_initial_points , i.e. calling atom.run(\"LR\", n_calls=20, n_intial_points=10) will run 20 iterations of which the first 10 are random. Note If n_initial_points=1 , the first trial will be equal to the estimator's default parameters. Other settings can be changed through the bo_params parameter, a dictionary where every key-value combination can be used to further customize the BO. By default, the hyperparameters and corresponding dimensions per model are predefined by ATOM. Use the dimensions key to use custom ones. Just like with est_params , you can share the same dimensions across models or use a dictionary with the model names as keys to specify the dimensions for every individual model. Note that the provided search space dimensions must be compliant with skopt's API. atom.run(\"LR\", n_calls=10, bo_params={\"dimensions\": [Integer(100, 1000, name=\"max_iter\")]}) The majority of skopt's callbacks to stop the optimizer early can be accessed through bo_params . You can include other callbacks using the callbacks key. atom.run(\"LR\", n_calls=10, bo_params={\"max_time\": 1000, \"callbacks\": custom_callback()}) You can also include other optimizer's parameters as key-value pairs. atom.run(\"LR\", n_calls=10, bo_params={\"acq_func\": \"EI\"})","title":"Hyperparameter optimization"},{"location":"user_guide/#bagging","text":"After fitting the estimator, you can asses the robustness of the model using bootstrap aggregating (bagging). This technique creates several new data sets selecting random samples from the training set (with replacement) and evaluates them on the test set. This way we get a distribution of the performance of the model. The number of sets can be chosen through the bagging parameter. Tip Use the plot_bagging method to plot the bagging scores in a convenient boxplot.","title":"Bagging"},{"location":"user_guide/#early-stopping","text":"XGBoost , LightGBM and CatBoost allow in-training evaluation. This means that the estimator is evaluated after every round of the training, and that the training is stopped early if it didn't improve in the last early_stopping rounds. This can save the pipeline much time that would otherwise be wasted on an estimator that is unlikely to improve further. Note that this technique will be applied both during the BO and at the final fit on the complete training set. There are two ways to apply early stopping on these models: Through the early_stopping key in bo_params . This approach applies early stopping to all models in the pipeline and allows the input of a fraction of the total number of rounds. Filling the early_stopping_rounds parameter directly in est_params . Don't forget to add _fit to the parameter to call it from the fit method. After fitting, the model will get the evals attribute, a dictionary of the train and test performances per round (also if early stopping wasn't applied). Click here for an example pipeline using early stopping. Tip Use the plot_evals method to plot the in-training evaluation on the train and test set.","title":"Early stopping"},{"location":"user_guide/#repeating-models","text":"If you want to fit the same model multiple times in a pipeline, add a tag after the acronym when calling the models. atom.run(models=[\"RF1\", \"RF2\"], est_params={\"RF1\": {\"n_estimators\": 100}, \"RF2\": {\"n_estimators\": 200}}) This pipeline will run two Random Forest models, one with 100 and the other with 200 decision trees. The models can be accessed through atom.rf1 and atom.rf2 . This can be useful to test how the same model performs with different parameters or different data sets.","title":"Repeating models"},{"location":"user_guide/#successive-halving","text":"Successive halving is a bandit-based algorithm that fits N models to 1/N of the data. The best half are selected to go to the next iteration where the process is repeated. This continues until only one model remains, which is fitted on the complete dataset. Beware that a model's performance can depend greatly on the amount of data on which it is trained. For this reason, we recommend only to use this technique with similar models, e.g. only using tree-based models. Use successive halving through the SuccessiveHalvingClassifier / SuccessiveHalvingRegressor classes or from atom via the successive_halving method. After running the pipeline, the results attribute will be multi-index, where the first index indicates the iteration and the second the model's acronym. Tip Use the plot_successive_halving method to see every model's performance per iteration of the successive halving.","title":"Successive halving"},{"location":"user_guide/#train-sizing","text":"When training models, there is usually a trade-off between model performance and computation time that is regulated by the number of samples in the training set. Train sizing can be used to create insights in this trade-off and help determine the optimal size of the training set, fitting the models multiple times, ever increasing the number of samples in the training set. Use train sizing through the TrainSizingClassifier / TrainSizingRegressor classes or from atom via the train_sizing method. The number of iterations and the number of samples per training can be specified with the train_sizes parameter. After running the pipeline, the results attribute will be multi-index, where the first index indicates the iteration and the second the model's acronym. Tip Use the plot_learning_curve method to see the model's performance per size of the training set.","title":"Train sizing"},{"location":"user_guide/#predicting","text":"After running a successful pipeline, it is possible you would like to apply all used transformations onto new data, or make predictions using one of the trained models. Just like a sklearn estimator, you can call the prediction methods from a fitted training instance, e.g. atom.predict(X) . Calling the method without specifying a model will use the winning model in the pipeline (under attribute winner ). To use a different model, simply call the method from a model , e.g. atom.KNN.predict(X) . If called from atom , the prediction methods will transform the provided data through all the transformers in the pipeline before making the predictions. By default, this excludes outlier handling and balancing the dataset since these steps should only be applied on the training set. Use the method's kwargs to select which transformations to use in every call. The available prediction methods are a selection of the most common methods for estimators in sklearn's API: transform Transform new data through all the pre-processing steps in the pipeline. predict Transform the data and make predictions on new data. predict_proba Transform the data and make probabilistic predictions on new data. predict_log_proba Transform the data and make logarithmic probability predictions on new data. decision_function Transform the data and evaluate the decision function on new data. score Transform the data and return the model's score on new data. Except for transform, the prediction methods can be calculated on the train and test set. You can access them through the model 's prediction attributes, e.g. atom.mnb.predict_train or atom.mnb.predict_test . Keep in mind that the results are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Note Many of the plots use the prediction attributes. This can considerably increase the size of the class for large datasets. Use the reset_prediction_attributes method if you need to free some memory!","title":"Predicting"},{"location":"user_guide/#plots","text":"After fitting the models to the data, it's time to analyze the results. ATOM provides many plotting methods to compare the model performances. Descriptions and examples can be found in the API section. ATOM uses the packages matplotlib , seaborn and shap for plotting. The plot methods can be called from a training directly, e.g. atom.plot_roc() , or from one of the models , e.g. atom.LGB.plot_roc() . If called from training , it will make the plot for all models in the pipeline. This can be useful to compare the results of multiple models. If called from a model , it will make the plot for only that model. Use this option if you want information just for that specific model or to make a plot less crowded.","title":"Plots"},{"location":"user_guide/#parameters","text":"Apart from the plot-specific parameters they may have, all plots have four parameters in common: The title parameter allows you to add a custom title to the plot. The figsize parameter adjust the plot's size. The filename parameter is used to save the plot. The display parameter determines whether the plot is rendered.","title":"Parameters"},{"location":"user_guide/#aesthetics","text":"The plot aesthetics can be customized using the plot attributes, e.g. atom.style = \"white\" . These attributes can be called from any instance with plotting methods. Note that the plot attributes are attached to the class and not the instance. This means that changing the attribute will also change it for all other instances in the module. ATOM's default values are: style: \"darkgrid\" palette: \"GnBu_r_d\" title_fontsize: 20 label_fontsize: 16 tick_fontsize: 12","title":"Aesthetics"},{"location":"user_guide/#shap","text":"The SHAP (SHapley Additive exPlanations) python package uses a game theoretic approach to explain the output of any machine learning model. It connects optimal credit allocation with local explanations using the classic Shapley values from game theory and their related extensions. ATOM implements methods to plot 5 of shap's plotting functions directly from its API. The explainer will be chosen automatically based on the model's type. For kernelExplainer, the data used to estimate the expected values is the complete training set when <100 rows, else its summarized with a set of 10 weighted K-means, each weighted by the number of points they represent. The five plots are: force_plot , dependence_plot , summary_plot , decision_plot and waterfall_plot . Since the plots are not made by ATOM, we can't draw multiple models in the same figure. Selecting more than one model will raise an exception. To avoid this, call the plot from a model , e.g. atom.xgb.force_plot() . Note You can recognize the SHAP plots by the fact that they end (instead of start) with plot.","title":"SHAP"},{"location":"user_guide/#available-plots","text":"A list of available plots can be find hereunder. Note that not all plots can be called from every class and that their availability can depend on the task at hand. plot_correlation Plot the data's correlation matrix. plot_pipeline Plot a diagram of every estimator in atom's pipeline. plot_pca Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per components. plot_rfecv Plot the RFECV results. plot_successive_halving Plot of the models\" scores per iteration of the successive halving. plot_learning_curve Plot the model's learning curve. plot_bagging Plot a boxplot of the bagging's results. plot_bo Plot the bayesian optimization scoring. plot_evals Plot evaluation curves for the train and test set. plot_roc Plot the Receiver Operating Characteristics curve. plot_prc Plot the precision-recall curve. plot_permutation_importance Plot the feature permutation importance of models. plot_feature_importance Plot a tree-based model's feature importance. plot_partial_dependence Plot the partial dependence of features. plot_errors Plot a model's prediction errors. plot_residuals Plot a model's residuals. plot_confusion_matrix Plot a model's confusion matrix. plot_threshold Plot metric performances against threshold values. plot_probabilities Plot the probability distribution of the classes in the target column. plot_calibration Plot the calibration curve for a binary classifier. plot_gains Plot the cumulative gains curve. plot_lift Plot the lift curve. force_plot Plot SHAP's force plot. dependence_plot Plot SHAP's dependence plot. summary_plot Plot SHAP's summary plot. decision_plot Plot SHAP's decision plot. waterfall_plot Plot SHAP's waterfall plot.","title":"Available plots"},{"location":"API/ATOM/atomclassifier/","text":"ATOMClassifier class atom.api. ATOMClassifier (*arrays, n_rows=1, test_size=0.2, logger=None, n_jobs=1, warnings=True, verbose=0, random_state=None) [source] ATOMClassifier is ATOM's wrapper for binary and multiclass classification tasks. Use this class to easily apply all data transformations and model management provided by the package on a given dataset. Note that contrary to scikit-learn's API, the ATOMClassifier object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. You can predict , plot and call any model from the ATOMClassifier instance. Read more in the user guide . Parameters: *arrays: sequence of indexables Dataset containing the features and target. Allowed formats are: X, y train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) X, train, test: dict, list, tuple, np.array or pd.DataFrame Feature set with shape=(n_features, n_samples). If no y is provided, the last column is used as target. y: int, str or array-like If int: Position of the target column in X. If str: Name of the target column in X. Else: Data target column with shape=(n_samples,). n_rows: int or float, optional (default=1) If <=1: Fraction of the dataset to use. If >1: Number of rows to use (only if input is X, y). test_size: int, float, optional (default=0.2) If <=1: Fraction of the dataset to include in the test set. If >1: Number of rows to include in the test set. This parameter is ignored if the train and test set are provided. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. warnings: bool or str, optional (default=True) If True: Default warning action (equal to \"default\" when string). If False: Suppress all warnings (equal to \"ignore\" when string). If str: One of the possible actions in python's warnings environment. Note that changing this parameter will affect the PYTHONWARNINGS environment. Note that ATOM can't manage warnings that go directly from C++ code to the stdout/stderr. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" for default name. If class: python Logger object. Note that warnings will not be saved to the logger in any case. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling atom.train will return the training set. The data can also be changed through these properties, e.g. atom.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column. mapping: dict Dictionary of the target classes mapped to their respective encoded integer. nans: pd.Series Returns columns with number of missing values. n_nans: int Number of columns with missing values. categorical: list Returns columns with categorical features. n_categorical: int Number of columns with categorical features. scaled: bool Returns whether the feature set is scaled. Utility attributes Attributes: missing: list List of values that are considered \"missing\". Default values are: \"\", \"?\", \"None\", \"NA\", \"nan\", \"NaN\" and \"inf\". Note that None , NaN , +inf and -inf are always considered missing since they are incompatible with sklearn estimators. genetic_features: pd.DataFrame Dataframe of the non-linear features created by the feature_generation method. Columns include: name: Name of the feature (automatically created). description: Operators used to create this feature. fitness: Fitness score. collinear: pd.DataFrame Dataframe of the collinear features removed by the feature_selection method. Columns include: drop_feature: name of the feature dropped by the method. correlated feature: Name of the correlated feature(s). correlation_value: Pearson correlation coefficient(s) of the feature pairs. models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. pipeline: pd.Series Series containing all classes fitted in the pipeline. Use this attribute only to access the individual classes. To visualize the pipeline, use atom 's __repr__ or plot_pipeline . results: pd.DataFrame Dataframe of the training results. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Utility methods The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_class_weight Return class weights for a balanced data set. log Save information to the logger and print to stdout. report Get an extensive profile analysis of the data. save Save the instance to a pickle file. save_data Save data to a csv file. scoring Returns the scores of the models for a specific metric. stats Print out a list of basic statistics on the dataset. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method report (dataset=\"dataset\", n_rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for n_rows > 10k. Parameters: dataset: str, optional (default=\"dataset\") Name of the data set to get the profile from. n_rows: int or None, optional (default=None) Number of (randomly picked) rows to process. None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method save_data (filename=None, dataset=\"dataset\") [source] Save data to a csv file. Parameters: filename: str or None, optional (default=None) Name of the saved file. None to use default name. dataset: str, optional (default=\"dataset\") Data set to save. method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method stats () [source] Print out a list of basic information on the dataset. Data cleaning ATOMClassifier provides data cleaning methods to scale your features and handle missing values, categorical columns, outliers and unbalanced datasets. Calling on one of them will automatically apply the method on the dataset in the pipeline. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. scale Scale all the features to mean=1 and std=0. clean Applies standard data cleaning steps on the dataset. impute Handle missing values in the dataset. encode Encode categorical features. outliers Remove or replace outliers in the training set. balance Balance the target classes in the training set. method scale () [source] Scale the features to mean=1 and std=0. method clean (prohibited_types=None, strip_categorical=True, maximum_cardinality=True, minimum_cardinality=True, missing_target=True, map_target=None) [source] Applies standard data cleaning steps on the dataset. These steps can include: Strip categorical features from white spaces. Removing columns with prohibited data types. Removing categorical columns with maximal cardinality. Removing columns with minimum cardinality. Removing rows with missing values in the target column. Encode the target column. See Cleaner for a description of the parameters. method impute (strat_num=\"drop\", strat_cat=\"drop\", min_frac_rows=0.5, min_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. The imputer is fitted only on the training set to avoid data leakage. Use the missing attribute to customize what are considered \"missing values\". See Imputer for a description of the parameters. Note that since the Imputer can remove rows from both train and test set, the set's sizes may change size. method encode (strategy=\"LeaveOneOut\", max_onehot=10, frac_to_other=None) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: If n_unique=2, use Label-encoding. If 2 < n_unique <= max_onehot, use OneHot-encoding. If n_unique > max_onehot, use strategy -encoding. Also replaces classes with low occurrences with the value \"other\" in order to prevent too high cardinality. Categorical features are defined as all columns whose dtype.kind not in \"ifu\". Will raise an error if it encounters missing values or unknown classes when transforming. The encoder is fitted only on the training set to avoid data leakage. See Encoder for a description of the parameters. method outliers (strategy=\"drop\", max_sigma=3, include_target=False) [source] Remove or replace outliers in the training set. Outliers are defined as values that lie further than max_sigma * standard_deviation away from the mean of the column. Only outliers from the training set are removed to maintain an original sample of target values in the test set. Ignores categorical columns. See Outliers for a description of the parameters. method balance (strategy=\"ADASYN\", **kwargs) [source] Balance the number of instances per target class in the training set. Only the training set is balanced in order to maintain the original distribution of target classes in the test set. See Balancer for a description of the parameters. Feature engineering To further pre-process the data you can create new non-linear features transforming the existing ones or, if your dataset is too large, remove features using one of the provided strategies. feature_generation Create new features from combinations of existing ones. feature_selection Remove features according to the selected strategy. method feature_generation (strategy=\"DFS\", n_features=None, generations=20, population=500, operators=None) [source] Use Deep feature Synthesis or a genetic algorithm to create new combinations of existing features to capture the non-linear relations between the original features. See FeatureGenerator for a description of the parameters. Attributes created by the class are attached to the ATOM instance. method feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=1., **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. See FeatureSelector for a description of the parameters. Plotting methods and attributes created by the class are attached to the instance. Note When strategy=\"univariate\" and solver=None, f_classif will be used as default solver. When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and the solver is one of ATOM's models, the algorithm will automatically select the classifier (no need to add _class to the solver). When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and solver=None, ATOM will use the winning model (if it exists) as solver. When strategy=\"RFECV\", ATOM will use the metric in the pipeline (if it exists) as the scoring parameter (only if not specified manually). Training The training methods are where the models are fitted to the data and their performance is evaluated according to the selected metric. ATOMClassifier contains three methods to call the training classes from the ATOM package. All relevant attributes and methods from the training classes are attached to ATOMClassifier for convenience. These include the errors, winner and results attributes, the models , and the prediction and plotting methods. run Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. method run (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainerClassifier instance. method successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a SuccessiveHalvingClassifier instance. method train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainSizingClassifier instance. Example from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y=True) # Initialize class atom = ATOMClassifier(X, y, logger=\"auto\", n_jobs=2, verbose=2) # Apply data cleaning methods atom.outliers(strategy=\"min_max\", max_sigma=2) atom.balance(strategy=\"smote\", sampling_strategy=0.7) # Fit the models to the data atom.run( models=[\"QDA\", \"CatB\"], metric=\"precision\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Analyze the results print(f\"The winning model is: {atom.winner.name}\") print(atom.results) # Make some plots atom.palette = \"Blues\" atom.plot_roc(figsize=(9, 6), filename=\"roc.png\") atom.CatB.plot_feature_importance(filename=\"catboost_feature_importance.png\") # Run an extra model atom.run( models=\"LR\", metric=\"precision\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Get the predictions for the best model on new data predictions = atom.predict(X_new)","title":"ATOMClassifier"},{"location":"API/ATOM/atomclassifier/#atomclassifier","text":"class atom.api. ATOMClassifier (*arrays, n_rows=1, test_size=0.2, logger=None, n_jobs=1, warnings=True, verbose=0, random_state=None) [source] ATOMClassifier is ATOM's wrapper for binary and multiclass classification tasks. Use this class to easily apply all data transformations and model management provided by the package on a given dataset. Note that contrary to scikit-learn's API, the ATOMClassifier object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. You can predict , plot and call any model from the ATOMClassifier instance. Read more in the user guide . Parameters: *arrays: sequence of indexables Dataset containing the features and target. Allowed formats are: X, y train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) X, train, test: dict, list, tuple, np.array or pd.DataFrame Feature set with shape=(n_features, n_samples). If no y is provided, the last column is used as target. y: int, str or array-like If int: Position of the target column in X. If str: Name of the target column in X. Else: Data target column with shape=(n_samples,). n_rows: int or float, optional (default=1) If <=1: Fraction of the dataset to use. If >1: Number of rows to use (only if input is X, y). test_size: int, float, optional (default=0.2) If <=1: Fraction of the dataset to include in the test set. If >1: Number of rows to include in the test set. This parameter is ignored if the train and test set are provided. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. warnings: bool or str, optional (default=True) If True: Default warning action (equal to \"default\" when string). If False: Suppress all warnings (equal to \"ignore\" when string). If str: One of the possible actions in python's warnings environment. Note that changing this parameter will affect the PYTHONWARNINGS environment. Note that ATOM can't manage warnings that go directly from C++ code to the stdout/stderr. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" for default name. If class: python Logger object. Note that warnings will not be saved to the logger in any case. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"ATOMClassifier"},{"location":"API/ATOM/atomclassifier/#attributes","text":"","title":"Attributes"},{"location":"API/ATOM/atomclassifier/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling atom.train will return the training set. The data can also be changed through these properties, e.g. atom.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column. mapping: dict Dictionary of the target classes mapped to their respective encoded integer. nans: pd.Series Returns columns with number of missing values. n_nans: int Number of columns with missing values. categorical: list Returns columns with categorical features. n_categorical: int Number of columns with categorical features. scaled: bool Returns whether the feature set is scaled.","title":"Data attributes"},{"location":"API/ATOM/atomclassifier/#utility-attributes","text":"Attributes: missing: list List of values that are considered \"missing\". Default values are: \"\", \"?\", \"None\", \"NA\", \"nan\", \"NaN\" and \"inf\". Note that None , NaN , +inf and -inf are always considered missing since they are incompatible with sklearn estimators. genetic_features: pd.DataFrame Dataframe of the non-linear features created by the feature_generation method. Columns include: name: Name of the feature (automatically created). description: Operators used to create this feature. fitness: Fitness score. collinear: pd.DataFrame Dataframe of the collinear features removed by the feature_selection method. Columns include: drop_feature: name of the feature dropped by the method. correlated feature: Name of the correlated feature(s). correlation_value: Pearson correlation coefficient(s) of the feature pairs. models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. pipeline: pd.Series Series containing all classes fitted in the pipeline. Use this attribute only to access the individual classes. To visualize the pipeline, use atom 's __repr__ or plot_pipeline . results: pd.DataFrame Dataframe of the training results. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/ATOM/atomclassifier/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/ATOM/atomclassifier/#utility-methods","text":"The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_class_weight Return class weights for a balanced data set. log Save information to the logger and print to stdout. report Get an extensive profile analysis of the data. save Save the instance to a pickle file. save_data Save data to a csv file. scoring Returns the scores of the models for a specific metric. stats Print out a list of basic statistics on the dataset. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method report (dataset=\"dataset\", n_rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for n_rows > 10k. Parameters: dataset: str, optional (default=\"dataset\") Name of the data set to get the profile from. n_rows: int or None, optional (default=None) Number of (randomly picked) rows to process. None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method save_data (filename=None, dataset=\"dataset\") [source] Save data to a csv file. Parameters: filename: str or None, optional (default=None) Name of the saved file. None to use default name. dataset: str, optional (default=\"dataset\") Data set to save. method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method stats () [source] Print out a list of basic information on the dataset.","title":"Utility methods"},{"location":"API/ATOM/atomclassifier/#data-cleaning","text":"ATOMClassifier provides data cleaning methods to scale your features and handle missing values, categorical columns, outliers and unbalanced datasets. Calling on one of them will automatically apply the method on the dataset in the pipeline. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. scale Scale all the features to mean=1 and std=0. clean Applies standard data cleaning steps on the dataset. impute Handle missing values in the dataset. encode Encode categorical features. outliers Remove or replace outliers in the training set. balance Balance the target classes in the training set. method scale () [source] Scale the features to mean=1 and std=0. method clean (prohibited_types=None, strip_categorical=True, maximum_cardinality=True, minimum_cardinality=True, missing_target=True, map_target=None) [source] Applies standard data cleaning steps on the dataset. These steps can include: Strip categorical features from white spaces. Removing columns with prohibited data types. Removing categorical columns with maximal cardinality. Removing columns with minimum cardinality. Removing rows with missing values in the target column. Encode the target column. See Cleaner for a description of the parameters. method impute (strat_num=\"drop\", strat_cat=\"drop\", min_frac_rows=0.5, min_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. The imputer is fitted only on the training set to avoid data leakage. Use the missing attribute to customize what are considered \"missing values\". See Imputer for a description of the parameters. Note that since the Imputer can remove rows from both train and test set, the set's sizes may change size. method encode (strategy=\"LeaveOneOut\", max_onehot=10, frac_to_other=None) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: If n_unique=2, use Label-encoding. If 2 < n_unique <= max_onehot, use OneHot-encoding. If n_unique > max_onehot, use strategy -encoding. Also replaces classes with low occurrences with the value \"other\" in order to prevent too high cardinality. Categorical features are defined as all columns whose dtype.kind not in \"ifu\". Will raise an error if it encounters missing values or unknown classes when transforming. The encoder is fitted only on the training set to avoid data leakage. See Encoder for a description of the parameters. method outliers (strategy=\"drop\", max_sigma=3, include_target=False) [source] Remove or replace outliers in the training set. Outliers are defined as values that lie further than max_sigma * standard_deviation away from the mean of the column. Only outliers from the training set are removed to maintain an original sample of target values in the test set. Ignores categorical columns. See Outliers for a description of the parameters. method balance (strategy=\"ADASYN\", **kwargs) [source] Balance the number of instances per target class in the training set. Only the training set is balanced in order to maintain the original distribution of target classes in the test set. See Balancer for a description of the parameters.","title":"Data cleaning"},{"location":"API/ATOM/atomclassifier/#feature-engineering","text":"To further pre-process the data you can create new non-linear features transforming the existing ones or, if your dataset is too large, remove features using one of the provided strategies. feature_generation Create new features from combinations of existing ones. feature_selection Remove features according to the selected strategy. method feature_generation (strategy=\"DFS\", n_features=None, generations=20, population=500, operators=None) [source] Use Deep feature Synthesis or a genetic algorithm to create new combinations of existing features to capture the non-linear relations between the original features. See FeatureGenerator for a description of the parameters. Attributes created by the class are attached to the ATOM instance. method feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=1., **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. See FeatureSelector for a description of the parameters. Plotting methods and attributes created by the class are attached to the instance. Note When strategy=\"univariate\" and solver=None, f_classif will be used as default solver. When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and the solver is one of ATOM's models, the algorithm will automatically select the classifier (no need to add _class to the solver). When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and solver=None, ATOM will use the winning model (if it exists) as solver. When strategy=\"RFECV\", ATOM will use the metric in the pipeline (if it exists) as the scoring parameter (only if not specified manually).","title":"Feature engineering"},{"location":"API/ATOM/atomclassifier/#training","text":"The training methods are where the models are fitted to the data and their performance is evaluated according to the selected metric. ATOMClassifier contains three methods to call the training classes from the ATOM package. All relevant attributes and methods from the training classes are attached to ATOMClassifier for convenience. These include the errors, winner and results attributes, the models , and the prediction and plotting methods. run Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. method run (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainerClassifier instance. method successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a SuccessiveHalvingClassifier instance. method train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainSizingClassifier instance.","title":"Training"},{"location":"API/ATOM/atomclassifier/#example","text":"from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier X, y = load_breast_cancer(return_X_y=True) # Initialize class atom = ATOMClassifier(X, y, logger=\"auto\", n_jobs=2, verbose=2) # Apply data cleaning methods atom.outliers(strategy=\"min_max\", max_sigma=2) atom.balance(strategy=\"smote\", sampling_strategy=0.7) # Fit the models to the data atom.run( models=[\"QDA\", \"CatB\"], metric=\"precision\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Analyze the results print(f\"The winning model is: {atom.winner.name}\") print(atom.results) # Make some plots atom.palette = \"Blues\" atom.plot_roc(figsize=(9, 6), filename=\"roc.png\") atom.CatB.plot_feature_importance(filename=\"catboost_feature_importance.png\") # Run an extra model atom.run( models=\"LR\", metric=\"precision\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Get the predictions for the best model on new data predictions = atom.predict(X_new)","title":"Example"},{"location":"API/ATOM/atomloader/","text":"ATOMLoader function ATOMLoader (filename=None, data=None, transform_data=True, verbose=None) [source] Load a class instance from a pickle file. If the file is a training instance that was saved using save_data=False , you can load new data into it. If the file is an atom instance, you can also apply all data transformations in the pipeline to the provided data. Parameters: filename: str Name of the pickle file to load. data: tuple of indexables or None, optional (default=None) Tuple containing the features and target data. Only use this parameter if the file is a training instance that was saved using save_data=False (see the save method). Allowed formats are: X, y train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) X, train, test: dict, list, tuple, np.array or pd.DataFrame Feature set with shape=(n_features, n_samples). If no y is provided, the last column is used as target. y: int, str or array-like If int: Position of the target column in X. If str: Name of the target column in X. Else: Data target column with shape=(n_samples,). transform_data: bool, optional (default=True) If False, the data is left as provided. If True, the data is transformed through all the steps in the instance's pipeline. This parameter is ignored if the loaded file is not an atom instance. verbose: int or None, optional (default=None) Verbosity level of the transformations applied on the new data. If None, use the verbosity from the loaded instance. This parameter is ignored if transform_data=False . Example from atom import ATOMClassifier, ATOMLoader # Save an atom instance to a pickle file atom = ATOMClassifier(X, y) atom.encode(strategy=\"Helmert\", max_onehot=12) atom.run(\"LR\", metric=\"AP\", n_calls=25, n_initial_points=10) atom.save(\"atom_lr\", save_data=False) # Load the class and add the transformed data to the new instance atom_2 = ATOMLoader(\"atom_lr\", data=(X, y), verbose=0)","title":"ATOMLoader"},{"location":"API/ATOM/atomloader/#atomloader","text":"function ATOMLoader (filename=None, data=None, transform_data=True, verbose=None) [source] Load a class instance from a pickle file. If the file is a training instance that was saved using save_data=False , you can load new data into it. If the file is an atom instance, you can also apply all data transformations in the pipeline to the provided data. Parameters: filename: str Name of the pickle file to load. data: tuple of indexables or None, optional (default=None) Tuple containing the features and target data. Only use this parameter if the file is a training instance that was saved using save_data=False (see the save method). Allowed formats are: X, y train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) X, train, test: dict, list, tuple, np.array or pd.DataFrame Feature set with shape=(n_features, n_samples). If no y is provided, the last column is used as target. y: int, str or array-like If int: Position of the target column in X. If str: Name of the target column in X. Else: Data target column with shape=(n_samples,). transform_data: bool, optional (default=True) If False, the data is left as provided. If True, the data is transformed through all the steps in the instance's pipeline. This parameter is ignored if the loaded file is not an atom instance. verbose: int or None, optional (default=None) Verbosity level of the transformations applied on the new data. If None, use the verbosity from the loaded instance. This parameter is ignored if transform_data=False .","title":"ATOMLoader"},{"location":"API/ATOM/atomloader/#example","text":"from atom import ATOMClassifier, ATOMLoader # Save an atom instance to a pickle file atom = ATOMClassifier(X, y) atom.encode(strategy=\"Helmert\", max_onehot=12) atom.run(\"LR\", metric=\"AP\", n_calls=25, n_initial_points=10) atom.save(\"atom_lr\", save_data=False) # Load the class and add the transformed data to the new instance atom_2 = ATOMLoader(\"atom_lr\", data=(X, y), verbose=0)","title":"Example"},{"location":"API/ATOM/atommodel/","text":"ATOMModel function ATOMModel (estimator, name=None, fullname=None, needs_scaling=False, type=\"kernel\") [source] Convert an estimator to a model that can be ingested by ATOM's pipeline. Parameters: estimator: class Model's estimator. Can be a class or an instance. name: str, optional (default=None) Model's acronym. Used to call the model from the training instance. If None, the estimator's name will be used (not recommended). fullname: str, optional (default=None) Full model's name. If None, the estimator's name will be used. needs_scaling: bool, optional (default=False) Whether the model needs scaled features. Can not be True for deep learning datasets. type: str, optional (default=\"kernel\") Model's type. Used to select shap's explainer . Choose from: \"linear\" for linear models. \"tree\" for tree-based models. \"kernel\" for the remaining models. Example from atom import ATOMRegressor, ATOMModel from sklearn.linear_model import HuberRegressor model = ATOMModel(HuberRegressor, name=\"hub\", fullname=\"Huber\", needs_scaling=True, type=\"linear\") atom = ATOMRegressor(X, y) atom.run(model) atom.hub.predict(X_new)","title":"ATOMModel"},{"location":"API/ATOM/atommodel/#atommodel","text":"function ATOMModel (estimator, name=None, fullname=None, needs_scaling=False, type=\"kernel\") [source] Convert an estimator to a model that can be ingested by ATOM's pipeline. Parameters: estimator: class Model's estimator. Can be a class or an instance. name: str, optional (default=None) Model's acronym. Used to call the model from the training instance. If None, the estimator's name will be used (not recommended). fullname: str, optional (default=None) Full model's name. If None, the estimator's name will be used. needs_scaling: bool, optional (default=False) Whether the model needs scaled features. Can not be True for deep learning datasets. type: str, optional (default=\"kernel\") Model's type. Used to select shap's explainer . Choose from: \"linear\" for linear models. \"tree\" for tree-based models. \"kernel\" for the remaining models.","title":"ATOMModel"},{"location":"API/ATOM/atommodel/#example","text":"from atom import ATOMRegressor, ATOMModel from sklearn.linear_model import HuberRegressor model = ATOMModel(HuberRegressor, name=\"hub\", fullname=\"Huber\", needs_scaling=True, type=\"linear\") atom = ATOMRegressor(X, y) atom.run(model) atom.hub.predict(X_new)","title":"Example"},{"location":"API/ATOM/atomregressor/","text":"ATOMRegressor class atom.api. ATOMRegressor (*arrays, n_rows=1, test_size=0.2, logger=None, n_jobs=1, warnings=True, verbose=0, random_state=None) [source] ATOMRegressor is ATOM's wrapper for regression tasks. Use this class to easily apply all data transformations and model management provided by the package on a given dataset. Note that contrary to scikit-learn's API, the ATOMRegressor object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. You can predict , plot and call any model from the ATOMRegressor instance. Read more in the user guide . Parameters: *arrays: sequence of indexables Dataset containing the features and target. Allowed formats are: X, y train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) X, train, test: dict, list, tuple, np.array or pd.DataFrame Feature set with shape=(n_features, n_samples). If no y is provided, the last column is used as target. y: int, str or array-like If int: Position of the target column in X. If str: Name of the target column in X. Else: Data target column with shape=(n_samples,). n_rows: int or float, optional (default=1) If <=1: Fraction of the dataset to use. If >1: Number of rows to use (only if input is X, y). test_size: int, float, optional (default=0.2) If <=1: Fraction of the dataset to include in the test set. If >1: Number of rows to include in the test set. This parameter is ignored if the train and test set are provided. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. warnings: bool or str, optional (default=True) If True: Default warning action (equal to \"default\" when string). If False: Suppress all warnings (equal to \"ignore\" when string). If str: One of the possible actions in python's warnings environment. Note that changing this parameter will affect the PYTHONWARNINGS environment. Note that ATOM can't manage warnings that go directly from C++ code to the stdout/stderr. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" for default name. If class: python Logger object. Note that warnings will not be saved to the logger in any case. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling atom.train will return the training set. The data can also be changed through these properties, e.g. atom.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. Utility attributes Attributes: genetic_features: pd.DataFrame Dataframe of the non-linear features created by the feature_generation method. Columns include: name: Name of the feature (automatically created). description: Operators used to create this feature. fitness: Fitness score. collinear: pd.DataFrame Dataframe of the collinear features removed by the feature_selection method. Columns include: drop_feature: name of the feature dropped by the method. correlated feature: Name of the correlated feature(s). correlation_value: Pearson correlation coefficient(s) of the feature pairs. models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. pipeline: pd.Series Series containing all classes fitted in the pipeline. Use this attribute only to access the individual classes. To visualize the pipeline, use atom 's __repr__ or plot_pipeline . results: pd.DataFrame Dataframe of the training results. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Utility methods The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. clear Remove a model from the pipeline. log Save information to the logger and print to stdout. report Get an extensive profile analysis of the data. save Save the instance to a pickle file. save_data Save data to a csv file. scoring Returns the scores of the models for a specific metric. stats Print out a list of basic statistics on the dataset. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str, list or tuple, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method report (dataset=\"dataset\", n_rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for n_rows > 10k. Parameters: df: str, optional (default=\"dataset\") Name of the data set to get the profile from. n_rows: int or None, optional (default=None) Number of (randomly picked) rows to process. None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method save_data (filename=None, dataset=\"dataset\") [source] Save data to a csv file. Parameters: filename: str or None, optional (default=None) Name of the saved file. None to use default name. dataset: str, optional (default=\"dataset\") Data set to save. method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method stats () [source] Print out a list of basic information on the dataset. Data cleaning ATOMRegressor provides data cleaning methods to scale your features and handle missing values, categorical columns and outliers. Calling on one of them will automatically apply the method on the dataset in the pipeline. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. scale Scale all the features to mean=1 and std=0. clean Applies standard data cleaning steps on the dataset. impute Handle missing values in the dataset. encode Encode categorical features. outliers Remove or replace outliers in the training set. method scale () [source] Scale the features to mean=1 and std=0. method clean (prohibited_types=None, strip_categorical=True, maximum_cardinality=True, minimum_cardinality=True, missing_target=True, map_target=None) [source] Applies standard data cleaning steps on the dataset. These steps can include: Strip categorical features from white spaces. Removing columns with prohibited data types. Removing categorical columns with maximal cardinality. Removing columns with minimum cardinality. Removing rows with missing values in the target column. Encode the target column. See Cleaner for a description of the parameters. method impute (strat_num=\"drop\", strat_cat=\"drop\", min_frac_rows=0.5, min_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. The imputer is fitted only on the training set to avoid data leakage. Use the missing attribute to customize what are considered \"missing values\". See Imputer for a description of the parameters. Note that since the Imputer can remove rows from both train and test set, the set's sizes may change to keep ATOM's test_size ratio. method encode (strategy=\"LeaveOneOut\", max_onehot=10, frac_to_other=None) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: If n_unique=2, use Label-encoding. If 2 < n_unique <= max_onehot, use OneHot-encoding. If n_unique > max_onehot, use strategy -encoding. Also replaces classes with low occurrences with the value \"other\" in order to prevent too high cardinality. Categorical features are defined as all columns whose dtype.kind not in \"ifu\". Will raise an error if it encounters missing values or unknown classes when transforming. The encoder is fitted only on the training set to avoid data leakage. See Encoder for a description of the parameters. method outliers (strategy=\"drop\", max_sigma=3, include_target=False) [source] Remove or replace outliers in the training set. Outliers are defined as values that lie further than max_sigma * standard_deviation away from the mean of the column. Only outliers from the training set are removed to maintain an original sample of target values in the test set. Ignores categorical columns. See Outliers for a description of the parameters. Feature engineering To further pre-process the data you can create new non-linear features transforming the existing ones or, if your dataset is too large, remove features using one of the provided strategies. feature_generation Create new features from combinations of existing ones. feature_selection Remove features according to the selected strategy. method feature_generation (strategy=\"DFS\", n_features=None, generations=20, population=500, operators=None) [source] Use Deep feature Synthesis or a genetic algorithm to create new combinations of existing features to capture the non-linear relations between the original features. See FeatureGenerator for a description of the parameters. Attributes created by the class are attached to the ATOM instance. method feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=1., **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. See FeatureSelector for a description of the parameters. Plotting methods and attributes created by the class are attached to the instance. Note When strategy=\"univariate\" and solver=None, f_regression will be used as default solver. When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and the solver is one of ATOM's models, the algorithm will automatically select the classifier (no need to add _reg to the solver). When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and solver=None, ATOM will use the winning model (if it exists) as solver. When strategy=\"RFECV\", ATOM will use the metric in the pipeline (if it exists) as the scoring parameter (only if not specified manually). Training The training methods are where the models are fitted to the data and their performance is evaluated according to the selected metric. ATOMRegressor contains three methods to call the training classes from the ATOM package. All relevant attributes and methods from the training classes are attached to ATOMClassifier for convenience. These include the errors, winner and results attributes, the models , and the prediction and plotting methods. run Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. method run (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainerRegressor instance. method successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a SuccessiveHalvingRegressor instance. method train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainSizingRegressor instance. Example from sklearn.datasets import load_boston from atom import ATOMRegressor X, y = load_boston(return_X_y=True) # Initialize class atom = ATOMRegressor(X, y, logger=\"auto\", n_jobs=2, verbose=2) # Apply data cleaning methods atom.outliers(strategy=\"min_max\", max_sigma=2, include_target=True) # Fit the models to the data atom.run( models=[\"OLS\", \"BR\", \"CatB\"], metric=\"MSE\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Analyze the results print(f\"The winning model is: {atom.winner.name}\") print(atom.results) # Make some plots atom.palette = \"Blues\" atom.plot_errors(figsize=(9, 6), filename=\"errors.png\") atom.CatB.plot_feature_importance(filename=\"catboost_feature_importance.png\") # Run an extra model atom.run( models=\"MLP\", metric=\"MSE\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Get the predictions for the best model on new data predictions = atom.predict(X_new)","title":"ATOMRegressor"},{"location":"API/ATOM/atomregressor/#atomregressor","text":"class atom.api. ATOMRegressor (*arrays, n_rows=1, test_size=0.2, logger=None, n_jobs=1, warnings=True, verbose=0, random_state=None) [source] ATOMRegressor is ATOM's wrapper for regression tasks. Use this class to easily apply all data transformations and model management provided by the package on a given dataset. Note that contrary to scikit-learn's API, the ATOMRegressor object already contains the dataset on which we want to perform the analysis. Calling a method will automatically apply it on the dataset it contains. You can predict , plot and call any model from the ATOMRegressor instance. Read more in the user guide . Parameters: *arrays: sequence of indexables Dataset containing the features and target. Allowed formats are: X, y train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) X, train, test: dict, list, tuple, np.array or pd.DataFrame Feature set with shape=(n_features, n_samples). If no y is provided, the last column is used as target. y: int, str or array-like If int: Position of the target column in X. If str: Name of the target column in X. Else: Data target column with shape=(n_samples,). n_rows: int or float, optional (default=1) If <=1: Fraction of the dataset to use. If >1: Number of rows to use (only if input is X, y). test_size: int, float, optional (default=0.2) If <=1: Fraction of the dataset to include in the test set. If >1: Number of rows to include in the test set. This parameter is ignored if the train and test set are provided. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. warnings: bool or str, optional (default=True) If True: Default warning action (equal to \"default\" when string). If False: Suppress all warnings (equal to \"ignore\" when string). If str: One of the possible actions in python's warnings environment. Note that changing this parameter will affect the PYTHONWARNINGS environment. Note that ATOM can't manage warnings that go directly from C++ code to the stdout/stderr. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" for default name. If class: python Logger object. Note that warnings will not be saved to the logger in any case. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"ATOMRegressor"},{"location":"API/ATOM/atomregressor/#attributes","text":"","title":"Attributes"},{"location":"API/ATOM/atomregressor/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling atom.train will return the training set. The data can also be changed through these properties, e.g. atom.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column.","title":"Data attributes"},{"location":"API/ATOM/atomregressor/#utility-attributes","text":"Attributes: genetic_features: pd.DataFrame Dataframe of the non-linear features created by the feature_generation method. Columns include: name: Name of the feature (automatically created). description: Operators used to create this feature. fitness: Fitness score. collinear: pd.DataFrame Dataframe of the collinear features removed by the feature_selection method. Columns include: drop_feature: name of the feature dropped by the method. correlated feature: Name of the correlated feature(s). correlation_value: Pearson correlation coefficient(s) of the feature pairs. models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. pipeline: pd.Series Series containing all classes fitted in the pipeline. Use this attribute only to access the individual classes. To visualize the pipeline, use atom 's __repr__ or plot_pipeline . results: pd.DataFrame Dataframe of the training results. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/ATOM/atomregressor/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/ATOM/atomregressor/#utility-methods","text":"The ATOM class contains a variety of methods to help you handle the data and inspect the pipeline. clear Remove a model from the pipeline. log Save information to the logger and print to stdout. report Get an extensive profile analysis of the data. save Save the instance to a pickle file. save_data Save data to a csv file. scoring Returns the scores of the models for a specific metric. stats Print out a list of basic statistics on the dataset. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str, list or tuple, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method report (dataset=\"dataset\", n_rows=None, filename=None) [source] Get an extensive profile analysis of the data. The report is rendered in HTML5 and CSS3 and saved to the profile attribute. Note that this method can be slow for n_rows > 10k. Parameters: df: str, optional (default=\"dataset\") Name of the data set to get the profile from. n_rows: int or None, optional (default=None) Number of (randomly picked) rows to process. None for all rows. filename: str or None, optional (default=None) Name of the file when saved (as .html). None to not save anything. method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method save_data (filename=None, dataset=\"dataset\") [source] Save data to a csv file. Parameters: filename: str or None, optional (default=None) Name of the saved file. None to use default name. dataset: str, optional (default=\"dataset\") Data set to save. method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method stats () [source] Print out a list of basic information on the dataset.","title":"Utility methods"},{"location":"API/ATOM/atomregressor/#data-cleaning","text":"ATOMRegressor provides data cleaning methods to scale your features and handle missing values, categorical columns and outliers. Calling on one of them will automatically apply the method on the dataset in the pipeline. Tip Use the report method to examine the data and help you determine suitable parameters for the data cleaning methods. scale Scale all the features to mean=1 and std=0. clean Applies standard data cleaning steps on the dataset. impute Handle missing values in the dataset. encode Encode categorical features. outliers Remove or replace outliers in the training set. method scale () [source] Scale the features to mean=1 and std=0. method clean (prohibited_types=None, strip_categorical=True, maximum_cardinality=True, minimum_cardinality=True, missing_target=True, map_target=None) [source] Applies standard data cleaning steps on the dataset. These steps can include: Strip categorical features from white spaces. Removing columns with prohibited data types. Removing categorical columns with maximal cardinality. Removing columns with minimum cardinality. Removing rows with missing values in the target column. Encode the target column. See Cleaner for a description of the parameters. method impute (strat_num=\"drop\", strat_cat=\"drop\", min_frac_rows=0.5, min_frac_cols=0.5, missing=None) [source] Handle missing values according to the selected strategy. Also removes rows and columns with too many missing values. The imputer is fitted only on the training set to avoid data leakage. Use the missing attribute to customize what are considered \"missing values\". See Imputer for a description of the parameters. Note that since the Imputer can remove rows from both train and test set, the set's sizes may change to keep ATOM's test_size ratio. method encode (strategy=\"LeaveOneOut\", max_onehot=10, frac_to_other=None) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: If n_unique=2, use Label-encoding. If 2 < n_unique <= max_onehot, use OneHot-encoding. If n_unique > max_onehot, use strategy -encoding. Also replaces classes with low occurrences with the value \"other\" in order to prevent too high cardinality. Categorical features are defined as all columns whose dtype.kind not in \"ifu\". Will raise an error if it encounters missing values or unknown classes when transforming. The encoder is fitted only on the training set to avoid data leakage. See Encoder for a description of the parameters. method outliers (strategy=\"drop\", max_sigma=3, include_target=False) [source] Remove or replace outliers in the training set. Outliers are defined as values that lie further than max_sigma * standard_deviation away from the mean of the column. Only outliers from the training set are removed to maintain an original sample of target values in the test set. Ignores categorical columns. See Outliers for a description of the parameters.","title":"Data cleaning"},{"location":"API/ATOM/atomregressor/#feature-engineering","text":"To further pre-process the data you can create new non-linear features transforming the existing ones or, if your dataset is too large, remove features using one of the provided strategies. feature_generation Create new features from combinations of existing ones. feature_selection Remove features according to the selected strategy. method feature_generation (strategy=\"DFS\", n_features=None, generations=20, population=500, operators=None) [source] Use Deep feature Synthesis or a genetic algorithm to create new combinations of existing features to capture the non-linear relations between the original features. See FeatureGenerator for a description of the parameters. Attributes created by the class are attached to the ATOM instance. method feature_selection (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=1., **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Also removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. See FeatureSelector for a description of the parameters. Plotting methods and attributes created by the class are attached to the instance. Note When strategy=\"univariate\" and solver=None, f_regression will be used as default solver. When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and the solver is one of ATOM's models, the algorithm will automatically select the classifier (no need to add _reg to the solver). When strategy is one of \"SFM\", \"RFE\" or \"RFECV\" and solver=None, ATOM will use the winning model (if it exists) as solver. When strategy=\"RFECV\", ATOM will use the metric in the pipeline (if it exists) as the scoring parameter (only if not specified manually).","title":"Feature engineering"},{"location":"API/ATOM/atomregressor/#training","text":"The training methods are where the models are fitted to the data and their performance is evaluated according to the selected metric. ATOMRegressor contains three methods to call the training classes from the ATOM package. All relevant attributes and methods from the training classes are attached to ATOMClassifier for convenience. These include the errors, winner and results attributes, the models , and the prediction and plotting methods. run Fit the models to the data in a direct fashion. successive_halving Fit the models to the data in a successive halving fashion. train_sizing Fit the models to the data in a train sizing fashion. method run (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainerRegressor instance. method successive_halving (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a SuccessiveHalvingRegressor instance. method train_sizing (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=0, n_initial_points=5, est_params={}, bo_params={}, bagging=None) [source] Runs a TrainSizingRegressor instance.","title":"Training"},{"location":"API/ATOM/atomregressor/#example","text":"from sklearn.datasets import load_boston from atom import ATOMRegressor X, y = load_boston(return_X_y=True) # Initialize class atom = ATOMRegressor(X, y, logger=\"auto\", n_jobs=2, verbose=2) # Apply data cleaning methods atom.outliers(strategy=\"min_max\", max_sigma=2, include_target=True) # Fit the models to the data atom.run( models=[\"OLS\", \"BR\", \"CatB\"], metric=\"MSE\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Analyze the results print(f\"The winning model is: {atom.winner.name}\") print(atom.results) # Make some plots atom.palette = \"Blues\" atom.plot_errors(figsize=(9, 6), filename=\"errors.png\") atom.CatB.plot_feature_importance(filename=\"catboost_feature_importance.png\") # Run an extra model atom.run( models=\"MLP\", metric=\"MSE\", n_calls=25, n_initial_points=10, bo_params={\"cv\": 1}, bagging=4 ) # Get the predictions for the best model on new data predictions = atom.predict(X_new)","title":"Example"},{"location":"API/data_cleaning/balancer/","text":"Balancer class atom.data_cleaning. Balancer (strategy=\"ADASYN\", n_jobs=1, verbose=0, logger=None, random_state=None, **kwargs) [source] Balance the number of rows per target class. Use only for classification tasks. This class can be accessed from atom through the balance method. Read more in the user guide . Parameters: strategy: str, optional (default=\"ADASYN\") Type of algorithm to use for oversampling or undersampling. Choose from one of the estimators available in the imbalanced-learn package. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . **kwargs Additional keyword arguments passed to the strategy estimator. Attributes Attributes: <estimator_name>: class Estimator instance (attribute name in all lowercase) used to oversample/undersample the data, e.g. balancer.adasyn for the default option. mapping: dict Dictionary of the target values mapped to their respective encoded integer. Methods fit_transform Same as transform. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit_transform (X, y) [source] Oversample or undersample the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Balancer Estimator instance. method transform (X, y) [source] Oversample or undersample the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.balance(strategy=\"NearMiss\", sampling_strategy=0.7, n_neighbors=10) or from atom.data_cleaning import Balancer balancer = Balancer(strategy=\"NearMiss\", sampling_strategy=0.7, n_neighbors=10) X_train, y_train = balancer.transform(X_train, y_train)","title":"Balancer"},{"location":"API/data_cleaning/balancer/#balancer","text":"class atom.data_cleaning. Balancer (strategy=\"ADASYN\", n_jobs=1, verbose=0, logger=None, random_state=None, **kwargs) [source] Balance the number of rows per target class. Use only for classification tasks. This class can be accessed from atom through the balance method. Read more in the user guide . Parameters: strategy: str, optional (default=\"ADASYN\") Type of algorithm to use for oversampling or undersampling. Choose from one of the estimators available in the imbalanced-learn package. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . **kwargs Additional keyword arguments passed to the strategy estimator.","title":"Balancer"},{"location":"API/data_cleaning/balancer/#attributes","text":"Attributes: <estimator_name>: class Estimator instance (attribute name in all lowercase) used to oversample/undersample the data, e.g. balancer.adasyn for the default option. mapping: dict Dictionary of the target values mapped to their respective encoded integer.","title":"Attributes"},{"location":"API/data_cleaning/balancer/#methods","text":"fit_transform Same as transform. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit_transform (X, y) [source] Oversample or undersample the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Balancer Estimator instance. method transform (X, y) [source] Oversample or undersample the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column.","title":"Methods"},{"location":"API/data_cleaning/balancer/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.balance(strategy=\"NearMiss\", sampling_strategy=0.7, n_neighbors=10) or from atom.data_cleaning import Balancer balancer = Balancer(strategy=\"NearMiss\", sampling_strategy=0.7, n_neighbors=10) X_train, y_train = balancer.transform(X_train, y_train)","title":"Example"},{"location":"API/data_cleaning/cleaner/","text":"Cleaner class atom.data_cleaning. Cleaner (prohibited_types=None, strip_categorical=True, maximum_cardinality=True, minimum_cardinality=True, missing_target=True, encode_target=True, verbose=0, logger=None) [source] Performs standard data cleaning steps on a dataset. Use the parameters to choose which transformations to perform. The available steps are: Remove columns with prohibited data types. Strip categorical features from white spaces. Remove categorical columns with maximal cardinality. Remove columns with minimum cardinality. Remove rows with missing values in the target column. Encode the target column. This class can be accessed from atom through the clean method. Read more in the user guide . Parameters: prohibited_types: str, iterable or None, optional (default=None) Columns with any of these types will be removed from the dataset. strip_categorical: bool, optional (default=True) Whether to strip the spaces from values in the categorical columns. maximum_cardinality: bool, optional (default=True) Whether to remove categorical columns with maximum cardinality, i.e. the number of unique values is equal to the number of instances. Usually the case for names, IDs, etc... minimum_cardinality: bool, optional (default=True) Whether to remove columns with minimum cardinality, i.e. all values in the column are the same. missing_target: bool, optional (default=True) Whether to remove rows with missing values in the target column. Ignored if y is not provided. encode_target: bool, optional (default=True) Whether to Label-encode the target column. Ignored if y is not provided. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. Attributes Attributes: missing: list List of values that are considered \"missing\". Default values are: \"\", \"?\", \"None\", \"NA\", \"nan\", \"NaN\" and \"inf\". Note that None , NaN , +inf and -inf are always considered missing since they are incompatible with sklearn estimators. mapping: dict Dictionary of the target values mapped to their respective encoded integer. Only available if encode_target=True. Methods fit_transform Same as transform. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit_transform (X, y=None) [source] Apply the data cleaning steps on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Cleaner Estimator instance. method transform (X, y=None) [source] Apply the data cleaning steps on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.clean() or from atom.data_cleaning import Cleaner cleaner = Cleaner(prohibited_types=\"datetime64\", maximum_cardinality=False) X, y = cleaner.transform(X, y)","title":"Cleaner"},{"location":"API/data_cleaning/cleaner/#cleaner","text":"class atom.data_cleaning. Cleaner (prohibited_types=None, strip_categorical=True, maximum_cardinality=True, minimum_cardinality=True, missing_target=True, encode_target=True, verbose=0, logger=None) [source] Performs standard data cleaning steps on a dataset. Use the parameters to choose which transformations to perform. The available steps are: Remove columns with prohibited data types. Strip categorical features from white spaces. Remove categorical columns with maximal cardinality. Remove columns with minimum cardinality. Remove rows with missing values in the target column. Encode the target column. This class can be accessed from atom through the clean method. Read more in the user guide . Parameters: prohibited_types: str, iterable or None, optional (default=None) Columns with any of these types will be removed from the dataset. strip_categorical: bool, optional (default=True) Whether to strip the spaces from values in the categorical columns. maximum_cardinality: bool, optional (default=True) Whether to remove categorical columns with maximum cardinality, i.e. the number of unique values is equal to the number of instances. Usually the case for names, IDs, etc... minimum_cardinality: bool, optional (default=True) Whether to remove columns with minimum cardinality, i.e. all values in the column are the same. missing_target: bool, optional (default=True) Whether to remove rows with missing values in the target column. Ignored if y is not provided. encode_target: bool, optional (default=True) Whether to Label-encode the target column. Ignored if y is not provided. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object.","title":"Cleaner"},{"location":"API/data_cleaning/cleaner/#attributes","text":"Attributes: missing: list List of values that are considered \"missing\". Default values are: \"\", \"?\", \"None\", \"NA\", \"nan\", \"NaN\" and \"inf\". Note that None , NaN , +inf and -inf are always considered missing since they are incompatible with sklearn estimators. mapping: dict Dictionary of the target values mapped to their respective encoded integer. Only available if encode_target=True.","title":"Attributes"},{"location":"API/data_cleaning/cleaner/#methods","text":"fit_transform Same as transform. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit_transform (X, y=None) [source] Apply the data cleaning steps on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Cleaner Estimator instance. method transform (X, y=None) [source] Apply the data cleaning steps on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided.","title":"Methods"},{"location":"API/data_cleaning/cleaner/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.clean() or from atom.data_cleaning import Cleaner cleaner = Cleaner(prohibited_types=\"datetime64\", maximum_cardinality=False) X, y = cleaner.transform(X, y)","title":"Example"},{"location":"API/data_cleaning/encoder/","text":"Encoder class atom.data_cleaning. Encoder (strategy=\"LeaveOneOut\", max_onehot=10, frac_to_other=None, verbose=0, logger=None, **kwargs) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: If n_unique=2, use Label-encoding. If 2 < n_unique <= max_onehot, use OneHot-encoding. If n_unique > max_onehot, use strategy -encoding. Also replaces classes with low occurrences with the value other in order to prevent too high cardinality. Categorical features are defined as all columns whose dtype.kind not in ifu . Will raise an error if it encounters missing values or unknown classes when transforming. This class can be accessed from atom through the encode method. Read more in the user guide . Parameters: strategy: str, optional (default=\"LeaveOneOut\") Type of encoding to use for high cardinality features. Choose from one of the estimators available in the category-encoders package except for: OneHotEncoder: Use the max_onehot parameter. HashingEncoder: Incompatibility of APIs. max_onehot: int or None, optional (default=10) Maximum number of unique values in a feature to perform one-hot-encoding. If None, it will always use strategy when n_unique > 2. frac_to_other: float, optional (default=None) Classes with less occurrences than n_rows * fraction_to_other are replaced with the string other . If None, skip this step. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. **kwargs Additional keyword arguments passed to the strategy estimator. Tip Use atom 's categorical attribute for a list of the categorical columns in the dataset. Methods fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: self: Encoder Fitted instance of self. method fit_transform (X, y) [source] Fit the Encoder and return the encoded data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Encoder Estimator instance. method transform (X, y=None) [source] Encode the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Transformed feature set. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.encode(strategy=\"CatBoost\", max_onehot=5) or from atom.data_cleaning import Encoder encoder = Encoder(strategy=\"CatBoost\", max_onehot=5) encoder.fit(X_train, y_train) X = encoder.transform(X)","title":"Encoder"},{"location":"API/data_cleaning/encoder/#encoder","text":"class atom.data_cleaning. Encoder (strategy=\"LeaveOneOut\", max_onehot=10, frac_to_other=None, verbose=0, logger=None, **kwargs) [source] Perform encoding of categorical features. The encoding type depends on the number of unique values in the column: If n_unique=2, use Label-encoding. If 2 < n_unique <= max_onehot, use OneHot-encoding. If n_unique > max_onehot, use strategy -encoding. Also replaces classes with low occurrences with the value other in order to prevent too high cardinality. Categorical features are defined as all columns whose dtype.kind not in ifu . Will raise an error if it encounters missing values or unknown classes when transforming. This class can be accessed from atom through the encode method. Read more in the user guide . Parameters: strategy: str, optional (default=\"LeaveOneOut\") Type of encoding to use for high cardinality features. Choose from one of the estimators available in the category-encoders package except for: OneHotEncoder: Use the max_onehot parameter. HashingEncoder: Incompatibility of APIs. max_onehot: int or None, optional (default=10) Maximum number of unique values in a feature to perform one-hot-encoding. If None, it will always use strategy when n_unique > 2. frac_to_other: float, optional (default=None) Classes with less occurrences than n_rows * fraction_to_other are replaced with the string other . If None, skip this step. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. **kwargs Additional keyword arguments passed to the strategy estimator. Tip Use atom 's categorical attribute for a list of the categorical columns in the dataset.","title":"Encoder"},{"location":"API/data_cleaning/encoder/#methods","text":"fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: self: Encoder Fitted instance of self. method fit_transform (X, y) [source] Fit the Encoder and return the encoded data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Encoder Estimator instance. method transform (X, y=None) [source] Encode the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Transformed feature set.","title":"Methods"},{"location":"API/data_cleaning/encoder/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.encode(strategy=\"CatBoost\", max_onehot=5) or from atom.data_cleaning import Encoder encoder = Encoder(strategy=\"CatBoost\", max_onehot=5) encoder.fit(X_train, y_train) X = encoder.transform(X)","title":"Example"},{"location":"API/data_cleaning/imputer/","text":"Imputer class atom.data_cleaning. Imputer (strat_num=\"drop\", strat_cat=\"drop\", min_frac_rows=0.5, min_frac_cols=0.5, verbose=0, logger=None) [source] Impute or remove missing values according to the selected strategy. Also removes rows and columns with too many missing values. Use the missing attribute to customize what are considered \"missing values\". This class can be accessed from atom through the impute method. Read more in the user guide . Parameters: strat_num: str, int or float, optional (default=\"drop\") Imputing strategy for numerical columns. Choose from: \"drop\": Drop rows containing missing values. \"mean\": Impute with mean of column. \"median\": Impute with median of column. \"knn\": Impute using a K-Nearest Neighbors approach. \"most_frequent\": Impute with most frequent value. int or float: Impute with provided numerical value. strat_cat: str, optional (default=\"drop\") Imputing strategy for categorical columns. Choose from: \"drop\": Drop rows containing missing values. \"most_frequent\": Impute with most frequent value. str: Impute with provided string. min_frac_rows: float, optional (default=0.5) Minimum fraction of non-missing values in a row. If less, the row is removed. min_frac_cols: float, optional (default=0.5) Minimum fraction of non-missing values in a column. If less, the column is removed. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. Tip Use atom 's nans attribute for an overview of the missing values in the dataset. Attributes Attributes: missing: list List of values that are considered \"missing\". Default values are: \"\", \"?\", \"None\", \"NA\", \"nan\", \"NaN\" and \"inf\". Note that None , NaN , +inf and -inf are always considered missing since they are incompatible with sklearn estimators. Methods fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y=None) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: self: Imputer Fitted instance of self. method fit_transform (X, y=None) [source] Fit the Imputer and return the imputed data. Warning Leaving y=None can lead to inconsistencies in data length between X and y if rows are dropped during the transformation. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: imputer Estimator instance. method transform (X, y=None) [source] Impute the data. Warning Leaving y=None can lead to inconsistencies in data length between X and y if rows are dropped during the transformation. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,) Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.impute(strat_num=\"knn\", strat_cat=\"drop\", min_frac_cols=0.8) or from atom.data_cleaning import Imputer imputer = Imputer(strat_num=\"knn\", strat_cat=\"drop\", min_frac_cols=0.8) imputer.fit(X_train, y_train) X = imputer.transform(X)","title":"Imputer"},{"location":"API/data_cleaning/imputer/#imputer","text":"class atom.data_cleaning. Imputer (strat_num=\"drop\", strat_cat=\"drop\", min_frac_rows=0.5, min_frac_cols=0.5, verbose=0, logger=None) [source] Impute or remove missing values according to the selected strategy. Also removes rows and columns with too many missing values. Use the missing attribute to customize what are considered \"missing values\". This class can be accessed from atom through the impute method. Read more in the user guide . Parameters: strat_num: str, int or float, optional (default=\"drop\") Imputing strategy for numerical columns. Choose from: \"drop\": Drop rows containing missing values. \"mean\": Impute with mean of column. \"median\": Impute with median of column. \"knn\": Impute using a K-Nearest Neighbors approach. \"most_frequent\": Impute with most frequent value. int or float: Impute with provided numerical value. strat_cat: str, optional (default=\"drop\") Imputing strategy for categorical columns. Choose from: \"drop\": Drop rows containing missing values. \"most_frequent\": Impute with most frequent value. str: Impute with provided string. min_frac_rows: float, optional (default=0.5) Minimum fraction of non-missing values in a row. If less, the row is removed. min_frac_cols: float, optional (default=0.5) Minimum fraction of non-missing values in a column. If less, the column is removed. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. Tip Use atom 's nans attribute for an overview of the missing values in the dataset.","title":"Imputer"},{"location":"API/data_cleaning/imputer/#attributes","text":"Attributes: missing: list List of values that are considered \"missing\". Default values are: \"\", \"?\", \"None\", \"NA\", \"nan\", \"NaN\" and \"inf\". Note that None , NaN , +inf and -inf are always considered missing since they are incompatible with sklearn estimators.","title":"Attributes"},{"location":"API/data_cleaning/imputer/#methods","text":"fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y=None) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: self: Imputer Fitted instance of self. method fit_transform (X, y=None) [source] Fit the Imputer and return the imputed data. Warning Leaving y=None can lead to inconsistencies in data length between X and y if rows are dropped during the transformation. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: imputer Estimator instance. method transform (X, y=None) [source] Impute the data. Warning Leaving y=None can lead to inconsistencies in data length between X and y if rows are dropped during the transformation. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,) Returns: X: pd.DataFrame Transformed feature set. y: pd.Series Transformed target column. Only returned if provided.","title":"Methods"},{"location":"API/data_cleaning/imputer/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.impute(strat_num=\"knn\", strat_cat=\"drop\", min_frac_cols=0.8) or from atom.data_cleaning import Imputer imputer = Imputer(strat_num=\"knn\", strat_cat=\"drop\", min_frac_cols=0.8) imputer.fit(X_train, y_train) X = imputer.transform(X)","title":"Example"},{"location":"API/data_cleaning/outliers/","text":"Outliers class atom.data_cleaning. Outliers (strategy=\"drop\", max_sigma=3, include_target=False, verbose=0, logger=None) [source] Remove or replace outliers in the data. Outliers are defined as values that lie further than max_sigma * standard_deviation away from the mean of the column. Ignores categorical columns. This class can be accessed from atom through the outliers method. Read more in the user guide . Parameters: strategy: int, float or str, optional (default=\"drop\") Strategy to apply on the outliers. Choose from: \"drop\": Drop any row with outliers. \"min_max\": Replace the outlier with the min or max of the column. Any numerical value with which to replace the outliers. max_sigma: int or float, optional (default=3) Maximum allowed standard deviations from the mean of the column. If more, it is considered an outlier. include_target: bool, optional (default=False) Whether to include the target column in the transformation. This can be useful for regression tasks. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. Methods fit_transform Same as transform. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit_transform (X, y=None) [source] Apply the outlier strategy on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column. Only returned if provided. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Outliers Estimator instance. method transform (X, y=None) [source] Apply the outlier strategy on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column. Only returned if provided. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.outliers(strategy=\"min_max\", max_sigma=2, include_target=True) or from atom.data_cleaning import Outliers outliers = Outliers(strategy=\"min_max\", max_sigma=2, include_target=True) X_train, y_train = outliers.transform(X_train, y_train)","title":"Outliers"},{"location":"API/data_cleaning/outliers/#outliers","text":"class atom.data_cleaning. Outliers (strategy=\"drop\", max_sigma=3, include_target=False, verbose=0, logger=None) [source] Remove or replace outliers in the data. Outliers are defined as values that lie further than max_sigma * standard_deviation away from the mean of the column. Ignores categorical columns. This class can be accessed from atom through the outliers method. Read more in the user guide . Parameters: strategy: int, float or str, optional (default=\"drop\") Strategy to apply on the outliers. Choose from: \"drop\": Drop any row with outliers. \"min_max\": Replace the outlier with the min or max of the column. Any numerical value with which to replace the outliers. max_sigma: int or float, optional (default=3) Maximum allowed standard deviations from the mean of the column. If more, it is considered an outlier. include_target: bool, optional (default=False) Whether to include the target column in the transformation. This can be useful for regression tasks. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object.","title":"Outliers"},{"location":"API/data_cleaning/outliers/#methods","text":"fit_transform Same as transform. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit_transform (X, y=None) [source] Apply the outlier strategy on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column. Only returned if provided. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Outliers Estimator instance. method transform (X, y=None) [source] Apply the outlier strategy on the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. X: pd.Series Transformed target column. Only returned if provided.","title":"Methods"},{"location":"API/data_cleaning/outliers/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.outliers(strategy=\"min_max\", max_sigma=2, include_target=True) or from atom.data_cleaning import Outliers outliers = Outliers(strategy=\"min_max\", max_sigma=2, include_target=True) X_train, y_train = outliers.transform(X_train, y_train)","title":"Example"},{"location":"API/data_cleaning/scaler/","text":"Scaler class atom.data_cleaning. Scaler (verbose=0, logger=None) [source] Scales data to mean=0 and std=1. This method is equal to sklearn's StandardScaler except that it returns a dataframe when provided. This class can be accessed from atom through the scale method. Read more in the user guide . Parameters: verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. Attributes Attributes: standard_scaler: StandardScaler Instance with which the data is scaled. Methods fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y=None) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: self: Scaler Fitted instance of self. method fit_transform (X, y=None) [source] Fit the Scaler and return the scaled data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Scaled feature set. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Scaler Estimator instance. method transform (X, y=None) [source] Scale the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Scaled feature set. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.scale() or from atom.data_cleaning import Scaler scaler = Scaler() scaler.fit(X_train) X = scaler.transform(X)","title":"Scaler"},{"location":"API/data_cleaning/scaler/#scaler","text":"class atom.data_cleaning. Scaler (verbose=0, logger=None) [source] Scales data to mean=0 and std=1. This method is equal to sklearn's StandardScaler except that it returns a dataframe when provided. This class can be accessed from atom through the scale method. Read more in the user guide . Parameters: verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object.","title":"Scaler"},{"location":"API/data_cleaning/scaler/#attributes","text":"Attributes: standard_scaler: StandardScaler Instance with which the data is scaled.","title":"Attributes"},{"location":"API/data_cleaning/scaler/#methods","text":"fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y=None) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: self: Scaler Fitted instance of self. method fit_transform (X, y=None) [source] Fit the Scaler and return the scaled data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Scaled feature set. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: Scaler Estimator instance. method transform (X, y=None) [source] Scale the data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Scaled feature set.","title":"Methods"},{"location":"API/data_cleaning/scaler/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.scale() or from atom.data_cleaning import Scaler scaler = Scaler() scaler.fit(X_train) X = scaler.transform(X)","title":"Example"},{"location":"API/feature_engineering/feature_generator/","text":"FeatureGenerator class atom.feature_engineering. FeatureGenerator (strategy=\"DFS\", n_features=None, generations=20, population=500, operators=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Use Deep feature Synthesis or a genetic algorithm to create new combinations of existing features to capture the non-linear relations between the original features. This class can be accessed from atom through the feature_generation method. Read more in the user guide . Parameters: strategy: str, optional (default=\"DFS\") Strategy to crate new features. Choose from: \"DFS\" to use Deep Feature Synthesis. \"GFG\" or \"genetic\" to use Genetic Feature Generation. n_features: int or None, optional (default=None) Number of newly generated features to add to the dataset. No more than 1% of the population (for the genetic strategy). If None, select all created. generations: int, optional (default=20) Number of generations to evolve. Only for the genetic strategy. population: int, optional (default=500) Number of programs in each generation. Only for the genetic strategy. operators: str, list, tuple or None, optional (default=None) Name of the operators to be used on the features (for both strategies). None to use all. Valid options are: \"add\", \"sub\", \"mul\", \"div\", \"sqrt\", \"log\", \"sin\", \"cos\", \"tan\". n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Tip DFS can create many new features and not all of them will be useful. Use FeatureSelector to reduce the number of features! Warning Using the div, log or sqrt operators can return new features with inf or NaN values. Check the warnings that may pop up or use atom 's missing property. Warning When using DFS with n_jobs>1 , make sure to protect your code with if __name__ == \"__main__\" . Featuretools uses dask , which uses python multiprocessing for parallelization. The spawn method on multiprocessing starts a new python process, which requires it to import the __main__ module before it can do its task. Attributes Attributes: symbolic_transformer: SymbolicTransformer Instance used to calculate the genetic features. Only for the genetic strategy. genetic_features: pd.DataFrame Dataframe of the newly created non-linear features. Only for the genetic strategy. Columns include: name: Name of the feature (automatically created). description: Operators used to create this feature. fitness: Fitness score. Methods fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: self: FeatureGenerator Fitted instance of self. method fit_transform (X, y) [source] Fit the FeatureGenerator and return the transformed data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Feature set with the newly generated features. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: FeatureGenerator Estimator instance. method transform (X, y=None) [source] Generate new features. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, array-like or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Feature set with the newly generated features. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_generation(strategy=\"genetic\", n_features=3, generations=30, population=400) or from atom.feature_engineering import FeatureGenerator feature_generator = FeatureGenerator(strategy=\"genetic\", n_features=3, generations=30, population=400) feature_generator.fit(X_train, y_train) X = feature_generator.transform(X)","title":"FeatureGenerator"},{"location":"API/feature_engineering/feature_generator/#featuregenerator","text":"class atom.feature_engineering. FeatureGenerator (strategy=\"DFS\", n_features=None, generations=20, population=500, operators=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Use Deep feature Synthesis or a genetic algorithm to create new combinations of existing features to capture the non-linear relations between the original features. This class can be accessed from atom through the feature_generation method. Read more in the user guide . Parameters: strategy: str, optional (default=\"DFS\") Strategy to crate new features. Choose from: \"DFS\" to use Deep Feature Synthesis. \"GFG\" or \"genetic\" to use Genetic Feature Generation. n_features: int or None, optional (default=None) Number of newly generated features to add to the dataset. No more than 1% of the population (for the genetic strategy). If None, select all created. generations: int, optional (default=20) Number of generations to evolve. Only for the genetic strategy. population: int, optional (default=500) Number of programs in each generation. Only for the genetic strategy. operators: str, list, tuple or None, optional (default=None) Name of the operators to be used on the features (for both strategies). None to use all. Valid options are: \"add\", \"sub\", \"mul\", \"div\", \"sqrt\", \"log\", \"sin\", \"cos\", \"tan\". n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Tip DFS can create many new features and not all of them will be useful. Use FeatureSelector to reduce the number of features! Warning Using the div, log or sqrt operators can return new features with inf or NaN values. Check the warnings that may pop up or use atom 's missing property. Warning When using DFS with n_jobs>1 , make sure to protect your code with if __name__ == \"__main__\" . Featuretools uses dask , which uses python multiprocessing for parallelization. The spawn method on multiprocessing starts a new python process, which requires it to import the __main__ module before it can do its task.","title":"FeatureGenerator"},{"location":"API/feature_engineering/feature_generator/#attributes","text":"Attributes: symbolic_transformer: SymbolicTransformer Instance used to calculate the genetic features. Only for the genetic strategy. genetic_features: pd.DataFrame Dataframe of the newly created non-linear features. Only for the genetic strategy. Columns include: name: Name of the feature (automatically created). description: Operators used to create this feature. fitness: Fitness score.","title":"Attributes"},{"location":"API/feature_engineering/feature_generator/#methods","text":"fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y) [source] Fit the class. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: self: FeatureGenerator Fitted instance of self. method fit_transform (X, y) [source] Fit the FeatureGenerator and return the transformed data. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str or array-like If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Feature set with the newly generated features. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: FeatureGenerator Estimator instance. method transform (X, y=None) [source] Generate new features. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, array-like or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Feature set with the newly generated features.","title":"Methods"},{"location":"API/feature_engineering/feature_generator/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_generation(strategy=\"genetic\", n_features=3, generations=30, population=400) or from atom.feature_engineering import FeatureGenerator feature_generator = FeatureGenerator(strategy=\"genetic\", n_features=3, generations=30, population=400) feature_generator.fit(X_train, y_train) X = feature_generator.transform(X)","title":"Example"},{"location":"API/feature_engineering/feature_selector/","text":"FeatureSelector class atom.feature_engineering. FeatureSelector (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=1., n_jobs=1, verbose=0, logger=None, random_state=None, **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Additionally, removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. This class can be accessed from atom through the feature_selection method. Read more in the user guide . Parameters: strategy: string or None, optional (default=None) Feature selection strategy to use. Choose from: None: Do not perform any feature selection algorithm. \"univariate\": Select best features according to a univariate F-test. \"PCA\": Perform principal component analysis. \"SFM\": Select best features according to a model. \"RFE\": Perform recursive feature elimination. \"RFECV\": Perform RFE with cross-validated selection. solver: string, callable or None, optional (default=None) Solver or model to use for the feature selection strategy. See the sklearn documentation for an extended description of the choices. Select None for the default option per strategy (not applicable for SFM, RFE and RFECV). for \"univariate\", choose from: \"f_classif\" \"f_regression\" \"mutual_info_classif\" \"mutual_info_regression\" \"chi2\" Any function taking two arrays (X, y), and returning arrays (scores, p-values). See the sklearn documentation . for \"PCA\", choose from: \"auto\" (default) \"full\" \"arpack\" \"randomized\" for \"SFM\", \"RFE\" and \"RFECV: Estimator with either a feature_importances_ or coef_ attribute after fitting. You can use one of ATOM's pre-defined models . Add _class or _reg after the model's name to specify a classification or regression task, e.g. solver=\"LGB_reg\" (not necessary if called from an atom instance. No default option. n_features: int, float or None, optional (default=None) Number of features to select. Choose from: if None: Select all features. if < 1: Fraction of the total features to select. if >= 1: Number of features to select. If strategy=\"SFM\" and the threshold parameter is not specified, the threshold will be set to -np.inf in order to make this parameter the number of features to select. If strategy=\"RFECV\", it's the minimum number of features to select. max_frac_repeated: float or None, optional (default=1.) Remove features with the same value in at least this fraction of the total rows. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples. None to skip this step. max_correlation: float or None, optional (default=1.) Minimum value of the Pearson correlation coefficient to identify correlated features. A value of 1 removes on of 2 equal columns. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. None to skip this step. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . **kwargs Any extra keyword argument for the PCA, SFM, RFE or RFECV estimators. See the corresponding sklearn documentation for the available options. Tip Use the plot_feature_importance method to examine how much a specific feature contributes to the final predictions. If the model doesn't have a feature_importances_ attribute, use plot_permutation_importance instead. Warning The RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs. Attributes Utility attributes Attributes: collinear: pd.DataFrame Dataframe of the removed collinear features. Columns include: drop_feature: Name of the feature dropped by the method. correlated feature: Name of the correlated feature(s). correlation_value: Pearson correlation coefficient(s) of the feature pairs. feature_importance: list Remaining features ordered by importance. Only if strategy in [\"univariate\", \"SFM, \"RFE\", \"RFECV\"]. For RFE and RFECV, the importance is extracted from the external estimator fitted on the reduced set. univariate: SelectKBest Instance used to fit the estimator. Only if strategy=\"univariate\". scaler: Scaler Instance used to scale the data. Only if strategy=\"PCA\" and the data was not already scaled. pca: PCA Instance used to fit the estimator. Only if strategy=\"PCA\". sfm: SelectFromModel Instance used to fit the estimator. Only if strategy=\"SFM\". rfe: RFE Instance used to fit the estimator. Only if strategy=\"RFE\". rfecv: RFECV Instance used to fit the estimator. Only if strategy=\"RFECV\". Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Methods fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. plot_pca Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per component. plot_rfecv Plot the scores obtained by the estimator on the RFECV. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y=None) [source] Fit the class. Note that the univariate, sfm (when model is not fitted), rfe and rfecv strategies all need a target column. Leaving it None will raise an exception. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: self: FeatureSelector Fitted instance of self. method fit_transform (X, y) [source] Fit the FeatureSelector and return the transformed feature set. Note that the univariate, sfm (when model is not fitted), rfe and rfecv strategies need a target column. Leaving it None will raise an exception. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method plot_pca (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of components. See plot_pca for a description of the parameters. method plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. See plot_components for a description of the parameters. method plot_rfecv (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the scores obtained by the estimator fitted on every subset of the data. See plot_rfecv for a description of the parameters. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: FeatureSelector Estimator instance. method transform (X, y=None) [source] Transform the feature set. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Transformed feature set. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(stratgey=\"pca\", n_features=12, whiten=True, max_correlation=0.96) atom.plot_pca(filename=\"pca\", figsize=(8, 5)) or from atom.feature_engineering import FeatureSelector feature_selector = FeatureSelector(stratgey=\"pca\", n_features=12, whiten=True, max_correlation=0.96) feature_selector.fit(X_train, y_train) X = feature_selector.transform(X, y) feature_selector.plot_pca(filename=\"pca\", figsize=(8, 5))","title":"FeatureSelector"},{"location":"API/feature_engineering/feature_selector/#featureselector","text":"class atom.feature_engineering. FeatureSelector (strategy=None, solver=None, n_features=None, max_frac_repeated=1., max_correlation=1., n_jobs=1, verbose=0, logger=None, random_state=None, **kwargs) [source] Remove features according to the selected strategy. Ties between features with equal scores will be broken in an unspecified way. Additionally, removes features with too low variance and finds pairs of collinear features based on the Pearson correlation coefficient. For each pair above the specified limit (in terms of absolute value), it removes one of the two. This class can be accessed from atom through the feature_selection method. Read more in the user guide . Parameters: strategy: string or None, optional (default=None) Feature selection strategy to use. Choose from: None: Do not perform any feature selection algorithm. \"univariate\": Select best features according to a univariate F-test. \"PCA\": Perform principal component analysis. \"SFM\": Select best features according to a model. \"RFE\": Perform recursive feature elimination. \"RFECV\": Perform RFE with cross-validated selection. solver: string, callable or None, optional (default=None) Solver or model to use for the feature selection strategy. See the sklearn documentation for an extended description of the choices. Select None for the default option per strategy (not applicable for SFM, RFE and RFECV). for \"univariate\", choose from: \"f_classif\" \"f_regression\" \"mutual_info_classif\" \"mutual_info_regression\" \"chi2\" Any function taking two arrays (X, y), and returning arrays (scores, p-values). See the sklearn documentation . for \"PCA\", choose from: \"auto\" (default) \"full\" \"arpack\" \"randomized\" for \"SFM\", \"RFE\" and \"RFECV: Estimator with either a feature_importances_ or coef_ attribute after fitting. You can use one of ATOM's pre-defined models . Add _class or _reg after the model's name to specify a classification or regression task, e.g. solver=\"LGB_reg\" (not necessary if called from an atom instance. No default option. n_features: int, float or None, optional (default=None) Number of features to select. Choose from: if None: Select all features. if < 1: Fraction of the total features to select. if >= 1: Number of features to select. If strategy=\"SFM\" and the threshold parameter is not specified, the threshold will be set to -np.inf in order to make this parameter the number of features to select. If strategy=\"RFECV\", it's the minimum number of features to select. max_frac_repeated: float or None, optional (default=1.) Remove features with the same value in at least this fraction of the total rows. The default is to keep all features with non-zero variance, i.e. remove the features that have the same value in all samples. None to skip this step. max_correlation: float or None, optional (default=1.) Minimum value of the Pearson correlation coefficient to identify correlated features. A value of 1 removes on of 2 equal columns. A dataframe of the removed features and their correlation values can be accessed through the collinear attribute. None to skip this step. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . **kwargs Any extra keyword argument for the PCA, SFM, RFE or RFECV estimators. See the corresponding sklearn documentation for the available options. Tip Use the plot_feature_importance method to examine how much a specific feature contributes to the final predictions. If the model doesn't have a feature_importances_ attribute, use plot_permutation_importance instead. Warning The RFE and RFECV strategies don't work when the solver is a CatBoost model due to incompatibility of the APIs.","title":"FeatureSelector"},{"location":"API/feature_engineering/feature_selector/#attributes","text":"","title":"Attributes"},{"location":"API/feature_engineering/feature_selector/#utility-attributes","text":"Attributes: collinear: pd.DataFrame Dataframe of the removed collinear features. Columns include: drop_feature: Name of the feature dropped by the method. correlated feature: Name of the correlated feature(s). correlation_value: Pearson correlation coefficient(s) of the feature pairs. feature_importance: list Remaining features ordered by importance. Only if strategy in [\"univariate\", \"SFM, \"RFE\", \"RFECV\"]. For RFE and RFECV, the importance is extracted from the external estimator fitted on the reduced set. univariate: SelectKBest Instance used to fit the estimator. Only if strategy=\"univariate\". scaler: Scaler Instance used to scale the data. Only if strategy=\"PCA\" and the data was not already scaled. pca: PCA Instance used to fit the estimator. Only if strategy=\"PCA\". sfm: SelectFromModel Instance used to fit the estimator. Only if strategy=\"SFM\". rfe: RFE Instance used to fit the estimator. Only if strategy=\"RFE\". rfecv: RFECV Instance used to fit the estimator. Only if strategy=\"RFECV\".","title":"Utility attributes"},{"location":"API/feature_engineering/feature_selector/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/feature_engineering/feature_selector/#methods","text":"fit Fit the class. fit_transform Fit the class and return the transformed data. get_params Get parameters for this estimator. log Write information to the logger and print to stdout. plot_pca Plot the explained variance ratio vs the number of components. plot_components Plot the explained variance ratio per component. plot_rfecv Plot the scores obtained by the estimator on the RFECV. save Save the instance to a pickle file. set_params Set the parameters of this estimator. transform Transform the data. method fit (X, y=None) [source] Fit the class. Note that the univariate, sfm (when model is not fitted), rfe and rfecv strategies all need a target column. Leaving it None will raise an exception. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: self: FeatureSelector Fitted instance of self. method fit_transform (X, y) [source] Fit the FeatureSelector and return the transformed feature set. Note that the univariate, sfm (when model is not fitted), rfe and rfecv strategies need a target column. Leaving it None will raise an exception. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformation. If int: Index of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). Returns: X: pd.DataFrame Transformed feature set. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method plot_pca (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of components. See plot_pca for a description of the parameters. method plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. See plot_components for a description of the parameters. method plot_rfecv (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the scores obtained by the estimator fitted on every subset of the data. See plot_rfecv for a description of the parameters. method save (filename=None) [source] Save the instance to a pickle file. Parameters: filename: str or None, optional (default=None) Name to save the file with. None to save with default name. method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: FeatureSelector Estimator instance. method transform (X, y=None) [source] Transform the feature set. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) Does nothing. Implemented for continuity of the API. Returns: X: pd.DataFrame Transformed feature set.","title":"Methods"},{"location":"API/feature_engineering/feature_selector/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(stratgey=\"pca\", n_features=12, whiten=True, max_correlation=0.96) atom.plot_pca(filename=\"pca\", figsize=(8, 5)) or from atom.feature_engineering import FeatureSelector feature_selector = FeatureSelector(stratgey=\"pca\", n_features=12, whiten=True, max_correlation=0.96) feature_selector.fit(X_train, y_train) X = feature_selector.transform(X, y) feature_selector.plot_pca(filename=\"pca\", figsize=(8, 5))","title":"Example"},{"location":"API/models/adab/","text":"AdaBoost (AdaB) AdaBoost is a meta-estimator that begins by fitting a classifier/regressor on the original dataset and then fits additional copies of the algorithm on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. Corresponding estimators are: AdaBoostClassifier for classification tasks. AdaBoostRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The algorithm parameter is only used with AdaBoostClassifier. The loss parameter is only used with AdaBoostRegressor. The random_state parameter is set equal to that of the training instance. Dimensions: n_estimators: int, default=50 Integer(10, 500, name=\"n_estimators\") learning_rate: float, default=1.0 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") algorithm: str, default=\"SAMME.R\" Categorical([\"SAMME.R\", \"SAMME\"], name=\"algorithm\") loss: str, default=\"linear\" Categorical([\"linear\", \"square\", \"exponential\"], name=\"loss\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.adab.plot_permutation_importance() or atom.adab.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"AdaB\", metric=\"poisson\", est_params={\"algorithm\": \"SAMME.R\"})","title":"AdaBoost"},{"location":"API/models/adab/#adaboost-adab","text":"AdaBoost is a meta-estimator that begins by fitting a classifier/regressor on the original dataset and then fits additional copies of the algorithm on the same dataset but where the weights of instances are adjusted according to the error of the current prediction. Corresponding estimators are: AdaBoostClassifier for classification tasks. AdaBoostRegressor for regression tasks. Read more in sklearn's documentation .","title":"AdaBoost (AdaB)"},{"location":"API/models/adab/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The algorithm parameter is only used with AdaBoostClassifier. The loss parameter is only used with AdaBoostRegressor. The random_state parameter is set equal to that of the training instance. Dimensions: n_estimators: int, default=50 Integer(10, 500, name=\"n_estimators\") learning_rate: float, default=1.0 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") algorithm: str, default=\"SAMME.R\" Categorical([\"SAMME.R\", \"SAMME\"], name=\"algorithm\") loss: str, default=\"linear\" Categorical([\"linear\", \"square\", \"exponential\"], name=\"loss\")","title":"Hyperparameters"},{"location":"API/models/adab/#attributes","text":"","title":"Attributes"},{"location":"API/models/adab/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/adab/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/adab/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/adab/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.adab.plot_permutation_importance() or atom.adab.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/adab/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"AdaB\", metric=\"poisson\", est_params={\"algorithm\": \"SAMME.R\"})","title":"Example"},{"location":"API/models/ard/","text":"Automatic Relevance Determination (ARD) Automatic Relevance Determination is very similar to Bayesian Ridge , but can lead to sparser coefficients. Fit the weights of a regression model, using an ARD prior. The weights of the regression model are assumed to be in Gaussian distributions. Corresponding estimators are: ARDRegression for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: n_iter: float, default=300 Integer(100, 1000, name=\"n_iter\") alpha_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_1\") alpha_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_2\") lambda_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_1\") lambda_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_2\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.ard.plot_permutation_importance() or atom.ard.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"ARD\", n_calls=20, n_initial_points=7, bagging=5)","title":"Automated Relevance Determination"},{"location":"API/models/ard/#automatic-relevance-determination-ard","text":"Automatic Relevance Determination is very similar to Bayesian Ridge , but can lead to sparser coefficients. Fit the weights of a regression model, using an ARD prior. The weights of the regression model are assumed to be in Gaussian distributions. Corresponding estimators are: ARDRegression for regression tasks. Read more in sklearn's documentation .","title":"Automatic Relevance Determination (ARD)"},{"location":"API/models/ard/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: n_iter: float, default=300 Integer(100, 1000, name=\"n_iter\") alpha_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_1\") alpha_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_2\") lambda_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_1\") lambda_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_2\")","title":"Hyperparameters"},{"location":"API/models/ard/#attributes","text":"","title":"Attributes"},{"location":"API/models/ard/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/ard/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/ard/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/ard/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.ard.plot_permutation_importance() or atom.ard.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/ard/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"ARD\", n_calls=20, n_initial_points=7, bagging=5)","title":"Example"},{"location":"API/models/bag/","text":"Bagging (Bag) Bagging uses an ensemble meta-estimator that fits base classifiers/regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree ), by introducing randomization into its construction procedure and then making an ensemble out of it. Corresponding estimators are: BaggingClassifier for classification tasks. BaggingRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=10 Integer(10, 500, name=\"n_estimators\") max_samples: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"max_samples\") max_features: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"max_features\") bootstrap: bool, default=True Categorical([True, False], name=\"bootstrap\") bootstrap_features: bool, default=False Categorical([True, False], name=\"bootstrap_features\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.bag.plot_permutation_importance() or atom.bag.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Bag\")","title":"Bagging"},{"location":"API/models/bag/#bagging-bag","text":"Bagging uses an ensemble meta-estimator that fits base classifiers/regressors each on random subsets of the original dataset and then aggregate their individual predictions (either by voting or by averaging) to form a final prediction. Such a meta-estimator can typically be used as a way to reduce the variance of a black-box estimator (e.g., a decision tree ), by introducing randomization into its construction procedure and then making an ensemble out of it. Corresponding estimators are: BaggingClassifier for classification tasks. BaggingRegressor for regression tasks. Read more in sklearn's documentation .","title":"Bagging (Bag)"},{"location":"API/models/bag/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=10 Integer(10, 500, name=\"n_estimators\") max_samples: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"max_samples\") max_features: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"max_features\") bootstrap: bool, default=True Categorical([True, False], name=\"bootstrap\") bootstrap_features: bool, default=False Categorical([True, False], name=\"bootstrap_features\")","title":"Hyperparameters"},{"location":"API/models/bag/#attributes","text":"","title":"Attributes"},{"location":"API/models/bag/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/bag/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/bag/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/bag/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.bag.plot_permutation_importance() or atom.bag.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/bag/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Bag\")","title":"Example"},{"location":"API/models/bnb/","text":"Bernoulli Naive Bayes (BNB) Bernoulli Naive Bayes implements the Naive Bayes algorithm for multivariate Bernoulli models. Like Multinomial Naive bayes (MNB) , this classifier is suitable for discrete data. The difference is that while MNB works with occurrence counts, BNB is designed for binary/boolean features. Corresponding estimators are: BernoulliNB for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.bnb.plot_permutation_importance() or atom.bnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"BNB\", metric=\"precision\")","title":"Bernoulli Naive Bayes"},{"location":"API/models/bnb/#bernoulli-naive-bayes-bnb","text":"Bernoulli Naive Bayes implements the Naive Bayes algorithm for multivariate Bernoulli models. Like Multinomial Naive bayes (MNB) , this classifier is suitable for discrete data. The difference is that while MNB works with occurrence counts, BNB is designed for binary/boolean features. Corresponding estimators are: BernoulliNB for classification tasks. Read more in sklearn's documentation .","title":"Bernoulli Naive Bayes (BNB)"},{"location":"API/models/bnb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\")","title":"Hyperparameters"},{"location":"API/models/bnb/#attributes","text":"","title":"Attributes"},{"location":"API/models/bnb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/bnb/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/bnb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/bnb/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.bnb.plot_permutation_importance() or atom.bnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/bnb/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"BNB\", metric=\"precision\")","title":"Example"},{"location":"API/models/br/","text":"Bayesian Ridge (BR) Bayesian regression techniques can be used to include regularization parameters in the estimation procedure: the regularization parameter is not set in a hard sense but tuned to the data at hand. Corresponding estimators are: BayesianRidge for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: n_iter: float, default=300 Integer(100, 1000, name=\"n_iter\") alpha_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_1\") alpha_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_2\") lambda_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_1\") lambda_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_2\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.br.plot_permutation_importance() or atom.br.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"BR\", n_calls=20, n_initial_points=7, bagging=5)","title":"Bayesian Ridge"},{"location":"API/models/br/#bayesian-ridge-br","text":"Bayesian regression techniques can be used to include regularization parameters in the estimation procedure: the regularization parameter is not set in a hard sense but tuned to the data at hand. Corresponding estimators are: BayesianRidge for regression tasks. Read more in sklearn's documentation .","title":"Bayesian Ridge (BR)"},{"location":"API/models/br/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: n_iter: float, default=300 Integer(100, 1000, name=\"n_iter\") alpha_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_1\") alpha_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"alpha_2\") lambda_1: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_1\") lambda_2: float, default=1e-6 Categorical([1e-8, 1e-6, 1e-4, 1e-2], name=\"lambda_2\")","title":"Hyperparameters"},{"location":"API/models/br/#attributes","text":"","title":"Attributes"},{"location":"API/models/br/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/br/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/br/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/br/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.br.plot_permutation_importance() or atom.br.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/br/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"BR\", n_calls=20, n_initial_points=7, bagging=5)","title":"Example"},{"location":"API/models/catb/","text":"CatBoost (CatB) CatBoost is a machine learning method based on gradient boosting over decision trees. Main advantages of CatBoost: Superior quality when compared with other GBDT models on many datasets. Best in class prediction speed. Corresponding estimators are: CatBoostClassifier for classification tasks. CatBoostRegressor for regression tasks. Read more in CatBoost's documentation . Note CatBoost allows early stopping to stop the training of unpromising models prematurely! Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The bootstrap_type parameter is set to \"Bernoulli\" to allow for the subsample parameter. The num_leaves and min_child_samples parameters are not available for the CPU implementation. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(20, 500, name=\"n_estimators\") learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") colsample_by_level: float, default=1.0 Categorical(np.linspace(0.3, 1.0, 8), name=\"colsample_by_level\") reg_lambda: int, default=0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_lambda\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.catb.plot_permutation_importance() or atom.catb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"CatB\", n_calls=50, bo_params={\"max_time\": 1000, \"early_stopping\": 0.1})","title":"CatBoost"},{"location":"API/models/catb/#catboost-catb","text":"CatBoost is a machine learning method based on gradient boosting over decision trees. Main advantages of CatBoost: Superior quality when compared with other GBDT models on many datasets. Best in class prediction speed. Corresponding estimators are: CatBoostClassifier for classification tasks. CatBoostRegressor for regression tasks. Read more in CatBoost's documentation . Note CatBoost allows early stopping to stop the training of unpromising models prematurely!","title":"CatBoost (CatB)"},{"location":"API/models/catb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The bootstrap_type parameter is set to \"Bernoulli\" to allow for the subsample parameter. The num_leaves and min_child_samples parameters are not available for the CPU implementation. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(20, 500, name=\"n_estimators\") learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") colsample_by_level: float, default=1.0 Categorical(np.linspace(0.3, 1.0, 8), name=\"colsample_by_level\") reg_lambda: int, default=0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_lambda\")","title":"Hyperparameters"},{"location":"API/models/catb/#attributes","text":"","title":"Attributes"},{"location":"API/models/catb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/catb/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/catb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/catb/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.catb.plot_permutation_importance() or atom.catb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/catb/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"CatB\", n_calls=50, bo_params={\"max_time\": 1000, \"early_stopping\": 0.1})","title":"Example"},{"location":"API/models/catnb/","text":"Categorical Naive Bayes (CatNB) Categorical Naive Bayes implements the Naive Bayes algorithm for categorical features. Corresponding estimators are: CategoricalNB for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.catnb.plot_permutation_importance() or atom.catnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"CatNB\")","title":"Categorical Naive Bayes"},{"location":"API/models/catnb/#categorical-naive-bayes-catnb","text":"Categorical Naive Bayes implements the Naive Bayes algorithm for categorical features. Corresponding estimators are: CategoricalNB for classification tasks. Read more in sklearn's documentation .","title":"Categorical Naive Bayes (CatNB)"},{"location":"API/models/catnb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\")","title":"Hyperparameters"},{"location":"API/models/catnb/#attributes","text":"","title":"Attributes"},{"location":"API/models/catnb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/catnb/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/catnb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/catnb/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.catnb.plot_permutation_importance() or atom.catnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/catnb/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"CatNB\")","title":"Example"},{"location":"API/models/cnb/","text":"Complement Naive Bayes (CNB) The Complement Naive Bayes classifier was designed to correct the \u201csevere assumptions\u201d made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets. Corresponding estimators are: ComplementNB for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\") norm: bool, default=False Categorical([True, False], name=\"norm\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.cnb.plot_permutation_importance() or atom.cnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"CNB\")","title":"Complement Naive Bayes"},{"location":"API/models/cnb/#complement-naive-bayes-cnb","text":"The Complement Naive Bayes classifier was designed to correct the \u201csevere assumptions\u201d made by the standard Multinomial Naive Bayes classifier. It is particularly suited for imbalanced data sets. Corresponding estimators are: ComplementNB for classification tasks. Read more in sklearn's documentation .","title":"Complement Naive Bayes (CNB)"},{"location":"API/models/cnb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\") norm: bool, default=False Categorical([True, False], name=\"norm\")","title":"Hyperparameters"},{"location":"API/models/cnb/#attributes","text":"","title":"Attributes"},{"location":"API/models/cnb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/cnb/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/cnb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/cnb/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.cnb.plot_permutation_importance() or atom.cnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/cnb/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"CNB\")","title":"Example"},{"location":"API/models/en/","text":"Elastic Net (EN) Linear least squares with l1 and l2 regularization. Corresponding estimators are: ElasticNet for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") l1_ratio: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"l1_ratio\") selection: str, default=\"cyclic\" Categorical([\"cyclic\", \"random\"], name=\"selection\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.en.plot_permutation_importance() or atom.en.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"EN\", est_params={\"l1_ratio\": 0.75})","title":"Elastic Net"},{"location":"API/models/en/#elastic-net-en","text":"Linear least squares with l1 and l2 regularization. Corresponding estimators are: ElasticNet for regression tasks. Read more in sklearn's documentation .","title":"Elastic Net (EN)"},{"location":"API/models/en/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") l1_ratio: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"l1_ratio\") selection: str, default=\"cyclic\" Categorical([\"cyclic\", \"random\"], name=\"selection\")","title":"Hyperparameters"},{"location":"API/models/en/#attributes","text":"","title":"Attributes"},{"location":"API/models/en/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/en/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/en/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/en/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.en.plot_permutation_importance() or atom.en.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/en/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"EN\", est_params={\"l1_ratio\": 0.75})","title":"Example"},{"location":"API/models/et/","text":"Extra-Trees (ET) Extra-Trees use a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Corresponding estimators are: ExtraTreesClassifier for classification tasks. ExtraTreesRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The max_samples parameter is only used when bootstrap = True. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(10, 500, name=\"n_estimators\") criterion: str classifier: default=\"gini\" Categorical([\"gini\", \"entropy\"], name=\"criterion\") regressor: default=\"mse\" Categorical([\"mse\", \"mae\", \"friedman_mse\"], name=\"criterion\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") max_samples: float, default=0.9 Categorical(np.linspace(0.5, 0.9, 5), name=\"max_samples\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.et.plot_permutation_importance() or atom.et.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"ET\", metric=\"MSE\", n_calls=5, n_initial_points=1)","title":"Extra-Trees"},{"location":"API/models/et/#extra-trees-et","text":"Extra-Trees use a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. Corresponding estimators are: ExtraTreesClassifier for classification tasks. ExtraTreesRegressor for regression tasks. Read more in sklearn's documentation .","title":"Extra-Trees (ET)"},{"location":"API/models/et/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The max_samples parameter is only used when bootstrap = True. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(10, 500, name=\"n_estimators\") criterion: str classifier: default=\"gini\" Categorical([\"gini\", \"entropy\"], name=\"criterion\") regressor: default=\"mse\" Categorical([\"mse\", \"mae\", \"friedman_mse\"], name=\"criterion\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") max_samples: float, default=0.9 Categorical(np.linspace(0.5, 0.9, 5), name=\"max_samples\")","title":"Hyperparameters"},{"location":"API/models/et/#attributes","text":"","title":"Attributes"},{"location":"API/models/et/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/et/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/et/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/et/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.et.plot_permutation_importance() or atom.et.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/et/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"ET\", metric=\"MSE\", n_calls=5, n_initial_points=1)","title":"Example"},{"location":"API/models/gbm/","text":"Gradient Boosting Machine (GBM) A Gradient Boosting Machine builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced. Corresponding estimators are: GradientBoostingClassifier for classification tasks. GradientBoostingRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. For multiclass classification tasks, the loss parameter is always set to \"deviance\". The alpha parameter is only used when loss = \"huber\" or \"quantile\". The random_state parameter is set equal to that of the training instance. Dimensions: learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") n_estimators: int, default=100 Integer(10, 500, name=\"n_estimators\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") criterion: str, default=\"friedman_mse\" Categorical([\"friedman_mse\", \"mae\", \"mse\"], name=\"criterion\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_depth: int, default=3 Integer(1, 10, name=\"max_depth\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") ccp_alpha: float, default=0 Real(0, 0.035, name=\"ccp_alpha\") loss: str binary classifier: default=\"deviance\" Categorical([\"deviance\", \"exponential\"], name=\"loss\") regressor: default=\"ls\" Categorical([\"ls\", \"lad\", \"huber\", \"quantile\"], name=\"loss\") alpha: float, default=0.9 Categorical(np.linspace(0.5, 0.9, 5), name=\"alpha\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.gbm.plot_permutation_importance() or atom.gbm.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"GBM\")","title":"Gradient Boosting Machine"},{"location":"API/models/gbm/#gradient-boosting-machine-gbm","text":"A Gradient Boosting Machine builds an additive model in a forward stage-wise fashion; it allows for the optimization of arbitrary differentiable loss functions. In each stage n_classes_ regression trees are fit on the negative gradient of the binomial or multinomial deviance loss function. Binary classification is a special case where only a single regression tree is induced. Corresponding estimators are: GradientBoostingClassifier for classification tasks. GradientBoostingRegressor for regression tasks. Read more in sklearn's documentation .","title":"Gradient Boosting Machine (GBM)"},{"location":"API/models/gbm/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. For multiclass classification tasks, the loss parameter is always set to \"deviance\". The alpha parameter is only used when loss = \"huber\" or \"quantile\". The random_state parameter is set equal to that of the training instance. Dimensions: learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") n_estimators: int, default=100 Integer(10, 500, name=\"n_estimators\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") criterion: str, default=\"friedman_mse\" Categorical([\"friedman_mse\", \"mae\", \"mse\"], name=\"criterion\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_depth: int, default=3 Integer(1, 10, name=\"max_depth\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") ccp_alpha: float, default=0 Real(0, 0.035, name=\"ccp_alpha\") loss: str binary classifier: default=\"deviance\" Categorical([\"deviance\", \"exponential\"], name=\"loss\") regressor: default=\"ls\" Categorical([\"ls\", \"lad\", \"huber\", \"quantile\"], name=\"loss\") alpha: float, default=0.9 Categorical(np.linspace(0.5, 0.9, 5), name=\"alpha\")","title":"Hyperparameters"},{"location":"API/models/gbm/#attributes","text":"","title":"Attributes"},{"location":"API/models/gbm/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/gbm/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/gbm/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/gbm/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.gbm.plot_permutation_importance() or atom.gbm.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/gbm/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"GBM\")","title":"Example"},{"location":"API/models/gnb/","text":"Gaussian Naive bayes (GNB) Gaussian Naive Bayes implements the Naive Bayes algorithm for classification. The likelihood of the features is assumed to be Gaussian. Corresponding estimators are: GaussianNB for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. GNB has no parameters to tune with the BO. Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: estimator: class Estimator instance fitted on the complete training set. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: name: Name of the model. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.gnb.plot_permutation_importance() or atom.gnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"GNB\")","title":"Gaussian Naive Bayes"},{"location":"API/models/gnb/#gaussian-naive-bayes-gnb","text":"Gaussian Naive Bayes implements the Naive Bayes algorithm for classification. The likelihood of the features is assumed to be Gaussian. Corresponding estimators are: GaussianNB for classification tasks. Read more in sklearn's documentation .","title":"Gaussian Naive bayes (GNB)"},{"location":"API/models/gnb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. GNB has no parameters to tune with the BO.","title":"Hyperparameters"},{"location":"API/models/gnb/#attributes","text":"","title":"Attributes"},{"location":"API/models/gnb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/gnb/#utility-attributes","text":"Attributes: estimator: class Estimator instance fitted on the complete training set. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: name: Name of the model. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/gnb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/gnb/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.gnb.plot_permutation_importance() or atom.gnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/gnb/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"GNB\")","title":"Example"},{"location":"API/models/gp/","text":"Gaussian Process (GP) Gaussian Processes are a generic supervised learning method designed to solve regression and probabilistic classification problems. The advantages of Gaussian processes are: The prediction interpolates the observations. The prediction is probabilistic (Gaussian) so that one can compute empirical confidence intervals and decide based on those if one should refit (online fitting, adaptive fitting) the prediction in some region of interest. The disadvantages of Gaussian processes include: They are not sparse, i.e. they use the whole samples/features information to perform the prediction. They lose efficiency in high dimensional spaces, namely when the number of features exceeds a few dozens. Corresponding estimators are: GaussianProcessClassifier for classification tasks. GaussianProcessClassifier for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. GP has no parameters to tune with the BO. Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: estimator: class Estimator instance fitted on the complete training set. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: name: Name of the model. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.gp.plot_permutation_importance() or atom.gp.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"GP\", metric=\"medae\")","title":"Gaussian Process"},{"location":"API/models/gp/#gaussian-process-gp","text":"Gaussian Processes are a generic supervised learning method designed to solve regression and probabilistic classification problems. The advantages of Gaussian processes are: The prediction interpolates the observations. The prediction is probabilistic (Gaussian) so that one can compute empirical confidence intervals and decide based on those if one should refit (online fitting, adaptive fitting) the prediction in some region of interest. The disadvantages of Gaussian processes include: They are not sparse, i.e. they use the whole samples/features information to perform the prediction. They lose efficiency in high dimensional spaces, namely when the number of features exceeds a few dozens. Corresponding estimators are: GaussianProcessClassifier for classification tasks. GaussianProcessClassifier for regression tasks. Read more in sklearn's documentation .","title":"Gaussian Process (GP)"},{"location":"API/models/gp/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. GP has no parameters to tune with the BO.","title":"Hyperparameters"},{"location":"API/models/gp/#attributes","text":"","title":"Attributes"},{"location":"API/models/gp/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/gp/#utility-attributes","text":"Attributes: estimator: class Estimator instance fitted on the complete training set. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: name: Name of the model. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/gp/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/gp/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.gp.plot_permutation_importance() or atom.gp.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/gp/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"GP\", metric=\"medae\")","title":"Example"},{"location":"API/models/knn/","text":"K-Nearest Neighbors (KNN) K-Nearest Neighbors, as the name clearly indicates, implements the k-nearest neighbors vote. For regression, the target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set. Corresponding estimators are: KNeighborsClassifier for classification tasks. KNeighborsRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs parameter is set equal to that of the training instance. Dimensions: n_neighbors: int, default=5 Integer(1, 100, name=\"n_neighbors\") weights: str, default=\"uniform\" Categorical([\"uniform\", \"distance\"], name=\"weights\") algorithm: str, default=\"auto\" Categorical([\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"], name=\"algorithm\") leaf_size: int, default=30 Integer(20, 40, name=\"leaf_size\") p: int, default=2 Integer(1, 2, name=\"p\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.knn.plot_permutation_importance() or atom.knn.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"KNN\", metric=\"ME\", n_calls=20, bo_params={\"max_time\": 1000})","title":"K-Nearest Neighbors"},{"location":"API/models/knn/#k-nearest-neighbors-knn","text":"K-Nearest Neighbors, as the name clearly indicates, implements the k-nearest neighbors vote. For regression, the target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set. Corresponding estimators are: KNeighborsClassifier for classification tasks. KNeighborsRegressor for regression tasks. Read more in sklearn's documentation .","title":"K-Nearest Neighbors (KNN)"},{"location":"API/models/knn/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs parameter is set equal to that of the training instance. Dimensions: n_neighbors: int, default=5 Integer(1, 100, name=\"n_neighbors\") weights: str, default=\"uniform\" Categorical([\"uniform\", \"distance\"], name=\"weights\") algorithm: str, default=\"auto\" Categorical([\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"], name=\"algorithm\") leaf_size: int, default=30 Integer(20, 40, name=\"leaf_size\") p: int, default=2 Integer(1, 2, name=\"p\")","title":"Hyperparameters"},{"location":"API/models/knn/#attributes","text":"","title":"Attributes"},{"location":"API/models/knn/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/knn/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/knn/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/knn/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.knn.plot_permutation_importance() or atom.knn.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/knn/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"KNN\", metric=\"ME\", n_calls=20, bo_params={\"max_time\": 1000})","title":"Example"},{"location":"API/models/ksvm/","text":"Kernel-SVM (kSVM) The implementation of the Kernel (non-linear) Support Vector Machine is based on libsvm. The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples. For large datasets consider using a Linear Support Vector Machine or a Stochastic Gradient descent model instead. The multiclass support is handled according to a one-vs-one scheme. Corresponding estimators are: SVC for classification tasks. SVR for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The degree parameter is only used when kernel = \"poly\". The gamma parameter is always set to \"scale\" when kernel = \"poly\". The coef0 parameter is only used when kernel = \"rbf\". The random_state parameter is set equal to that of the training instance. Dimensions: C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") kernel: str, default=\"rbf\" Categorical([\"poly\", \"rbf\", \"sigmoid\"], name=\"kernel\") degree: int, default=3 Integer(2, 5, name=\"degree\"). gamma: str, default=\"scale\" Categorical([\"scale\", \"auto\"], name=\"gamma\") coef0: float, default=0 Real(-1.0, 1.0, name=\"coef0\"). shrinking: bool, default=True Categorical([True, False], name=\"shrinking\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.ksvm.plot_permutation_importance() or atom.ksvm.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"kSVM\", metric=\"r2\", est_params={\"kernel\": \"rbf\"})","title":"Kernel-SVM"},{"location":"API/models/ksvm/#kernel-svm-ksvm","text":"The implementation of the Kernel (non-linear) Support Vector Machine is based on libsvm. The fit time scales at least quadratically with the number of samples and may be impractical beyond tens of thousands of samples. For large datasets consider using a Linear Support Vector Machine or a Stochastic Gradient descent model instead. The multiclass support is handled according to a one-vs-one scheme. Corresponding estimators are: SVC for classification tasks. SVR for regression tasks. Read more in sklearn's documentation .","title":"Kernel-SVM (kSVM)"},{"location":"API/models/ksvm/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The degree parameter is only used when kernel = \"poly\". The gamma parameter is always set to \"scale\" when kernel = \"poly\". The coef0 parameter is only used when kernel = \"rbf\". The random_state parameter is set equal to that of the training instance. Dimensions: C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") kernel: str, default=\"rbf\" Categorical([\"poly\", \"rbf\", \"sigmoid\"], name=\"kernel\") degree: int, default=3 Integer(2, 5, name=\"degree\"). gamma: str, default=\"scale\" Categorical([\"scale\", \"auto\"], name=\"gamma\") coef0: float, default=0 Real(-1.0, 1.0, name=\"coef0\"). shrinking: bool, default=True Categorical([True, False], name=\"shrinking\")","title":"Hyperparameters"},{"location":"API/models/ksvm/#attributes","text":"","title":"Attributes"},{"location":"API/models/ksvm/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/ksvm/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/ksvm/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/ksvm/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.ksvm.plot_permutation_importance() or atom.ksvm.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/ksvm/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"kSVM\", metric=\"r2\", est_params={\"kernel\": \"rbf\"})","title":"Example"},{"location":"API/models/lasso/","text":"Lasso Regression (Lasso) Linear least squares with l1 regularization. Corresponding estimators are: Lasso for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") selection: str, default=\"cyclic\" Categorical([\"cyclic\", \"random\"], name=\"selection\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.lasso.plot_permutation_importance() or atom.lasso.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Lasso\")","title":"Lasso"},{"location":"API/models/lasso/#lasso-regression-lasso","text":"Linear least squares with l1 regularization. Corresponding estimators are: Lasso for regression tasks. Read more in sklearn's documentation .","title":"Lasso Regression (Lasso)"},{"location":"API/models/lasso/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") selection: str, default=\"cyclic\" Categorical([\"cyclic\", \"random\"], name=\"selection\")","title":"Hyperparameters"},{"location":"API/models/lasso/#attributes","text":"","title":"Attributes"},{"location":"API/models/lasso/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/lasso/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/lasso/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/lasso/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.lasso.plot_permutation_importance() or atom.lasso.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/lasso/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Lasso\")","title":"Example"},{"location":"API/models/lda/","text":"Linear Discriminant Analysis (LDA) Linear Discriminant Analysis is a classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes\u2019 rule. The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix. Corresponding estimators are: LinearDiscriminantAnalysis for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The shrinkage parameter is not used when solver = \"svd\". Dimensions: solver: str, default=\"svd\" Categorical([\"svd\", \"lsqr\", \"eigen\"], name=\"solver\") shrinkage: float, default=0 Categorical(np.linspace(0.0, 1.0, 11), name=\"shrinkage\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set. decision_function_test: np.ndarray Decision function scores on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.lda.plot_permutation_importance() or atom.lda.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"LDA\")","title":"Linear Discriminant Analysis"},{"location":"API/models/lda/#linear-discriminant-analysis-lda","text":"Linear Discriminant Analysis is a classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayes\u2019 rule. The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix. Corresponding estimators are: LinearDiscriminantAnalysis for classification tasks. Read more in sklearn's documentation .","title":"Linear Discriminant Analysis (LDA)"},{"location":"API/models/lda/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The shrinkage parameter is not used when solver = \"svd\". Dimensions: solver: str, default=\"svd\" Categorical([\"svd\", \"lsqr\", \"eigen\"], name=\"solver\") shrinkage: float, default=0 Categorical(np.linspace(0.0, 1.0, 11), name=\"shrinkage\")","title":"Hyperparameters"},{"location":"API/models/lda/#attributes","text":"","title":"Attributes"},{"location":"API/models/lda/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/lda/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/lda/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set. decision_function_test: np.ndarray Decision function scores on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/lda/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.lda.plot_permutation_importance() or atom.lda.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/lda/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"LDA\")","title":"Example"},{"location":"API/models/lgb/","text":"LightGBM (LGB) LightGBM is a gradient boosting model that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency. Lower memory usage. Better accuracy. Capable of handling large-scale data. Corresponding estimators are: LGBMClassifier for classification tasks. LGBMRegressor for regression tasks. Read more in LightGBM's documentation . Note LightGBM allows early stopping to stop the training of unpromising models prematurely! Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(20, 500, name=\"n_estimators\") learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") max_depth: int, default=-1 Categorical([-1, *list(range(1, 10))], name=\"max_depth\") num_leaves: int, default=31 Integer(20, 40, name=\"num_leaves\") min_child_weight: int, default=1 Integer(1, 20, name=\"min_child_weight\") min_child_samples: int, default=20 Integer(10, 30, name=\"min_child_samples\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") colsample_by_level: float, default=1.0 Categorical(np.linspace(0.3, 1.0, 8), name=\"colsample_by_level\") reg_alpha: float, default=0.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_alpha\") reg_lambda: float, default=0.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_lambda\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.lgb.plot_permutation_importance() or atom.lgb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"LGB\", metric=\"r2\", n_calls=50, bo_params={\"base_estimator\": \"ET\"})","title":"LightGBM"},{"location":"API/models/lgb/#lightgbm-lgb","text":"LightGBM is a gradient boosting model that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages: Faster training speed and higher efficiency. Lower memory usage. Better accuracy. Capable of handling large-scale data. Corresponding estimators are: LGBMClassifier for classification tasks. LGBMRegressor for regression tasks. Read more in LightGBM's documentation . Note LightGBM allows early stopping to stop the training of unpromising models prematurely!","title":"LightGBM (LGB)"},{"location":"API/models/lgb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(20, 500, name=\"n_estimators\") learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") max_depth: int, default=-1 Categorical([-1, *list(range(1, 10))], name=\"max_depth\") num_leaves: int, default=31 Integer(20, 40, name=\"num_leaves\") min_child_weight: int, default=1 Integer(1, 20, name=\"min_child_weight\") min_child_samples: int, default=20 Integer(10, 30, name=\"min_child_samples\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") colsample_by_level: float, default=1.0 Categorical(np.linspace(0.3, 1.0, 8), name=\"colsample_by_level\") reg_alpha: float, default=0.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_alpha\") reg_lambda: float, default=0.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_lambda\")","title":"Hyperparameters"},{"location":"API/models/lgb/#attributes","text":"","title":"Attributes"},{"location":"API/models/lgb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/lgb/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/lgb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/lgb/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.lgb.plot_permutation_importance() or atom.lgb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/lgb/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"LGB\", metric=\"r2\", n_calls=50, bo_params={\"base_estimator\": \"ET\"})","title":"Example"},{"location":"API/models/lr/","text":"Logistic regression (LR) Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function. Corresponding estimators are: LogisticRegression for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The penalty parameter will be automatically set to \"l2\" when penalty = \"none\" and solver = \"liblinear\". The penalty parameter will be automatically set to \"l2\" when penalty = \"l1\" and solver != \"liblinear\" or \"saga\". The penalty parameter will be automatically set to \"l2\" when penalty = \"elasticnet\" and solver != \"saga\". The C parameter is not used when penalty = \"none\". The l1_ratio parameter is only used when penalty = \"elasticnet\". The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: penalty: str, default=\"l2\" Categorical([\"none\", \"l1\", \"l2\", \"elasticnet\"], name=\"penalty\") C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") solver: str, default=\"lbfgs\" Categorical([\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\", \"saga\"], name=\"solver\") max_iter: int, default=100 Integer(100, 1000, name=\"max_iter\") l1_ratio: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"l1_ratio\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set. decision_function_test: np.ndarray Decision function scores on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.lr.plot_permutation_importance() or atom.lr.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"LR\")","title":"Logistic Regression"},{"location":"API/models/lr/#logistic-regression-lr","text":"Logistic regression, despite its name, is a linear model for classification rather than regression. Logistic regression is also known in the literature as logit regression, maximum-entropy classification (MaxEnt) or the log-linear classifier. In this model, the probabilities describing the possible outcomes of a single trial are modeled using a logistic function. Corresponding estimators are: LogisticRegression for classification tasks. Read more in sklearn's documentation .","title":"Logistic regression (LR)"},{"location":"API/models/lr/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The penalty parameter will be automatically set to \"l2\" when penalty = \"none\" and solver = \"liblinear\". The penalty parameter will be automatically set to \"l2\" when penalty = \"l1\" and solver != \"liblinear\" or \"saga\". The penalty parameter will be automatically set to \"l2\" when penalty = \"elasticnet\" and solver != \"saga\". The C parameter is not used when penalty = \"none\". The l1_ratio parameter is only used when penalty = \"elasticnet\". The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: penalty: str, default=\"l2\" Categorical([\"none\", \"l1\", \"l2\", \"elasticnet\"], name=\"penalty\") C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") solver: str, default=\"lbfgs\" Categorical([\"lbfgs\", \"newton-cg\", \"liblinear\", \"sag\", \"saga\"], name=\"solver\") max_iter: int, default=100 Integer(100, 1000, name=\"max_iter\") l1_ratio: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"l1_ratio\")","title":"Hyperparameters"},{"location":"API/models/lr/#attributes","text":"","title":"Attributes"},{"location":"API/models/lr/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/lr/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/lr/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set. decision_function_test: np.ndarray Decision function scores on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/lr/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.lr.plot_permutation_importance() or atom.lr.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/lr/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"LR\")","title":"Example"},{"location":"API/models/lsvm/","text":"Linear-SVM (lSVM) Similar to Kernel-SVM but with a linear kernel. Implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples. The multiclass support is handled according to a one-vs-rest scheme. Corresponding estimators are: LinearSVC for classification tasks. LinearSVR for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The penalty parameter is only used with LinearSVC. The penalty parameter is always set to \"l2\" when loss = \"hinge\". The dual parameter will be automatically set to False when penalty = \"l1\" and loss = \"squared_hinge\". The random_state parameter is set equal to that of the training instance. Dimensions: loss: str classifier: default=\"squared_hinge\" Categorical([\"hinge\", \"squared_hinge\"], name=\"loss\") regressor: default=\"epsilon_insensitive\" Categorical([\"epsilon_insensitive\", \"squared_epsilon_insensitive\"], name=\"loss\") C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") penalty: str, default=\"l2\" Categorical([\"l1\", \"l2\"], name=\"penalty\"). Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.lsvm.plot_permutation_importance() or atom.lsvm.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"lSVM\", metric=\"accuracy\", n_calls=10)","title":"Linear-SVM"},{"location":"API/models/lsvm/#linear-svm-lsvm","text":"Similar to Kernel-SVM but with a linear kernel. Implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples. The multiclass support is handled according to a one-vs-rest scheme. Corresponding estimators are: LinearSVC for classification tasks. LinearSVR for regression tasks. Read more in sklearn's documentation .","title":"Linear-SVM (lSVM)"},{"location":"API/models/lsvm/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The penalty parameter is only used with LinearSVC. The penalty parameter is always set to \"l2\" when loss = \"hinge\". The dual parameter will be automatically set to False when penalty = \"l1\" and loss = \"squared_hinge\". The random_state parameter is set equal to that of the training instance. Dimensions: loss: str classifier: default=\"squared_hinge\" Categorical([\"hinge\", \"squared_hinge\"], name=\"loss\") regressor: default=\"epsilon_insensitive\" Categorical([\"epsilon_insensitive\", \"squared_epsilon_insensitive\"], name=\"loss\") C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") penalty: str, default=\"l2\" Categorical([\"l1\", \"l2\"], name=\"penalty\").","title":"Hyperparameters"},{"location":"API/models/lsvm/#attributes","text":"","title":"Attributes"},{"location":"API/models/lsvm/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/lsvm/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/lsvm/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/lsvm/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.lsvm.plot_permutation_importance() or atom.lsvm.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/lsvm/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"lSVM\", metric=\"accuracy\", n_calls=10)","title":"Example"},{"location":"API/models/mlp/","text":"Multi-layer Perceptron (MLP) Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function by training on a dataset. Given a set of features and a target, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. Corresponding estimators are: MLPClassifier for classification tasks. MLPRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The MLP optimizes between one and three hidden layers with the BO. For more layers, use est_params . The learning_rate and power_t parameters are only used when solver = \"lbfgs\". The learning_rate_init parameter is only used when solver != \"lbfgs\". The random_state parameter is set equal to that of the training instance. Dimensions: hidden_layer_sizes: tuple, default=(100,) Integer(10, 100, name=\"hidden_layer_1\") Integer(0, 100, name=\"hidden_layer_2\") Integer(0, 100, name=\"hidden_layer_3\") activation: str, default=\"relu\" Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"], name=\"activation\") solver: str, default=\"adam\" Categorical([\"lbfgs\", \"sgd\", \"adam\"], name=\"solver\") alpha: float, default=1e-4 Real(1e-4, 0.1, \"log-uniform\", name=\"alpha\") batch_size: int, default=200 Integer(8, 250, name=\"batch_size\") learning_rate: str, default=\"constant\" Categorical([\"constant\", \"invscaling\", \"adaptive\"], name=\"learning_rate\"). learning_rate_init: float, default=1e-3 Real(1e-3, 0.1, \"log-uniform\", name=\"learning_rate_init\"). power_t: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"power_t\"). max_iter: int, default=200 Integer(50, 500, name=\"max_iter\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.mlp.plot_permutation_importance() or atom.mlp.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"MLP\", n_calls=20, est_params={\"solver\": \"sgd\", \"activation\": \"relu\"})","title":"Multi-layer Perceptron"},{"location":"API/models/mlp/#multi-layer-perceptron-mlp","text":"Multi-layer Perceptron (MLP) is a supervised learning algorithm that learns a function by training on a dataset. Given a set of features and a target, it can learn a non-linear function approximator for either classification or regression. It is different from logistic regression, in that between the input and the output layer, there can be one or more non-linear layers, called hidden layers. Corresponding estimators are: MLPClassifier for classification tasks. MLPRegressor for regression tasks. Read more in sklearn's documentation .","title":"Multi-layer Perceptron (MLP)"},{"location":"API/models/mlp/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The MLP optimizes between one and three hidden layers with the BO. For more layers, use est_params . The learning_rate and power_t parameters are only used when solver = \"lbfgs\". The learning_rate_init parameter is only used when solver != \"lbfgs\". The random_state parameter is set equal to that of the training instance. Dimensions: hidden_layer_sizes: tuple, default=(100,) Integer(10, 100, name=\"hidden_layer_1\") Integer(0, 100, name=\"hidden_layer_2\") Integer(0, 100, name=\"hidden_layer_3\") activation: str, default=\"relu\" Categorical([\"identity\", \"logistic\", \"tanh\", \"relu\"], name=\"activation\") solver: str, default=\"adam\" Categorical([\"lbfgs\", \"sgd\", \"adam\"], name=\"solver\") alpha: float, default=1e-4 Real(1e-4, 0.1, \"log-uniform\", name=\"alpha\") batch_size: int, default=200 Integer(8, 250, name=\"batch_size\") learning_rate: str, default=\"constant\" Categorical([\"constant\", \"invscaling\", \"adaptive\"], name=\"learning_rate\"). learning_rate_init: float, default=1e-3 Real(1e-3, 0.1, \"log-uniform\", name=\"learning_rate_init\"). power_t: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"power_t\"). max_iter: int, default=200 Integer(50, 500, name=\"max_iter\")","title":"Hyperparameters"},{"location":"API/models/mlp/#attributes","text":"","title":"Attributes"},{"location":"API/models/mlp/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/mlp/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/mlp/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/mlp/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.mlp.plot_permutation_importance() or atom.mlp.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/mlp/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"MLP\", n_calls=20, est_params={\"solver\": \"sgd\", \"activation\": \"relu\"})","title":"Example"},{"location":"API/models/mnb/","text":"Multinomial Naive Bayes (MNB) Multinomial Naive Bayes implements the Naive Bayes algorithm for multinomially distributed data, and is one of the two classic Naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). Corresponding estimators are: MultinomialNB for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.mnb.plot_permutation_importance() or atom.mnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"MNB\", metric=\"precision\")","title":"Multinomial Naive Bayes"},{"location":"API/models/mnb/#multinomial-naive-bayes-mnb","text":"Multinomial Naive Bayes implements the Naive Bayes algorithm for multinomially distributed data, and is one of the two classic Naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). Corresponding estimators are: MultinomialNB for classification tasks. Read more in sklearn's documentation .","title":"Multinomial Naive Bayes (MNB)"},{"location":"API/models/mnb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") fit_prior: bool, default=True Categorical([True, False], name=\"fit_prior\")","title":"Hyperparameters"},{"location":"API/models/mnb/#attributes","text":"","title":"Attributes"},{"location":"API/models/mnb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/mnb/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/mnb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/mnb/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.mnb.plot_permutation_importance() or atom.mnb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/mnb/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"MNB\", metric=\"precision\")","title":"Example"},{"location":"API/models/ols/","text":"Ordinary Least Squares (OLS) Ordinary Least Squares is just linear regression without any regularization. It fits a linear model with coefficients w = (w1, \u2026, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation. Corresponding estimators are: LinearRegression for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs parameter is set equal to that of the training instance. OLS has no parameters to tune with the BO. Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: estimator: class Estimator instance fitted on the complete training set. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: name: Name of the model. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.ols.plot_permutation_importance() or atom.ols.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"OLS\")","title":"Ordinary Least Squares"},{"location":"API/models/ols/#ordinary-least-squares-ols","text":"Ordinary Least Squares is just linear regression without any regularization. It fits a linear model with coefficients w = (w1, \u2026, wp) to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation. Corresponding estimators are: LinearRegression for regression tasks. Read more in sklearn's documentation .","title":"Ordinary Least Squares (OLS)"},{"location":"API/models/ols/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs parameter is set equal to that of the training instance. OLS has no parameters to tune with the BO.","title":"Hyperparameters"},{"location":"API/models/ols/#attributes","text":"","title":"Attributes"},{"location":"API/models/ols/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/ols/#utility-attributes","text":"Attributes: estimator: class Estimator instance fitted on the complete training set. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: name: Name of the model. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/ols/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/ols/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.ols.plot_permutation_importance() or atom.ols.predict(X) . The remaining utility methods can be found hereunder: reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/ols/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"OLS\")","title":"Example"},{"location":"API/models/pa/","text":"Passive Aggressive (PA) The passive-aggressive algorithms are a family of algorithms for large-scale learning. They are similar to the Perceptron in that they do not require a learning rate. However, contrary to the Perceptron, they include a regularization parameter C. Corresponding estimators are: PassiveAggressiveClassifier for classification tasks. PassiveAggressiveRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") loss: str classifier: default=\"hinge\" Categorical([\"hinge\", \"squared_hinge\"], name=\"loss\") regressor: default=\"epsilon_insensitive\" Categorical([\"epsilon_insensitive\", \"squared_epsilon_insensitive\"], name=\"loss\") average: float, default=False Categorical([True, False], name=\"average\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.pa.plot_permutation_importance() or atom.pa.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"PA\", metric=\"f1\")","title":"Passive Aggressive"},{"location":"API/models/pa/#passive-aggressive-pa","text":"The passive-aggressive algorithms are a family of algorithms for large-scale learning. They are similar to the Perceptron in that they do not require a learning rate. However, contrary to the Perceptron, they include a regularization parameter C. Corresponding estimators are: PassiveAggressiveClassifier for classification tasks. PassiveAggressiveRegressor for regression tasks. Read more in sklearn's documentation .","title":"Passive Aggressive (PA)"},{"location":"API/models/pa/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: C: float, default=1.0 Real(1e-3, 100, \"log-uniform\", name=\"C\") loss: str classifier: default=\"hinge\" Categorical([\"hinge\", \"squared_hinge\"], name=\"loss\") regressor: default=\"epsilon_insensitive\" Categorical([\"epsilon_insensitive\", \"squared_epsilon_insensitive\"], name=\"loss\") average: float, default=False Categorical([True, False], name=\"average\")","title":"Hyperparameters"},{"location":"API/models/pa/#attributes","text":"","title":"Attributes"},{"location":"API/models/pa/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/pa/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/pa/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/pa/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.pa.plot_permutation_importance() or atom.pa.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/pa/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"PA\", metric=\"f1\")","title":"Example"},{"location":"API/models/qda/","text":"Quadratic Discriminant Analysis (QDA) Linear Discriminant Analysis is a classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes\u2019 rule. The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix. Corresponding estimators are: QuadraticDiscriminantAnalysis for classification tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: reg_param: float, default=0 Categorical(np.linspace(0.0, 1.0, 11), name=\"reg_param\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set. decision_function_test: np.ndarray Decision function scores on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.qda.plot_permutation_importance() or atom.qda.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"QDA\")","title":"Quadratic Discriminant Analysis"},{"location":"API/models/qda/#quadratic-discriminant-analysis-qda","text":"Linear Discriminant Analysis is a classifier with a quadratic decision boundary, generated by fitting class conditional densities to the data and using Bayes\u2019 rule. The model fits a Gaussian density to each class, assuming that all classes share the same covariance matrix. Corresponding estimators are: QuadraticDiscriminantAnalysis for classification tasks. Read more in sklearn's documentation .","title":"Quadratic Discriminant Analysis (QDA)"},{"location":"API/models/qda/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. Dimensions: reg_param: float, default=0 Categorical(np.linspace(0.0, 1.0, 11), name=\"reg_param\")","title":"Hyperparameters"},{"location":"API/models/qda/#attributes","text":"","title":"Attributes"},{"location":"API/models/qda/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/qda/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/qda/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set. decision_function_test: np.ndarray Decision function scores on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/qda/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.qda.plot_permutation_importance() or atom.qda.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/qda/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"QDA\")","title":"Example"},{"location":"API/models/rf/","text":"Random Forest (RF) Random forests are an ensemble learning method that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random forests correct for decision trees\" habit of overfitting to their training set. Corresponding estimators are: RandomForestClassifier for classification tasks. RandomForestRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The max_samples parameter is only used when bootstrap = True. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(10, 500, name=\"n_estimators\") criterion: str classifier: default=\"gini\" Categorical([\"gini\", \"entropy\"], name=\"criterion\") regressor: default=\"mse\" Categorical([\"mse\", \"mae\", \"friedman_mse\"], name=\"criterion\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") max_samples: float, default=0.9 Categorical(np.linspace(0.5, 0.9, 5), name=\"max_samples\") results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.rf.plot_permutation_importance() or atom.rf.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"RF\", metric=\"mae\", n_calls=20, n_initial_points=10)","title":"Random Forest"},{"location":"API/models/rf/#random-forest-rf","text":"Random forests are an ensemble learning method that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random forests correct for decision trees\" habit of overfitting to their training set. Corresponding estimators are: RandomForestClassifier for classification tasks. RandomForestRegressor for regression tasks. Read more in sklearn's documentation .","title":"Random Forest (RF)"},{"location":"API/models/rf/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The max_samples parameter is only used when bootstrap = True. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(10, 500, name=\"n_estimators\") criterion: str classifier: default=\"gini\" Categorical([\"gini\", \"entropy\"], name=\"criterion\") regressor: default=\"mse\" Categorical([\"mse\", \"mae\", \"friedman_mse\"], name=\"criterion\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") bootstrap: bool, default=False Categorical([True, False], name=\"bootstrap\") max_samples: float, default=0.9 Categorical(np.linspace(0.5, 0.9, 5), name=\"max_samples\") results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Hyperparameters"},{"location":"API/models/rf/#attributes","text":"","title":"Attributes"},{"location":"API/models/rf/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/rf/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results.","title":"Utility attributes"},{"location":"API/models/rf/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/rf/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.rf.plot_permutation_importance() or atom.rf.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/rf/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"RF\", metric=\"mae\", n_calls=20, n_initial_points=10)","title":"Example"},{"location":"API/models/ridge/","text":"Ridge Classification/Regression (Ridge) Linear least squares with l2 regularization. Corresponding estimators are: RidgeClassifier for classification tasks. Ridge for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") solver: str, default=\"auto\" Categorical([\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"], name=\"solver\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the model , e.g. atom.ridge.plot_permutation_importance() or atom.ridge.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Ridge\")","title":"Ridge"},{"location":"API/models/ridge/#ridge-classificationregression-ridge","text":"Linear least squares with l2 regularization. Corresponding estimators are: RidgeClassifier for classification tasks. Ridge for regression tasks. Read more in sklearn's documentation .","title":"Ridge Classification/Regression (Ridge)"},{"location":"API/models/ridge/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: alpha: float, default=1.0 Real(1e-3, 10, \"log-uniform\", name=\"alpha\") solver: str, default=\"auto\" Categorical([\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"], name=\"solver\")","title":"Hyperparameters"},{"location":"API/models/ridge/#attributes","text":"","title":"Attributes"},{"location":"API/models/ridge/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/ridge/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the estimator. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/ridge/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set. predict_proba_test: np.ndarray Predicted probabilities of the model on the test set. predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set. predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set. score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/ridge/#methods","text":"The majority of the plots and prediction methods can be called directly from the model , e.g. atom.ridge.plot_permutation_importance() or atom.ridge.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/ridge/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Ridge\")","title":"Example"},{"location":"API/models/rnn/","text":"Radius Nearest Neighbors (RNN) Radius Nearest Neighbors implements the nearest neighbors vote, where the neighbors are selected from within a given radius. For regression, the target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set. Corresponding estimators are: RadiusNeighborsClassifier for classification tasks. RadiusNeighborsRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The outlier_label parameter is set by default to \"most_frequent\" to avoid errors when encountering outliers. The n_jobs parameter is set equal to that of the training instance. Dimensions: radius: float, default=mean(distances) Real(min(distances), max(distances), name=\"radius\") Since the optimal radius depends hugely on the data, ATOM's RNN implementation doesn't use sklearn's default radius of 1, but instead calculates the minkowsky distance between 10% of random samples in the training set and uses the mean of those distances as default radius. The lower and upper bounds of the radius\" dimensions for the BO are given by the minimum and maximum value of the calculated distances. weights: str, default=\"uniform\" Categorical([\"uniform\", \"distance\"], name=\"weights\") algorithm: str, default=\"auto\" Categorical([\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"], name=\"algorithm\") leaf_size: int, default=30 Integer(20, 40, name=\"leaf_size\") p: int, default=2 Integer(1, 2, name=\"p\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.rnn.plot_permutation_importance() or atom.rnn.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"RNN\", metric=\"precision\", est_params={\"radius\": 3.5})","title":"Radius Nearest Neighbors"},{"location":"API/models/rnn/#radius-nearest-neighbors-rnn","text":"Radius Nearest Neighbors implements the nearest neighbors vote, where the neighbors are selected from within a given radius. For regression, the target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set. Corresponding estimators are: RadiusNeighborsClassifier for classification tasks. RadiusNeighborsRegressor for regression tasks. Read more in sklearn's documentation .","title":"Radius Nearest Neighbors (RNN)"},{"location":"API/models/rnn/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The outlier_label parameter is set by default to \"most_frequent\" to avoid errors when encountering outliers. The n_jobs parameter is set equal to that of the training instance. Dimensions: radius: float, default=mean(distances) Real(min(distances), max(distances), name=\"radius\") Since the optimal radius depends hugely on the data, ATOM's RNN implementation doesn't use sklearn's default radius of 1, but instead calculates the minkowsky distance between 10% of random samples in the training set and uses the mean of those distances as default radius. The lower and upper bounds of the radius\" dimensions for the BO are given by the minimum and maximum value of the calculated distances. weights: str, default=\"uniform\" Categorical([\"uniform\", \"distance\"], name=\"weights\") algorithm: str, default=\"auto\" Categorical([\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"], name=\"algorithm\") leaf_size: int, default=30 Integer(20, 40, name=\"leaf_size\") p: int, default=2 Integer(1, 2, name=\"p\")","title":"Hyperparameters"},{"location":"API/models/rnn/#attributes","text":"","title":"Attributes"},{"location":"API/models/rnn/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/rnn/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/rnn/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/rnn/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.rnn.plot_permutation_importance() or atom.rnn.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/rnn/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"RNN\", metric=\"precision\", est_params={\"radius\": 3.5})","title":"Example"},{"location":"API/models/sgd/","text":"Stochastic Gradient Descent (SGD) Stochastic Gradient Descent is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions. Even though SGD has been around in the machine learning community for a long time, it has received a considerable amount of attention just recently in the context of large-scale learning. Corresponding estimators are: SGDClassifier for classification tasks. SGDRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The l1_ratio parameter is only used when penalty = \"elasticnet\". The eta0 parameter is only used when learning_rate != \"optimal\". The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: loss: str classifier: default=\"hinge\" Categorical([\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"], name=\"loss\") regressor: default=\"squared_loss\" Categorical([\"squared_loss\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"], name=\"loss\") penalty: str, default=\"l2\" Categorical([\"none\", \"l1\", \"l2\", \"elasticnet\"], name=\"penalty\") alpha: float, default=1e-4 Real(1e-4, 1.0, \"log-uniform\", name=\"alpha\") l1_ratio: float, default=0.15 Categorical(np.linspace(0.1, 0.9, 9), name=\"l1_ratio\"). epsilon: float, default=0.1 Real(1e-4, 1.0, \"log-uniform\", name=\"epsilon\") learning_rate: str, default=\"optimal\" Categorical([\"constant\", \"invscaling\", \"optimal\", \"adaptive\"], name = \"learning_rate\") eta0: float, default=1e-4 Real(1e-4, 1.0, \"log-uniform\", name=\"eta0\"). power_t: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"power_t\") average: bool, default=False Categorical([True, False], name=\"average\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.sgd.plot_permutation_importance() or atom.sgd.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"SGD\", metric=\"recall\", bo_params={\"cv\": 3})","title":"Stochastic Gradient Descent"},{"location":"API/models/sgd/#stochastic-gradient-descent-sgd","text":"Stochastic Gradient Descent is a simple yet very efficient approach to fitting linear classifiers and regressors under convex loss functions. Even though SGD has been around in the machine learning community for a long time, it has received a considerable amount of attention just recently in the context of large-scale learning. Corresponding estimators are: SGDClassifier for classification tasks. SGDRegressor for regression tasks. Read more in sklearn's documentation .","title":"Stochastic Gradient Descent (SGD)"},{"location":"API/models/sgd/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The l1_ratio parameter is only used when penalty = \"elasticnet\". The eta0 parameter is only used when learning_rate != \"optimal\". The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: loss: str classifier: default=\"hinge\" Categorical([\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"], name=\"loss\") regressor: default=\"squared_loss\" Categorical([\"squared_loss\", \"huber\", \"epsilon_insensitive\", \"squared_epsilon_insensitive\"], name=\"loss\") penalty: str, default=\"l2\" Categorical([\"none\", \"l1\", \"l2\", \"elasticnet\"], name=\"penalty\") alpha: float, default=1e-4 Real(1e-4, 1.0, \"log-uniform\", name=\"alpha\") l1_ratio: float, default=0.15 Categorical(np.linspace(0.1, 0.9, 9), name=\"l1_ratio\"). epsilon: float, default=0.1 Real(1e-4, 1.0, \"log-uniform\", name=\"epsilon\") learning_rate: str, default=\"optimal\" Categorical([\"constant\", \"invscaling\", \"optimal\", \"adaptive\"], name = \"learning_rate\") eta0: float, default=1e-4 Real(1e-4, 1.0, \"log-uniform\", name=\"eta0\"). power_t: float, default=0.5 Categorical(np.linspace(0.1, 0.9, 9), name=\"power_t\") average: bool, default=False Categorical([True, False], name=\"average\")","title":"Hyperparameters"},{"location":"API/models/sgd/#attributes","text":"","title":"Attributes"},{"location":"API/models/sgd/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/sgd/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/sgd/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. decision_function_train: np.ndarray Decision function scores on the training set (only if classifier). decision_function_test: np.ndarray Decision function scores on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/sgd/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.sgd.plot_permutation_importance() or atom.sgd.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/sgd/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(models=\"SGD\", metric=\"recall\", bo_params={\"cv\": 3})","title":"Example"},{"location":"API/models/tree/","text":"Decision Tree (Tree) A single decision tree classifier/regressor. Corresponding estimators are: DecisionTreeClassifier for classification tasks. DecisionTreeRegressor for regression tasks. Read more in sklearn's documentation . Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: criterion: str classifier: default=\"gini\" Categorical([\"gini\", \"entropy\"], name=\"criterion\") regressor: default=\"mse\" Categorical([\"mse\", \"mae\", \"friedman_mse\"], name=\"criterion\") splitter: str, default=\"best\" Categorical([\"best\", \"random\"], name=\"splitter\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") ccp_alpha: float, default=0.0 Real(0, 0.035, name=\"ccp_alpha\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.tree.plot_permutation_importance() or atom.tree.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Tree\", metric=\"MSLE\")","title":"Decision Tree"},{"location":"API/models/tree/#decision-tree-tree","text":"A single decision tree classifier/regressor. Corresponding estimators are: DecisionTreeClassifier for classification tasks. DecisionTreeRegressor for regression tasks. Read more in sklearn's documentation .","title":"Decision Tree (Tree)"},{"location":"API/models/tree/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The random_state parameter is set equal to that of the training instance. Dimensions: criterion: str classifier: default=\"gini\" Categorical([\"gini\", \"entropy\"], name=\"criterion\") regressor: default=\"mse\" Categorical([\"mse\", \"mae\", \"friedman_mse\"], name=\"criterion\") splitter: str, default=\"best\" Categorical([\"best\", \"random\"], name=\"splitter\") max_depth: int or None, default=None Categorical([None, *list(range(1, 10))], name=\"max_depth\") min_samples_split: int, default=2 Integer(2, 20, name=\"min_samples_split\") min_samples_leaf: int, default=1 Integer(1, 20, name=\"min_samples_leaf\") max_features: float or None, default=None Categorical([None, *np.linspace(0.5, 0.9, 5)], name=\"max_features\") ccp_alpha: float, default=0.0 Real(0, 0.035, name=\"ccp_alpha\")","title":"Hyperparameters"},{"location":"API/models/tree/#attributes","text":"","title":"Attributes"},{"location":"API/models/tree/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/tree/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/tree/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/tree/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.tree.plot_permutation_importance() or atom.tree.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/tree/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"Tree\", metric=\"MSLE\")","title":"Example"},{"location":"API/models/xgb/","text":"XGBoost (XGB) XGBoost is an optimized distributed gradient boosting model designed to be highly efficient, flexible and portable. XGBoost provides a parallel tree boosting that solve many data science problems in a fast and accurate way. Corresponding estimators are: XGBClassifier for classification tasks. XGBRegressor for regression tasks. Read more in XGBoost's documentation . Note XGBoost allows early stopping to stop the training of unpromising models prematurely! Hyperparameters By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(20, 500, name=\"n_estimators\") learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") max_depth: int, default=6 Integer(1, 10, name=\"max_depth\") gamma: float, default=0.0 Real(0, 1.0, name=\"gamma\") min_child_weight: int, default=1 Integer(1, 20, name=\"min_child_weight\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") colsample_by_tree: float, default=1.0 Categorical(np.linspace(0.3, 1.0, 8), name=\"colsample_by_tree\") reg_alpha: float, default=0.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_alpha\") reg_lambda: float, default=1.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_lambda\") Attributes Data attributes You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ). Utility attributes Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Prediction attributes The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set. Methods The majority of the plots and prediction methods can be called directly from the models , e.g. atom.xgb.plot_permutation_importance() or atom.xgb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"XGB\", metric=\"me\", n_calls=25, bo_params={\"cv\": 1})","title":"XGBoost"},{"location":"API/models/xgb/#xgboost-xgb","text":"XGBoost is an optimized distributed gradient boosting model designed to be highly efficient, flexible and portable. XGBoost provides a parallel tree boosting that solve many data science problems in a fast and accurate way. Corresponding estimators are: XGBClassifier for classification tasks. XGBRegressor for regression tasks. Read more in XGBoost's documentation . Note XGBoost allows early stopping to stop the training of unpromising models prematurely!","title":"XGBoost (XGB)"},{"location":"API/models/xgb/#hyperparameters","text":"By default, the estimator adopts the default parameters provided by it's package. See the user guide on how to customize them. The n_jobs and random_state parameters are set equal to those of the training instance. Dimensions: n_estimators: int, default=100 Integer(20, 500, name=\"n_estimators\") learning_rate: float, default=0.1 Real(0.01, 1.0, \"log-uniform\", name=\"learning_rate\") max_depth: int, default=6 Integer(1, 10, name=\"max_depth\") gamma: float, default=0.0 Real(0, 1.0, name=\"gamma\") min_child_weight: int, default=1 Integer(1, 20, name=\"min_child_weight\") subsample: float, default=1.0 Categorical(np.linspace(0.5, 1.0, 6), name=\"subsample\") colsample_by_tree: float, default=1.0 Categorical(np.linspace(0.3, 1.0, 8), name=\"colsample_by_tree\") reg_alpha: float, default=0.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_alpha\") reg_lambda: float, default=1.0 Categorical([0, 0.01, 0.1, 1, 10, 100], name=\"reg_lambda\")","title":"Hyperparameters"},{"location":"API/models/xgb/#attributes","text":"","title":"Attributes"},{"location":"API/models/xgb/#data-attributes","text":"You can use the same data attributes as the training instances to check the dataset that was used to fit a particular model. These can differ from each other if the model needs scaled features and the data wasn't already scaled. Note that, unlike with the training instances, these attributes not be updated (i.e. they have no @setter ).","title":"Data attributes"},{"location":"API/models/xgb/#utility-attributes","text":"Attributes: bo: pd.DataFrame Dataframe containing the information of every step taken by the BO. Columns include: \"params\": Parameters used in the model. \"estimator\": Estimator used for this iteration (fitted on last cross-validation). \"score\": Score of the chosen metric. List of scores for multi-metric. \"time_iteration\": Time spent on this iteration. \"time\": Total time spent since the start of the BO. best_params: dict Dictionary of the best combination of hyperparameters found by the BO. estimator: class Estimator instance with the best combination of hyperparameters fitted on the complete training set. time_bo: str Time it took to run the bayesian optimization algorithm. metric_bo: float or list Best metric score(s) on the BO. time_fit: str Time it took to train the model on the complete training set and calculate the metric(s) on the test set. metric_train: float or list Metric score(s) on the training set. metric_test: float or list Metric score(s) on the test set. evals: dict Dictionary of the metric calculated during training. The metric is provided by the estimator's package and is different for every task. Available keys are: \"metric\": Name of the metric. \"train\": List of scores calculated on the training set. \"test\": List of scores calculated on the test set. metric_bagging: list Array of the bagging's results. mean_bagging: float Mean of the bagging's results. std_bagging: float Standard deviation of the bagging's results. results: pd.DataFrame Dataframe of the training results with the model acronym as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/models/xgb/#prediction-attributes","text":"The prediction attributes are not calculated until the attribute is called for the first time. This mechanism avoids having to calculate attributes that are never used, saving time and memory. Prediction attributes: predict_train: np.ndarray Predictions of the model on the training set. predict_test: np.ndarray Predictions of the model on the test set. predict_proba_train: np.ndarray Predicted probabilities of the model on the training set (only if classifier). predict_proba_test: np.ndarray Predicted probabilities of the model on the test set (only if classifier). predict_log_proba_train: np.ndarray Predicted log probabilities of the model on the training set (only if classifier). predict_log_proba_test: np.ndarray Predicted log probabilities of the model on the test set (only if classifier). score_train: np.float64 Model's score on the training set. score_test: np.float64 Model's score on the test set.","title":"Prediction attributes"},{"location":"API/models/xgb/#methods","text":"The majority of the plots and prediction methods can be called directly from the models , e.g. atom.xgb.plot_permutation_importance() or atom.xgb.predict(X) . The remaining utility methods can be found hereunder: calibrate Calibrate the model. reset_prediction_attributes Clear all the prediction attributes. scoring Get the scoring of a specific metric on the test set. save_estimator Save the estimator to a pickle file. method calibrate (**kwargs) [source] Applies probability calibration on the estimator. The calibration is done using the CalibratedClassifierCV class from sklearn. The calibrator will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes will reset. Only if classifier. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method reset_prediction_attributes () [source] Clear all the prediction attributes. Use this method to free some memory before saving the class. method scoring (metric=None, dataset=\"test\") [source] Returns the model's score for a specific metric. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics (only if classifier): \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the final results for this model (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method save_estimator (filename=None) [source] Save the estimator to a pickle file. Parameters: filename: str or None, optional (default=None) Name of the file to save. If None or \"auto\", the estimator's name is used.","title":"Methods"},{"location":"API/models/xgb/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(models=\"XGB\", metric=\"me\", n_calls=25, bo_params={\"cv\": 1})","title":"Example"},{"location":"API/plots/decision_plot/","text":"decision_plot method decision_plot (models=None, index=None, show=None, target=1, title=None, figsize=None, filename=None, display=True, **kwargs) [source] Plot SHAP's decision plot. Visualize model decisions using cumulative SHAP values. Each plotted line explains a single model prediction. If a single prediction is plotted, feature values will be printed in the plot (if supplied). If multiple predictions are plotted together, feature values will not be printed. Plotting too many predictions together will make the plot unintelligible. The explainer will be chosen automatically based on the model's type. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int, list, tuple or None, optional (default=None) Indices of the rows in the dataset to plot. If tuple (n, m), select rows n until m. If None, select all rows in the test set. show: int or None, optional (default=None) Number of features (ordered by importance) to show in the plot. None to show all. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to the number of features. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's decision_plot. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(\"RF\") atom.decision_plot(index=(120, 140)) atom.decision_plot(index=120)","title":"decision_plot"},{"location":"API/plots/decision_plot/#decision_plot","text":"method decision_plot (models=None, index=None, show=None, target=1, title=None, figsize=None, filename=None, display=True, **kwargs) [source] Plot SHAP's decision plot. Visualize model decisions using cumulative SHAP values. Each plotted line explains a single model prediction. If a single prediction is plotted, feature values will be printed in the plot (if supplied). If multiple predictions are plotted together, feature values will not be printed. Plotting too many predictions together will make the plot unintelligible. The explainer will be chosen automatically based on the model's type. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int, list, tuple or None, optional (default=None) Indices of the rows in the dataset to plot. If tuple (n, m), select rows n until m. If None, select all rows in the test set. show: int or None, optional (default=None) Number of features (ordered by importance) to show in the plot. None to show all. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to the number of features. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's decision_plot.","title":"decision_plot"},{"location":"API/plots/decision_plot/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(\"RF\") atom.decision_plot(index=(120, 140)) atom.decision_plot(index=120)","title":"Example"},{"location":"API/plots/dependence_plot/","text":"dependence_plot method dependence_plot (models=None, index=\"rank(1)\", target=1, title=None, figsize=(10, 6), filename=None, display=True, **kwargs) [source] Plot SHAP's dependence plot. Plots the value of the feature on the x-axis and the SHAP value of the same feature on the y-axis. This shows how the model depends on the given feature, and is like a richer extension of the classical partial dependence plots. Vertical dispersion of the data points represents interaction effects. Grey ticks along the y-axis are data points where the feature's value was NaN. The explainer will be chosen automatically based on the model's type. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int, list, tuple or None, optional (default=\"rank(1)\") If this is an int, it is the index of the feature to plot. If this is a string it is either the name of the feature to plot, or it can have the form \"rank(int)\" to specify the feature with that rank (ordered by mean absolute SHAP value over all the samples). target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's dependence_plot. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(\"RF\") atom.dependence_plot(index=\"rank(3)\")","title":"dependence_plot"},{"location":"API/plots/dependence_plot/#dependence_plot","text":"method dependence_plot (models=None, index=\"rank(1)\", target=1, title=None, figsize=(10, 6), filename=None, display=True, **kwargs) [source] Plot SHAP's dependence plot. Plots the value of the feature on the x-axis and the SHAP value of the same feature on the y-axis. This shows how the model depends on the given feature, and is like a richer extension of the classical partial dependence plots. Vertical dispersion of the data points represents interaction effects. Grey ticks along the y-axis are data points where the feature's value was NaN. The explainer will be chosen automatically based on the model's type. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int, list, tuple or None, optional (default=\"rank(1)\") If this is an int, it is the index of the feature to plot. If this is a string it is either the name of the feature to plot, or it can have the form \"rank(int)\" to specify the feature with that rank (ordered by mean absolute SHAP value over all the samples). target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's dependence_plot.","title":"dependence_plot"},{"location":"API/plots/dependence_plot/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(\"RF\") atom.dependence_plot(index=\"rank(3)\")","title":"Example"},{"location":"API/plots/force_plot/","text":"force_plot method force_plot (models=None, index=None, target=1, title=None, figsize=(14, 6), filename=None, display=True, **kwargs) [source] Plot SHAP's force plot. Visualize the given SHAP values with an additive force layout. The explainer will be chosen automatically based on the model's type. Note that by default this plot will render using javascript. For a regular figure use matplotlib=True (this option is only available when only 1 row is selected through the index parameter). Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int, list, tuple or None, optional (default=None) Indices of the rows in the dataset to plot. If tuple (n, m), select rows n until m. If None, select all rows in the test set. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(14, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If matplotlib=False, the figure will be saved as an html file. If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's force_plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(\"lr\") atom.force_plot(index=atom.X_test.index[0], matplotlib=True, filename=\"force_plot\")","title":"force_plot"},{"location":"API/plots/force_plot/#force_plot","text":"method force_plot (models=None, index=None, target=1, title=None, figsize=(14, 6), filename=None, display=True, **kwargs) [source] Plot SHAP's force plot. Visualize the given SHAP values with an additive force layout. The explainer will be chosen automatically based on the model's type. Note that by default this plot will render using javascript. For a regular figure use matplotlib=True (this option is only available when only 1 row is selected through the index parameter). Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int, list, tuple or None, optional (default=None) Indices of the rows in the dataset to plot. If tuple (n, m), select rows n until m. If None, select all rows in the test set. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(14, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If matplotlib=False, the figure will be saved as an html file. If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's force_plot.","title":"force_plot"},{"location":"API/plots/force_plot/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(\"lr\") atom.force_plot(index=atom.X_test.index[0], matplotlib=True, filename=\"force_plot\")","title":"Example"},{"location":"API/plots/plot_bagging/","text":"plot_bagging method plot_bagging (models=None, metric=0, title=None, figsize=None, filename=None, display=True) [source] Plot a boxplot of the bagging's results. Only available for models fitted using bagging . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline that used bagging are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size the to number of models. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"Tree\", \"LGB\", \"MLP\"], metric=\"accuracy\", bagging=5) atom.plot_bagging()","title":"plot_bagging"},{"location":"API/plots/plot_bagging/#plot_bagging","text":"method plot_bagging (models=None, metric=0, title=None, figsize=None, filename=None, display=True) [source] Plot a boxplot of the bagging's results. Only available for models fitted using bagging . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline that used bagging are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size the to number of models. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_bagging"},{"location":"API/plots/plot_bagging/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"Tree\", \"LGB\", \"MLP\"], metric=\"accuracy\", bagging=5) atom.plot_bagging()","title":"Example"},{"location":"API/plots/plot_bo/","text":"plot_bo method plot_bo (models=None, metric=0, title=None, figsize=(10, 8), filename=None, display=True) [source] Plot the bayesian optimization scoring. Only for models that ran the hyperparameter optimization. This is the same plot as the one produced by bo_params={\"plot_bo\": True} while running the optimization. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline that used bayesian optimization are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 8)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LDA\", \"LGB\"], metric=\"f1\", n_calls=24, n_initial_points=10) atom.plot_bo()","title":"plot_bo"},{"location":"API/plots/plot_bo/#plot_bo","text":"method plot_bo (models=None, metric=0, title=None, figsize=(10, 8), filename=None, display=True) [source] Plot the bayesian optimization scoring. Only for models that ran the hyperparameter optimization. This is the same plot as the one produced by bo_params={\"plot_bo\": True} while running the optimization. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline that used bayesian optimization are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 8)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_bo"},{"location":"API/plots/plot_bo/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LDA\", \"LGB\"], metric=\"f1\", n_calls=24, n_initial_points=10) atom.plot_bo()","title":"Example"},{"location":"API/plots/plot_calibration/","text":"plot_calibration method plot_calibration (models=None, n_bins=10, title=None, figsize=(10, 10), filename=None, display=True) [source] Plot the calibration curve for a binary classifier. Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class. Read more in sklearn's documentation . This figure shows two plots: the calibration curve, where the x-axis represents the average predicted probability in each bin and the y-axis is the fraction of positives, i.e. the proportion of samples whose class is the positive class (in each bin); and a distribution of all predicted probabilities of the classifier. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. n_bins: int, optional (default=10) Number of bins for the calibration calculation and the histogram. Minimum of 5 required. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X) atom.run([\"GNB\", \"LR\", \"LGB\"], metric=\"average_precision\") atom.plot_calibration()","title":"plot_calibration"},{"location":"API/plots/plot_calibration/#plot_calibration","text":"method plot_calibration (models=None, n_bins=10, title=None, figsize=(10, 10), filename=None, display=True) [source] Plot the calibration curve for a binary classifier. Well calibrated classifiers are probabilistic classifiers for which the output of the predict_proba method can be directly interpreted as a confidence level. For instance a well calibrated (binary) classifier should classify the samples such that among the samples to which it gave a predict_proba value close to 0.8, approx. 80% actually belong to the positive class. Read more in sklearn's documentation . This figure shows two plots: the calibration curve, where the x-axis represents the average predicted probability in each bin and the y-axis is the fraction of positives, i.e. the proportion of samples whose class is the positive class (in each bin); and a distribution of all predicted probabilities of the classifier. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. n_bins: int, optional (default=10) Number of bins for the calibration calculation and the histogram. Minimum of 5 required. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 10)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_calibration"},{"location":"API/plots/plot_calibration/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X) atom.run([\"GNB\", \"LR\", \"LGB\"], metric=\"average_precision\") atom.plot_calibration()","title":"Example"},{"location":"API/plots/plot_components/","text":"plot_components method plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. Only available if PCA was applied on the data. Parameters: show: int or None, optional (default=None) Number of components to show. If None, the number of components in the data are plotted. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"PCA\", n_features=11) atom.plot_components()","title":"plot_components"},{"location":"API/plots/plot_components/#plot_components","text":"method plot_components (show=None, title=None, figsize=None, filename=None, display=True) [source] Plot the explained variance ratio per components. Only available if PCA was applied on the data. Parameters: show: int or None, optional (default=None) Number of components to show. If None, the number of components in the data are plotted. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_components"},{"location":"API/plots/plot_components/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"PCA\", n_features=11) atom.plot_components()","title":"Example"},{"location":"API/plots/plot_confusion_matrix/","text":"plot_confusion_matrix method plot_confusion_matrix (models=None, dataset=\"test\", normalize=False, title=None, figsize=None, filename=None, display=True) [source] Plot a model's confusion matrix. Only for classification tasks. For 1 model: plot the confusion matrix in a heatmap. For multiple models: compare TP, FP, FN and TN in a barplot (not implemented for multiclass classification tasks). Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the confusion matrix. Options are \"train\" or \"test\". normalize: bool, optional (default=False) Whether to normalize the matrix. Only for the heatmap plot. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to plot type. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"Bag\"]) atom.Tree.plot_confusion_matrix(normalize=True) atom.plot_confusion_matrix()","title":"plot_confusion_matrix"},{"location":"API/plots/plot_confusion_matrix/#plot_confusion_matrix","text":"method plot_confusion_matrix (models=None, dataset=\"test\", normalize=False, title=None, figsize=None, filename=None, display=True) [source] Plot a model's confusion matrix. Only for classification tasks. For 1 model: plot the confusion matrix in a heatmap. For multiple models: compare TP, FP, FN and TN in a barplot (not implemented for multiclass classification tasks). Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the confusion matrix. Options are \"train\" or \"test\". normalize: bool, optional (default=False) Whether to normalize the matrix. Only for the heatmap plot. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=None) Figure's size, format as (x, y). If None, adapts size to plot type. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_confusion_matrix"},{"location":"API/plots/plot_confusion_matrix/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"Bag\"]) atom.Tree.plot_confusion_matrix(normalize=True) atom.plot_confusion_matrix()","title":"Example"},{"location":"API/plots/plot_correlation/","text":"plot_correlation method plot_correlation (method=\"pearson\", title=None, figsize=(8, 8), filename=None, display=True) [source] Plot the data's correlation matrix. Ignores non-numeric columns. Parameters: method: str, optional (default=\"pearson\") Method of correlation. Choose from \"pearson\", \"kendall\" or \"spearman\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(8, 8)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, \"RainTomorrow\") atom.plot_correlation()","title":"plot_correlation"},{"location":"API/plots/plot_correlation/#plot_correlation","text":"method plot_correlation (method=\"pearson\", title=None, figsize=(8, 8), filename=None, display=True) [source] Plot the data's correlation matrix. Ignores non-numeric columns. Parameters: method: str, optional (default=\"pearson\") Method of correlation. Choose from \"pearson\", \"kendall\" or \"spearman\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(8, 8)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_correlation"},{"location":"API/plots/plot_correlation/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, \"RainTomorrow\") atom.plot_correlation()","title":"Example"},{"location":"API/plots/plot_errors/","text":"plot_errors method plot_errors (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot a model's prediction errors, i.e. the actual targets from a set against the predicted values generated by the regressor. A linear fit is made on the data. The gray, intersected line shows the identity line. This pot can be useful to detect noise or heteroscedasticity along a range of the target domain. Only for regression tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the errors. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run([\"OLS\", \"LGB\"], metric=\"MAE\") atom.plot_errors()","title":"plot_errors"},{"location":"API/plots/plot_errors/#plot_errors","text":"method plot_errors (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot a model's prediction errors, i.e. the actual targets from a set against the predicted values generated by the regressor. A linear fit is made on the data. The gray, intersected line shows the identity line. This pot can be useful to detect noise or heteroscedasticity along a range of the target domain. Only for regression tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the errors. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_errors"},{"location":"API/plots/plot_errors/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run([\"OLS\", \"LGB\"], metric=\"MAE\") atom.plot_errors()","title":"Example"},{"location":"API/plots/plot_evals/","text":"plot_evals method plot_evals (models=None, dataset=\"both\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot evaluation curves for the train and test set. Only for models that allow in-training evaluation (XGB, LGB, CatB). The metric is provided by the estimator's package and is different for every model and every task. For this reason, the method only allows plotting one model at a time. Parameters: models: str, list, tuple or None, optional (default=None) Name of the model to plot. If None, all models in the pipeline are selected. Note that leaving the default option could raise an exception if there are multiple models in the pipeline. To avoid this, call the plot from a model , e.g. atom.lgb.plot_evals() . dataset: str, optional (default=\"both\") Data set on which to calculate the evaluation curves. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run([\"Bag\", \"LGB\"]) atom.lgb.plot_evals()","title":"plot_evals"},{"location":"API/plots/plot_evals/#plot_evals","text":"method plot_evals (models=None, dataset=\"both\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot evaluation curves for the train and test set. Only for models that allow in-training evaluation (XGB, LGB, CatB). The metric is provided by the estimator's package and is different for every model and every task. For this reason, the method only allows plotting one model at a time. Parameters: models: str, list, tuple or None, optional (default=None) Name of the model to plot. If None, all models in the pipeline are selected. Note that leaving the default option could raise an exception if there are multiple models in the pipeline. To avoid this, call the plot from a model , e.g. atom.lgb.plot_evals() . dataset: str, optional (default=\"both\") Data set on which to calculate the evaluation curves. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_evals"},{"location":"API/plots/plot_evals/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run([\"Bag\", \"LGB\"]) atom.lgb.plot_evals()","title":"Example"},{"location":"API/plots/plot_feature_importance/","text":"plot_feature_importance method plot_feature_importance (models=None, show=None, title=None, figsize=None, filename=None, display=True) [source] Plot a tree-based model's feature importance. The importances are normalized in order to be able to compare them between models. The feature_importance attribute is updated with the extracted importance ranking. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None to show all. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"RF\"], metric=\"recall_weighted\") atom.RF.plot_feature_importance(show=11, filename=\"random_forest_importance.png\")","title":"plot_feature_importance"},{"location":"API/plots/plot_feature_importance/#plot_feature_importance","text":"method plot_feature_importance (models=None, show=None, title=None, figsize=None, filename=None, display=True) [source] Plot a tree-based model's feature importance. The importances are normalized in order to be able to compare them between models. The feature_importance attribute is updated with the extracted importance ranking. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None to show all. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_feature_importance"},{"location":"API/plots/plot_feature_importance/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"RF\"], metric=\"recall_weighted\") atom.RF.plot_feature_importance(show=11, filename=\"random_forest_importance.png\")","title":"Example"},{"location":"API/plots/plot_gains/","text":"plot_gains method plot_gains (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the cumulative gains curve. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the gains curve. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"GNB\", \"RF\", \"LGB\"], metric=\"roc_auc\") atom.plot_gains(filename=\"cumulative_gains_curve.png\")","title":"plot_gains"},{"location":"API/plots/plot_gains/#plot_gains","text":"method plot_gains (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the cumulative gains curve. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the gains curve. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_gains"},{"location":"API/plots/plot_gains/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"GNB\", \"RF\", \"LGB\"], metric=\"roc_auc\") atom.plot_gains(filename=\"cumulative_gains_curve.png\")","title":"Example"},{"location":"API/plots/plot_learning_curve/","text":"plot_learning_curve method plot_learning_curve (models=None, metric=0, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the model's learning curve: score vs number of training samples. Only available if the models were fitted using train sizing . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example import numpy as np from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.train_sizing([\"GNB\", \"LDA\"], metric=\"accuracy\", train_sizes=np.linspace(0.1, 1.0, 9), bagging=5) atom.plot_learning_curve()","title":"plot_learning_curve"},{"location":"API/plots/plot_learning_curve/#plot_learning_curve","text":"method plot_learning_curve (models=None, metric=0, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the model's learning curve: score vs number of training samples. Only available if the models were fitted using train sizing . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_learning_curve"},{"location":"API/plots/plot_learning_curve/#example","text":"import numpy as np from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.train_sizing([\"GNB\", \"LDA\"], metric=\"accuracy\", train_sizes=np.linspace(0.1, 1.0, 9), bagging=5) atom.plot_learning_curve()","title":"Example"},{"location":"API/plots/plot_lift/","text":"plot_lift method plot_lift (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the lift curve. Only for binary classification. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the lift curve. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"GNB\", \"RF\", \"LGB\"], metric=\"roc_auc\") atom.plot_lift(filename=\"lift_curve.png\")","title":"plot_lift"},{"location":"API/plots/plot_lift/#plot_lift","text":"method plot_lift (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the lift curve. Only for binary classification. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the lift curve. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_lift"},{"location":"API/plots/plot_lift/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"GNB\", \"RF\", \"LGB\"], metric=\"roc_auc\") atom.plot_lift(filename=\"lift_curve.png\")","title":"Example"},{"location":"API/plots/plot_partial_dependence/","text":"plot_partial_dependence method plot_partial_dependence (models=None, features=None, target=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the partial dependence of features. The partial dependence of a feature (or a set of features) corresponds to the average response of the model for each possible value of the feature. Two-way partial dependence plots are plotted as contour plots (only allowed for single model plots). The deciles of the feature values will be shown with tick marks on the x-axes for one-way plots, and on both axes for two-way plots. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. features: int, str, list, tuple or None, optional (default=None) Features or feature pairs (name or index) to get the partial dependence from. Maximum of 3 allowed. If None, it uses the top 3 features if feature_importance is defined (see plot_feature_importance or plot_permutation_importance ), else it uses the first 3 features in the dataset. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"PCA\", n_features=6) atom.run([\"Tree\", \"Bag\"], metric=\"precision\") atom.Tree.plot_partial_dependence(features=[0, 1, (1, 3)]) atom.plot_partial_dependence()","title":"plot_partial_dependence"},{"location":"API/plots/plot_partial_dependence/#plot_partial_dependence","text":"method plot_partial_dependence (models=None, features=None, target=None, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the partial dependence of features. The partial dependence of a feature (or a set of features) corresponds to the average response of the model for each possible value of the feature. Two-way partial dependence plots are plotted as contour plots (only allowed for single model plots). The deciles of the feature values will be shown with tick marks on the x-axes for one-way plots, and on both axes for two-way plots. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. features: int, str, list, tuple or None, optional (default=None) Features or feature pairs (name or index) to get the partial dependence from. Maximum of 3 allowed. If None, it uses the top 3 features if feature_importance is defined (see plot_feature_importance or plot_permutation_importance ), else it uses the first 3 features in the dataset. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_partial_dependence"},{"location":"API/plots/plot_partial_dependence/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"PCA\", n_features=6) atom.run([\"Tree\", \"Bag\"], metric=\"precision\") atom.Tree.plot_partial_dependence(features=[0, 1, (1, 3)]) atom.plot_partial_dependence()","title":"Example"},{"location":"API/plots/plot_pca/","text":"plot_pca method plot_pca (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of components. Only available if PCA was applied on the data. Parameters: title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"PCA\", n_features=11) atom.plot_pca()","title":"plot_pca"},{"location":"API/plots/plot_pca/#plot_pca","text":"method plot_pca (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the explained variance ratio vs the number of components. Only available if PCA was applied on the data. Parameters: title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_pca"},{"location":"API/plots/plot_pca/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"PCA\", n_features=11) atom.plot_pca()","title":"Example"},{"location":"API/plots/plot_permutation_importance/","text":"plot_permutation_importance method plot_permutation_importance (models=None, show=None, n_repeats=10, title=None, figsize=None, filename=None, display=True) [source] Plot the feature permutation importance of models. Calculating all permutations can be time consuming, especially if n_repeats is high. They are stored under the attribute permutations . This means that if a plot is repeated for the same model with the same n_repeats , it will be considerably faster. The feature_importance attribute is updated with the extracted importance ranking. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None to show all. n_repeats: int, optional (default=10) Number of times to permute each feature. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"LDA\"], metric=\"average_precision\") atom.LDA.plot_permutation_importance(show=10, n_repeats=7)","title":"plot_permutation_importance"},{"location":"API/plots/plot_permutation_importance/#plot_permutation_importance","text":"method plot_permutation_importance (models=None, show=None, n_repeats=10, title=None, figsize=None, filename=None, display=True) [source] Plot the feature permutation importance of models. Calculating all permutations can be time consuming, especially if n_repeats is high. They are stored under the attribute permutations . This means that if a plot is repeated for the same model with the same n_repeats , it will be considerably faster. The feature_importance attribute is updated with the extracted importance ranking. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. show: int, optional (default=None) Number of best features to show in the plot. None to show all. n_repeats: int, optional (default=10) Number of times to permute each feature. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_permutation_importance"},{"location":"API/plots/plot_permutation_importance/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"LDA\"], metric=\"average_precision\") atom.LDA.plot_permutation_importance(show=10, n_repeats=7)","title":"Example"},{"location":"API/plots/plot_pipeline/","text":"plot_pipeline method plot_pipeline (show_params=True, title=None, figsize=None, filename=None, display=True) [source] Plot a diagram of every estimator in atom 's pipeline. Parameters: show_params: bool, optional (default=True) Whether to show the parameters used for every estimator. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to the length of the pipeline. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.impute(strat_num=\"median\", strat_cat=\"drop\", min_frac_rows=0.8) atom.encode(strategy=\"LeaveOneOut\", max_onehot=8, frac_to_other=0.02) atom.outliers(strategy=\"drop\", max_sigma=4, include_target=False) atom.feature_selection( strategy=\"PCA\", n_features=10, max_frac_repeated=1., max_correlation=0.7 ) atom.run( models=[\"GBM\", \"LGB\"], metric=\"recall_weighted\", n_calls=(10, 20), n_initial_points=(5, 12), bo_params={\"base_estimator\": \"RF\", \"cv\": 1, \"max_time\": 1000}, bagging=4 ) atom.plot_pipeline()","title":"plot_pipeline"},{"location":"API/plots/plot_pipeline/#plot_pipeline","text":"method plot_pipeline (show_params=True, title=None, figsize=None, filename=None, display=True) [source] Plot a diagram of every estimator in atom 's pipeline. Parameters: show_params: bool, optional (default=True) Whether to show the parameters used for every estimator. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to the length of the pipeline. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_pipeline"},{"location":"API/plots/plot_pipeline/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.impute(strat_num=\"median\", strat_cat=\"drop\", min_frac_rows=0.8) atom.encode(strategy=\"LeaveOneOut\", max_onehot=8, frac_to_other=0.02) atom.outliers(strategy=\"drop\", max_sigma=4, include_target=False) atom.feature_selection( strategy=\"PCA\", n_features=10, max_frac_repeated=1., max_correlation=0.7 ) atom.run( models=[\"GBM\", \"LGB\"], metric=\"recall_weighted\", n_calls=(10, 20), n_initial_points=(5, 12), bo_params={\"base_estimator\": \"RF\", \"cv\": 1, \"max_time\": 1000}, bagging=4 ) atom.plot_pipeline()","title":"Example"},{"location":"API/plots/plot_prc/","text":"plot_prc method plot_prc (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the precision-recall curve. The legend shows the average precision (AP) score. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"RF\", \"LGB\"], metric=\"average_precision\") atom.plot_prc()","title":"plot_prc"},{"location":"API/plots/plot_prc/#plot_prc","text":"method plot_prc (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the precision-recall curve. The legend shows the average precision (AP) score. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_prc"},{"location":"API/plots/plot_prc/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"RF\", \"LGB\"], metric=\"average_precision\") atom.plot_prc()","title":"Example"},{"location":"API/plots/plot_probabilities/","text":"plot_probabilities method plot_probabilities (models=None, dataset=\"test\", target=1, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the probability distribution of the classes in the target column. Only for classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". target: int or str, optional (default=1) Probability of being that class in the target column as index or name. Only for multiclass classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, \"RainTomorrow\") atom.run(\"rf\") atom.plot_probabilities(target=\"Yes\", filename=\"probabilities_class_yes\")","title":"plot_probabilities"},{"location":"API/plots/plot_probabilities/#plot_probabilities","text":"method plot_probabilities (models=None, dataset=\"test\", target=1, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the probability distribution of the classes in the target column. Only for classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". target: int or str, optional (default=1) Probability of being that class in the target column as index or name. Only for multiclass classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_probabilities"},{"location":"API/plots/plot_probabilities/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, \"RainTomorrow\") atom.run(\"rf\") atom.plot_probabilities(target=\"Yes\", filename=\"probabilities_class_yes\")","title":"Example"},{"location":"API/plots/plot_residuals/","text":"plot_residuals method plot_residuals (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] The plot shows the residuals (difference between the predicted and the true value) on the vertical axis and the independent variable on the horizontal axis. The gray, intersected line shows the identity line. This plot can be useful to analyze the variance of the error of the regressor. If the points are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a non-linear model is more appropriate. Only for regression tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run([\"OLS\", \"LGB\"], metric=\"MAE\") atom.plot_residuals()","title":"plot_residuals"},{"location":"API/plots/plot_residuals/#plot_residuals","text":"method plot_residuals (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] The plot shows the residuals (difference between the predicted and the true value) on the vertical axis and the independent variable on the horizontal axis. The gray, intersected line shows the identity line. This plot can be useful to analyze the variance of the error of the regressor. If the points are randomly dispersed around the horizontal axis, a linear regression model is appropriate for the data; otherwise, a non-linear model is more appropriate. Only for regression tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_residuals"},{"location":"API/plots/plot_residuals/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run([\"OLS\", \"LGB\"], metric=\"MAE\") atom.plot_residuals()","title":"Example"},{"location":"API/plots/plot_rfecv/","text":"plot_rfecv method plot_rfecv (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the RFECV results, i.e. the scores obtained by the estimator fitted on every subset of the dataset. Only available if RFECV was applied on the data. Parameters: title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"RFECV\", solver=\"LGB\", scoring=\"precision\") atom.plot_rfecv()","title":"plot_rfecv"},{"location":"API/plots/plot_rfecv/#plot_rfecv","text":"method plot_rfecv (title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the RFECV results, i.e. the scores obtained by the estimator fitted on every subset of the dataset. Only available if RFECV was applied on the data. Parameters: title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_rfecv"},{"location":"API/plots/plot_rfecv/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.feature_selection(strategy=\"RFECV\", solver=\"LGB\", scoring=\"precision\") atom.plot_rfecv()","title":"Example"},{"location":"API/plots/plot_roc/","text":"plot_roc method plot_roc (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the Receiver Operating Characteristics curve. The legend shows the Area Under the ROC Curve (AUC) score. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"RF\", \"LGB\"], metric=\"roc_auc\") atom.plot_roc(filename=\"roc_curve.png\")","title":"plot_roc"},{"location":"API/plots/plot_roc/#plot_roc","text":"method plot_roc (models=None, dataset=\"test\", title=None, figsize=(10, 6), filename=None, display=True) [source] Plot the Receiver Operating Characteristics curve. The legend shows the Area Under the ROC Curve (AUC) score. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_roc"},{"location":"API/plots/plot_roc/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"LR\", \"RF\", \"LGB\"], metric=\"roc_auc\") atom.plot_roc(filename=\"roc_curve.png\")","title":"Example"},{"location":"API/plots/plot_successive_halving/","text":"plot_successive_halving method plot_successive_halving (models=None, metric=0, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot of the models\" scores per iteration of the successive halving. Only available if the models were fitted using successive halving . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.successive_halving([\"bag\", \"adab\", \"et\", \"lgb\"], metric=\"accuracy\", bagging=5) atom.plot_successive_halving(filename=\"plot_successive_halving\")","title":"plot_successive_halving"},{"location":"API/plots/plot_successive_halving/#plot_successive_halving","text":"method plot_successive_halving (models=None, metric=0, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot of the models\" scores per iteration of the successive halving. Only available if the models were fitted using successive halving . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all the models in the pipeline are selected. metric: int or str, optional (default=0) Index or name of the metric to plot. Only for multi-metric runs. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_successive_halving"},{"location":"API/plots/plot_successive_halving/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.successive_halving([\"bag\", \"adab\", \"et\", \"lgb\"], metric=\"accuracy\", bagging=5) atom.plot_successive_halving(filename=\"plot_successive_halving\")","title":"Example"},{"location":"API/plots/plot_threshold/","text":"plot_threshold method plot_threshold (models=None, metric=None, dataset=\"test\", steps=100, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot metric performances against threshold values. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. metric: str, callable, list, tuple or None, optional (default=None) Metric(s) to plot. These can be one of sklearn's pre-defined scorers, a metric function or a sklearn scorer object (see the user guide ). If None, the metric used to run the pipeline is used. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". steps: int, optional (default=100) Number of thresholds measured. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier from sklearn.metrics import recall_score atom = ATOMClassifier(X, y) atom.run(\"LGB\") atom.plot_threshold(metric=[\"accuracy\", \"f1\", recall_score])","title":"plot_threshold"},{"location":"API/plots/plot_threshold/#plot_threshold","text":"method plot_threshold (models=None, metric=None, dataset=\"test\", steps=100, title=None, figsize=(10, 6), filename=None, display=True) [source] Plot metric performances against threshold values. Only for binary classification tasks. Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. metric: str, callable, list, tuple or None, optional (default=None) Metric(s) to plot. These can be one of sklearn's pre-defined scorers, a metric function or a sklearn scorer object (see the user guide ). If None, the metric used to run the pipeline is used. dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\", \"test\" or \"both\". steps: int, optional (default=100) Number of thresholds measured. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple, optional (default=(10, 6)) Figure's size, format as (x, y). filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"plot_threshold"},{"location":"API/plots/plot_threshold/#example","text":"from atom import ATOMClassifier from sklearn.metrics import recall_score atom = ATOMClassifier(X, y) atom.run(\"LGB\") atom.plot_threshold(metric=[\"accuracy\", \"f1\", recall_score])","title":"Example"},{"location":"API/plots/summary_plot/","text":"summary_plot method summary_plot (models=None, show=None, target=1, title=None, figsize=None, filename=None, display=True, **kwargs) [source] Plot SHAP's summary plot. Create a SHAP beeswarm plot, colored by feature values when they are provided. The explainer will be chosen automatically based on the model's type. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . show: int or None, optional (default=None) Number of features to show in the plot. None to show all. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's summary_plot. Example from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(\"RF\") atom.summary_plot(show=11)","title":"summary_plot"},{"location":"API/plots/summary_plot/#summary_plot","text":"method summary_plot (models=None, show=None, target=1, title=None, figsize=None, filename=None, display=True, **kwargs) [source] Plot SHAP's summary plot. Create a SHAP beeswarm plot, colored by feature values when they are provided. The explainer will be chosen automatically based on the model's type. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . show: int or None, optional (default=None) Number of features to show in the plot. None to show all. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. **kwargs Additional keyword arguments for shap's summary_plot.","title":"summary_plot"},{"location":"API/plots/summary_plot/#example","text":"from atom import ATOMRegressor atom = ATOMRegressor(X, y) atom.run(\"RF\") atom.summary_plot(show=11)","title":"Example"},{"location":"API/plots/waterfall_plot/","text":"waterfall_plot method waterfall_plot (models=None, index=None, show=None, target=1, title=None, figsize=None, filename=None, display=True) [source] Plot SHAP's waterfall plot for a single prediction. The SHAP value of a feature represents the impact of the evidence provided by that feature on the model\u2019s output. The waterfall plot is designed to visually display how the SHAP values (evidence) of each feature move the model output from our prior expectation under the background data distribution, to the final model prediction given the evidence of all the features. Features are sorted by the magnitude of their SHAP values with the smallest magnitude features grouped together at the bottom of the plot when the number of features in the models exceeds the show parameter. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int or None, optional (default=None) Index of the row in the dataset to plot. If None, selects a random row in the test set. show: int or None, optional (default=None) Number of features to show in the plot. None to show all. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(\"Tree\") atom.tree.waterfall_plot(show=11)","title":"waterfall_plot"},{"location":"API/plots/waterfall_plot/#waterfall_plot","text":"method waterfall_plot (models=None, index=None, show=None, target=1, title=None, figsize=None, filename=None, display=True) [source] Plot SHAP's waterfall plot for a single prediction. The SHAP value of a feature represents the impact of the evidence provided by that feature on the model\u2019s output. The waterfall plot is designed to visually display how the SHAP values (evidence) of each feature move the model output from our prior expectation under the background data distribution, to the final model prediction given the evidence of all the features. Features are sorted by the magnitude of their SHAP values with the smallest magnitude features grouped together at the bottom of the plot when the number of features in the models exceeds the show parameter. Read more about SHAP plots in the user guide . Parameters: models: str, list, tuple or None, optional (default=None) Name of the models to plot. If None, all models in the pipeline are selected. Note that selecting multiple models will raise an exception. To avoid this, call the plot from a model . index: int or None, optional (default=None) Index of the row in the dataset to plot. If None, selects a random row in the test set. show: int or None, optional (default=None) Number of features to show in the plot. None to show all. target: int or str, optional (default=1) Category to look at in the target class as index or name. Only for multi-class classification tasks. title: str or None, optional (default=None) Plot's title. If None, the default option is used. figsize: tuple or None, optional (default=None) Figure's size, format as (x, y). If None, adapts size to show parameter. filename: str or None, optional (default=None) Name of the file (to save). If None, the figure is not saved. display: bool, optional (default=True) Whether to render the plot.","title":"waterfall_plot"},{"location":"API/plots/waterfall_plot/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(\"Tree\") atom.tree.waterfall_plot(show=11)","title":"Example"},{"location":"API/predicting/decision_function/","text":"decision_function method decision_function (X, verbose=None, **kwargs) [source] Transform the data and evaluate the decision function on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a decision_function method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(\"kSVM\", metric=\"accuracy\") # Evaluate the decision function on new data predictions = atom.ksvm.decision_function(X_new)","title":"decision_function"},{"location":"API/predicting/decision_function/#decision_function","text":"method decision_function (X, verbose=None, **kwargs) [source] Transform the data and evaluate the decision function on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a decision_function method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations.","title":"decision_function"},{"location":"API/predicting/decision_function/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run(\"kSVM\", metric=\"accuracy\") # Evaluate the decision function on new data predictions = atom.ksvm.decision_function(X_new)","title":"Example"},{"location":"API/predicting/predict/","text":"predict method predict (X, verbose=None, **kwargs) [source] Transform the data and make predictions on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a predict method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"AdaB\"], metric=\"AP\", n_calls=10) # Make predictions on new data predictions = atom.adab.predict(X_new)","title":"predict"},{"location":"API/predicting/predict/#predict","text":"method predict (X, verbose=None, **kwargs) [source] Transform the data and make predictions on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a predict method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations.","title":"predict"},{"location":"API/predicting/predict/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"AdaB\"], metric=\"AP\", n_calls=10) # Make predictions on new data predictions = atom.adab.predict(X_new)","title":"Example"},{"location":"API/predicting/predict_log_proba/","text":"predict_log_proba method predict_log_proba (X, verbose=None, **kwargs) [source] Transform the data and make logarithmic probability predictions on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a predict_log_proba method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"AdaB\"], metric=\"AP\", n_calls=10) # Make predictions on new data predictions = atom.adab.predict_log_proba(X_new)","title":"predict_log_proba"},{"location":"API/predicting/predict_log_proba/#predict_log_proba","text":"method predict_log_proba (X, verbose=None, **kwargs) [source] Transform the data and make logarithmic probability predictions on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a predict_log_proba method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations.","title":"predict_log_proba"},{"location":"API/predicting/predict_log_proba/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"AdaB\"], metric=\"AP\", n_calls=10) # Make predictions on new data predictions = atom.adab.predict_log_proba(X_new)","title":"Example"},{"location":"API/predicting/predict_proba/","text":"predict_proba method predict_proba (X, verbose=None, **kwargs) [source] Transform the data and make probabilistic predictions on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a predict_proba method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"AdaB\"], metric=\"AP\", n_calls=10) # Make predictions on new data predictions = atom.adab.predict_proba(X_new)","title":"predict_proba"},{"location":"API/predicting/predict_proba/#predict_proba","text":"method predict_proba (X, verbose=None, **kwargs) [source] Transform the data and make probabilistic predictions on new data. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a predict_proba method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations.","title":"predict_proba"},{"location":"API/predicting/predict_proba/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"Tree\", \"AdaB\"], metric=\"AP\", n_calls=10) # Make predictions on new data predictions = atom.adab.predict_proba(X_new)","title":"Example"},{"location":"API/predicting/score/","text":"score method score (X, y, sample_weight=None, verbose=None, **kwargs) [source] Transform the data and return the model's score on new data. The score is a default evaluation criterion for the problem the estimator is designed to solve, defined by the estimator's package. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a score method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If int: Position of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). sample_weight: array-like or None, optional (default=None) Sample weights with shape=(n_samples,). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations. Note The returned metric is determined by each estimator's score method predefined by its respective package. See its corresponding documentation for further details. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"MNB\", \"KNN\", \"kSVM\"], metric=\"precision\") # Get the mean accuracy on new data predictions = atom.kSVM.score(X_new, y_new)","title":"score"},{"location":"API/predicting/score/#score","text":"method score (X, y, sample_weight=None, verbose=None, **kwargs) [source] Transform the data and return the model's score on new data. The score is a default evaluation criterion for the problem the estimator is designed to solve, defined by the estimator's package. If called from a training instance, it will use the best model in the pipeline (under the winner attribute). If called from a model , it will use that model. The estimator must have a score method. Parameters: X: dict, list, tuple, np.array or pd.DataFrame Data containing the features, with shape=(n_samples, n_features). y: int, str, sequence, np.array or pd.Series If int: Position of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). sample_weight: array-like or None, optional (default=None) Sample weights with shape=(n_samples,). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Same keyword arguments as the transform method to include/exclude transformers from the transformations. Note The returned metric is determined by each estimator's score method predefined by its respective package. See its corresponding documentation for further details.","title":"score"},{"location":"API/predicting/score/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.run([\"MNB\", \"KNN\", \"kSVM\"], metric=\"precision\") # Get the mean accuracy on new data predictions = atom.kSVM.score(X_new, y_new)","title":"Example"},{"location":"API/predicting/transform/","text":"transform method transform (X, y=None, verbose=None, **kwargs) [source] Transform new data through all the pre-processing steps in the pipeline. By default, all transformers are included except outliers and balance since they should only be applied on the training set. Can only be called from atom . Parameters: X: dict, list, tuple, np.array or pd.DataFrame Features to transform, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformers. If int: Position of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Additional keyword arguments to customize which transformers to apply. You can either select them including their index in the pipeline parameter, e.g. pipeline=[0, 1, 4] or include/exclude them individually using their methods, e.g. impute=True or feature_selection=False . Note When using the pipeline parameter to include/exclude transformers, remember that the first transformer (index 0) in atom 's pipeline is always the Cleaner called during initialization. Example from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.impute(strat_num=\"knn\", strat_cat=\"drop\") atom.outliers(strategy=\"min_max\", max_sigma=2) atom.feature_generation(strategy=\"gfg\", n_features=3, generations=10, population=1000) # Apply only the Cleaner and Imputer on new data X_transformed = atom.transform(X_new, pipeline=[0, 1])","title":"transform"},{"location":"API/predicting/transform/#transform","text":"method transform (X, y=None, verbose=None, **kwargs) [source] Transform new data through all the pre-processing steps in the pipeline. By default, all transformers are included except outliers and balance since they should only be applied on the training set. Can only be called from atom . Parameters: X: dict, list, tuple, np.array or pd.DataFrame Features to transform, with shape=(n_samples, n_features). y: int, str, sequence, np.array, pd.Series or None, optional (default=None) If None: y is ignored in the transformers. If int: Position of the target column in X. If str: Name of the target column in X. Else: Target column with shape=(n_samples,). verbose: int or None, optional (default=None) Verbosity level of the output. If None, it uses the training 's verbosity. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. **kwargs Additional keyword arguments to customize which transformers to apply. You can either select them including their index in the pipeline parameter, e.g. pipeline=[0, 1, 4] or include/exclude them individually using their methods, e.g. impute=True or feature_selection=False . Note When using the pipeline parameter to include/exclude transformers, remember that the first transformer (index 0) in atom 's pipeline is always the Cleaner called during initialization.","title":"transform"},{"location":"API/predicting/transform/#example","text":"from atom import ATOMClassifier atom = ATOMClassifier(X, y) atom.impute(strat_num=\"knn\", strat_cat=\"drop\") atom.outliers(strategy=\"min_max\", max_sigma=2) atom.feature_generation(strategy=\"gfg\", n_features=3, generations=10, population=1000) # Apply only the Cleaner and Imputer on new data X_transformed = atom.transform(X_new, pipeline=[0, 1])","title":"Example"},{"location":"API/training/successivehalvingclassifier/","text":"SuccessiveHalvingClassifier class atom.training. SuccessiveHalvingClassifier (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a successive halving fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the complete training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the SuccessiveHalvingClassifier instance. Read more in the user guide . Parameters: models: str or sequence Models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"Ridge\" for Ridge Classification \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. skip_runs: int, optional (default=0) Skip last skip_runs runs of the successive halving. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column. Utility attributes Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the number of models in a run and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Methods calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_class_weight Return class weights for a balanced data set. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use default name (SuccessiveHalvingClassifier). save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: SuccessiveHalvingClassifier Estimator instance. Example from atom.training import SuccessiveHalvingClassifier # Run the pipeline trainer = SuccessiveHalvingClassifier([\"Tree\", \"Bag\", \"RF\", \"ET\"], n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_successive_halving()","title":"SuccessiveHalvingClassifier"},{"location":"API/training/successivehalvingclassifier/#successivehalvingclassifier","text":"class atom.training. SuccessiveHalvingClassifier (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a successive halving fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the complete training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the SuccessiveHalvingClassifier instance. Read more in the user guide . Parameters: models: str or sequence Models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"Ridge\" for Ridge Classification \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. skip_runs: int, optional (default=0) Skip last skip_runs runs of the successive halving. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"SuccessiveHalvingClassifier"},{"location":"API/training/successivehalvingclassifier/#attributes","text":"","title":"Attributes"},{"location":"API/training/successivehalvingclassifier/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column.","title":"Data attributes"},{"location":"API/training/successivehalvingclassifier/#utility-attributes","text":"Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the number of models in a run and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/training/successivehalvingclassifier/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/training/successivehalvingclassifier/#methods","text":"calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_class_weight Return class weights for a balanced data set. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use default name (SuccessiveHalvingClassifier). save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: SuccessiveHalvingClassifier Estimator instance.","title":"Methods"},{"location":"API/training/successivehalvingclassifier/#example","text":"from atom.training import SuccessiveHalvingClassifier # Run the pipeline trainer = SuccessiveHalvingClassifier([\"Tree\", \"Bag\", \"RF\", \"ET\"], n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_successive_halving()","title":"Example"},{"location":"API/training/successivehalvingregressor/","text":"SuccessiveHalvingRegressor class atom.training. SuccessiveHalvingRegressor (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a successive halving fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the complete training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the SuccessiveHalvingRegressor instance. Read more in the user guide . Parameters: models: str or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Regression \"Lasso\" for Lasso Regression \"EN\" for ElasticNet \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. skip_runs: int, optional (default=0) Skip last skip_runs runs of the successive halving. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. Utility attributes Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the number of models in a run and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Methods clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: SuccessiveHalvingRegressor Estimator instance. Example from atom.training import SuccessiveHalvingRegressor # Run the pipeline trainer = SuccessiveHalvingRegressor([\"Tree\", \"Bag\", \"RF\", \"ET\"], n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_successive_halving()","title":"SuccessiveHalvingClassifier"},{"location":"API/training/successivehalvingregressor/#successivehalvingregressor","text":"class atom.training. SuccessiveHalvingRegressor (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, skip_runs=0, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a successive halving fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the complete training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the SuccessiveHalvingRegressor instance. Read more in the user guide . Parameters: models: str or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Regression \"Lasso\" for Lasso Regression \"EN\" for ElasticNet \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. skip_runs: int, optional (default=0) Skip last skip_runs runs of the successive halving. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"SuccessiveHalvingRegressor"},{"location":"API/training/successivehalvingregressor/#attributes","text":"","title":"Attributes"},{"location":"API/training/successivehalvingregressor/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column.","title":"Data attributes"},{"location":"API/training/successivehalvingregressor/#utility-attributes","text":"Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the number of models in a run and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/training/successivehalvingregressor/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/training/successivehalvingregressor/#methods","text":"clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: SuccessiveHalvingRegressor Estimator instance.","title":"Methods"},{"location":"API/training/successivehalvingregressor/#example","text":"from atom.training import SuccessiveHalvingRegressor # Run the pipeline trainer = SuccessiveHalvingRegressor([\"Tree\", \"Bag\", \"RF\", \"ET\"], n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_successive_halving()","title":"Example"},{"location":"API/training/trainerclassifier/","text":"TrainerClassifier class atom.training. TrainerClassifier (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluates the models to the data in the pipeline. The following steps are applied: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainerClassifier instance. Read more in the user guide . Parameters: models: str or sequence Models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"Ridge\" for Ridge Classification \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column. Utility attributes Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the model acronyms as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Methods calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainerClassifier Estimator instance. Example from atom.training import TrainerClassifier # Run the pipeline trainer = TrainerClassifier([\"Tree\", \"RF\"], n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.scoring(\"auc\") trainer.Tree.plot_bo()","title":"TrainerClassifier"},{"location":"API/training/trainerclassifier/#trainerclassifier","text":"class atom.training. TrainerClassifier (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluates the models to the data in the pipeline. The following steps are applied: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainerClassifier instance. Read more in the user guide . Parameters: models: str or sequence Models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"Ridge\" for Ridge Classification \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"TrainerClassifier"},{"location":"API/training/trainerclassifier/#attributes","text":"","title":"Attributes"},{"location":"API/training/trainerclassifier/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column.","title":"Data attributes"},{"location":"API/training/trainerclassifier/#utility-attributes","text":"Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the model acronyms as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/training/trainerclassifier/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/training/trainerclassifier/#methods","text":"calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainerClassifier Estimator instance.","title":"Methods"},{"location":"API/training/trainerclassifier/#example","text":"from atom.training import TrainerClassifier # Run the pipeline trainer = TrainerClassifier([\"Tree\", \"RF\"], n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.scoring(\"auc\") trainer.Tree.plot_bo()","title":"Example"},{"location":"API/training/trainerregressor/","text":"TrainerRegressor class atom.training. TrainerRegressor (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluates the models to the data in the pipeline. The following steps are applied: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainerRegressor instance. Read more in the user guide . Parameters: models: str or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Regression \"Lasso\" for Lasso Regression \"EN\" for ElasticNet \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. Utility attributes Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the model acronyms as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Methods clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainerRegressor Estimator instance. Example from atom.training import TrainerRegressor # Run the pipeline trainer = TrainerRegressor([\"OLS\", \"BR\"], n_calls=5, n_initial_points=3, bagging=5) trainer.run(train, test) # Analyze the results trainer.scoring(\"mse\") trainer.plot_bagging()","title":"TrainerRegressor"},{"location":"API/training/trainerregressor/#trainerregressor","text":"class atom.training. TrainerRegressor (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluates the models to the data in the pipeline. The following steps are applied: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainerRegressor instance. Read more in the user guide . Parameters: models: str or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Regression \"Lasso\" for Lasso Regression \"EN\" for ElasticNet \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"TrainerRegressor"},{"location":"API/training/trainerregressor/#attributes","text":"","title":"Attributes"},{"location":"API/training/trainerregressor/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column.","title":"Data attributes"},{"location":"API/training/trainerregressor/#utility-attributes","text":"Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the model acronyms as index. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/training/trainerregressor/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/training/trainerregressor/#methods","text":"clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainerRegressor Estimator instance.","title":"Methods"},{"location":"API/training/trainerregressor/#example","text":"from atom.training import TrainerRegressor # Run the pipeline trainer = TrainerRegressor([\"OLS\", \"BR\"], n_calls=5, n_initial_points=3, bagging=5) trainer.run(train, test) # Analyze the results trainer.scoring(\"mse\") trainer.plot_bagging()","title":"Example"},{"location":"API/training/trainsizingclassifier/","text":"TrainSizingClassifier class atom.training. TrainSizingClassifier (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a train sizing fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainSizingClassifier instance. Read more in the user guide . Parameters: models: str or iterable Models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"Ridge\" for Ridge Classification \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. train_sizes: array-like, optional (default=np.linspace(0.2, 1.0, 5)) Sequence of training set sizes used to run the trainings. If <=1: Fraction of the training set. If >1: Total number of samples. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column. Utility attributes Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the fraction of the training set and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Methods calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_class_weight Return class weights for a balanced data set. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use default name (TrainSizingClassifier). save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainSizingClassifier Estimator instance. Example from atom.training import TrainSizingClassifier # Run the pipeline trainer = TrainSizingClassifier(\"RF\", n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_learning_curve()","title":"TrainSizingClassifier"},{"location":"API/training/trainsizingclassifier/#trainsizingclassifier","text":"class atom.training. TrainSizingClassifier (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a train sizing fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainSizingClassifier instance. Read more in the user guide . Parameters: models: str or iterable Models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"GNB\" for Gaussian Naive Bayes \"MNB\" for Multinomial Naive Bayes \"BNB\" for Bernoulli Naive Bayes \"CatNB\" for Categorical Naive Bayes \"CNB\" for Complement Naive Bayes \"Ridge\" for Ridge Classification \"LR\" for Logistic Regression \"LDA\" for Linear Discriminant Analysis \"QDA\" for Quadratic Discriminant Analysis \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. train_sizes: array-like, optional (default=np.linspace(0.2, 1.0, 5)) Sequence of training set sizes used to run the trainings. If <=1: Fraction of the training set. If >1: Total number of samples. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"TrainSizingClassifier"},{"location":"API/training/trainsizingclassifier/#attributes","text":"","title":"Attributes"},{"location":"API/training/trainsizingclassifier/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. classes: pd.DataFrame Dataframe of the number of rows per target class in the train, test and complete dataset. n_classes: int Number of unique classes in the target column.","title":"Data attributes"},{"location":"API/training/trainsizingclassifier/#utility-attributes","text":"Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the fraction of the training set and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/training/trainsizingclassifier/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/training/trainsizingclassifier/#methods","text":"calibrate Calibrate the winning model. clear Remove a model from the pipeline. get_class_weight Return class weights for a balanced data set. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method calibrate (**kwargs) [source] Applies probability calibration on the winning model. The calibration is done with the CalibratedClassifierCV class from sklearn. The model will be trained via cross-validation on a subset of the training data, using the rest to fit the calibrator. The new classifier will replace the estimator attribute. After calibrating, all prediction attributes of the winning model will reset. Parameters: **kwargs Additional keyword arguments for the CalibratedClassifierCV instance. Using cv=\"prefit\" will use the trained model and fit the calibrator on the test set. Note that doing this will result in data leakage in the test set. Use this only if you have another, independent set for testing. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_class_weight (dataset=\"train\") [source] Return class weights for a balanced data set. Statistically, the class weights re-balance the data set so that the sampled data set represents the target population as closely as reasonably possible. The returned weights are inversely proportional to class frequencies in the selected data set. Parameters: dataset: str, optional (default=\"train\") Data set from which to get the weights. Choose between \"train\", \"test\" or \"dataset\". method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use default name (TrainSizingClassifier). save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS or one of the following custom metrics: \"cm\" for the confusion matrix. \"tn\" for true negatives. \"fp\" for false positives. \"fn\" for false negatives. \"tp\" for true positives. \"lift\" for the lift metric. \"fpr\" for the false positive rate. \"tpr\" for true positive rate. \"sup\" for the support metric. If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainSizingClassifier Estimator instance.","title":"Methods"},{"location":"API/training/trainsizingclassifier/#example","text":"from atom.training import TrainSizingClassifier # Run the pipeline trainer = TrainSizingClassifier(\"RF\", n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_learning_curve()","title":"Example"},{"location":"API/training/trainsizingregressor/","text":"TrainSizingRegressor class atom.training. TrainSizingRegressor (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a train sizing fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainSizingRegressor instance. Read more in the user guide . Parameters: models: str or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Regression \"Lasso\" for Lasso Regression \"EN\" for ElasticNet \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. train_sizes: sequence, optional (default=np.linspace(0.2, 1.0, 5)) Sequence of training set sizes used to run the trainings. If <=1: Fraction of the training set. If >1: Total number of samples. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random . Attributes Data attributes The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column. Utility attributes Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the fraction of the training set and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run. Plot attributes Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes. Methods clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainSizingRegressor Estimator instance. Example from atom.training import TrainSizingRegressor # Run the pipeline trainer = TrainSizingRegressor(\"RF\", n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_learning_curve()","title":"TrainSizingRegressor"},{"location":"API/training/trainsizingregressor/#trainsizingregressor","text":"class atom.training. TrainSizingRegressor (models, metric=None, greater_is_better=True, needs_proba=False, needs_threshold=False, train_sizes=np.linspace(0.2, 1.0, 5), n_calls=10, n_initial_points=5, est_params={}, bo_params={}, bagging=None, n_jobs=1, verbose=0, logger=None, random_state=None) [source] Fit and evaluate the models in a train sizing fashion. The pipeline applies the following steps per iteration: The optimal hyperparameters are selected using a bayesian optimization algorithm. The model is fitted on the training set using the best combinations of hyperparameters found. Using a bagging algorithm, various scores on the test set are calculated. Just like atom , you can predict , plot and call any model from the TrainSizingRegressor instance. Read more in the user guide . Parameters: models: str or sequence List of models to fit on the data. Use the predefined acronyms to select the models. Possible values are (case insensitive): \"GP\" for Gaussian Process \"OLS\" for Ordinary Least Squares \"Ridge\" for Ridge Regression \"Lasso\" for Lasso Regression \"EN\" for ElasticNet \"BR\" for Bayesian Ridge \"ARD\" for Automated Relevance Determination \"KNN\" for K-Nearest Neighbors \"RNN\" for Radius Nearest Neighbors \"Tree\" for a single Decision Tree \"Bag\" for Bagging \"ET\" for Extra-Trees \"RF\" for Random Forest \"AdaB\" for AdaBoost \"GBM\" for Gradient Boosting Machine \"XGB\" for XGBoost (only available if package is installed) \"LGB\" for LightGBM (only available if package is installed) \"CatB\" for CatBoost (only available if package is installed) \"lSVM\" for Linear-SVM \"kSVM\" for Kernel-SVM \"PA\" for Passive Aggressive \"SGD\" for Stochastic Gradient Descent \"MLP\" for Multi-layer Perceptron metric: str, callable or iterable, optional (default=None) Metric(s) on which the pipeline fits the models. Choose from any of sklearn's predefined scorers , use a score (or loss) function with signature metric(y, y_pred, **kwargs) or use a scorer object. If multiple metrics are selected, only the first will be used to optimize the BO. If None, a default metric is selected: \"f1\" for binary classification \"f1_weighted\" for multiclass classification \"r2\" for regression greater_is_better: bool or iterable, optional (default=True) Whether the metric is a score function or a loss function, i.e. if True, a higher score is better and if False, lower is better. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_proba: bool or iterable, optional (default=False) Whether the metric function requires probability estimates out of a classifier. If True, make sure that every model in the pipeline has a predict_proba method. Will be ignored if the metric is a string or a scorer. If iterable, the n-th value will apply to the n-th metric in the pipeline. needs_threshold: bool or iterable, optional (default=False) Whether the metric function takes a continuous decision certainty. This only works for binary classification using estimators that have either a decision_function or predict_proba method. Will be ignored if the metric is a string or a scorer. If sequence, the n-th value will apply to the n-th metric in the pipeline. train_sizes: sequence, optional (default=np.linspace(0.2, 1.0, 5)) Sequence of training set sizes used to run the trainings. If <=1: Fraction of the training set. If >1: Total number of samples. n_calls: int or iterable, optional (default=0) Maximum number of iterations of the BO (including n_initial_points ). If 0, skip the BO and fit the model on its default parameters. If iterable, the n-th value will apply to the n-th model in the pipeline. n_initial_points: int or iterable, optional (default=5) Initial number of random tests of the BO before fitting the surrogate function. If equal to n_calls , the optimizer will technically be performing a random search. If iterable, the n-th value will apply to the n-th model in the pipeline. est_params: dict, optional (default={}}) Additional parameters for the estimators. See the corresponding documentation for the available options. For multiple models, use the acronyms as key and a dictionary of the parameters as value. bo_params: dict, optional (default={}) Additional parameters to for the BO. These can include: base_estimator: str, optional (default=\"GP\") Base estimator to use in the BO. Choose from: \"GP\" for Gaussian Process \"RF\" for Random Forest \"ET\" for Extra-Trees \"GBRT\" for Gradient Boosted Regression Trees max_time: int, optional (default=np.inf) Stop the optimization after max_time seconds. delta_x: int or float, optional (default=0) Stop the optimization when |x1 - x2| < delta_x . delta_y: int or float, optional (default=0) Stop the optimization if the 5 minima are within delta_y . cv: int, optional (default=5) Number of folds for the cross-validation. If 1, the training set will be randomly split in a subtrain and validation set. early stopping: int, float or None, optional (default=None) Training will stop if the model didn't improve in last early_stopping rounds. If <1, fraction of rounds from the total. If None, no early stopping is performed. Only available for models that allow in-training evaluation. callback: callable or list of callables, optional (default=None) Callbacks for the BO. dimensions: dict, array or None, optional (default=None) Custom hyperparameter space for the bayesian optimization. Can be an array to share dimensions across models or a dictionary with the model's name as key. If None, ATOM's predefined dimensions are used. plot_bo: bool, optional (default=False) Whether to plot the BO's progress as it runs. Creates a canvas with two plots: the first plot shows the score of every trial and the second shows the distance between the last consecutive steps. Don't forget to call %matplotlib at the start of the cell if you are using an interactive notebook! Additional keyword argument for skopt's optimizer. bagging: int, iterable or None, optional (default=None) Number of data sets (bootstrapped from the training set) to use in the bagging algorithm. If None or 0, no bagging is performed. If iterable, the n-th value will apply to the n-th model in the pipeline. n_jobs: int, optional (default=1) Number of cores to use for parallel processing. If >0: Number of cores to use. If -1: Use all available cores. If <-1: Use available_cores - 1 + n_jobs. Beware that using multiple processes on the same machine may cause memory issues for large datasets. verbose: int, optional (default=0) Verbosity level of the class. Possible values are: 0 to not print anything. 1 to print basic information. 2 to print detailed information. logger: bool, str, class or None, optional (default=None) If None: Doesn't save a logging file. If bool: True for logging file with default name. False for no logger. If str: Name of the logging file. \"auto\" to create an automatic name. If class: python Logger object. random_state: int or None, optional (default=None) Seed used by the random number generator. If None, the random number generator is the RandomState instance used by numpy.random .","title":"TrainSizingRegressor"},{"location":"API/training/trainsizingregressor/#attributes","text":"","title":"Attributes"},{"location":"API/training/trainsizingregressor/#data-attributes","text":"The dataset can be accessed at any time through multiple properties, e.g. calling trainer.train will return the training set. The data can also be changed through these properties, e.g. trainer.test = atom.test.drop(0) will drop the first row from the test set. This will also update the other data attributes. Attributes: dataset: pd.DataFrame Complete dataset in the pipeline. train: pd.DataFrame Training set. test: pd.DataFrame Test set. X: pd.DataFrame Feature set. y: pd.Series Target column. X_train: pd.DataFrame Training features. y_train: pd.Series Training target. X_test: pd.DataFrame Test features. y_test: pd.Series Test target. shape: tuple Dataset's shape in the form (rows x columns). columns: list List of columns in the dataset. target: str Name of the target column.","title":"Data attributes"},{"location":"API/training/trainsizingregressor/#utility-attributes","text":"Attributes: models: list List of models in the pipeline. metric: str or list Metric(s) used to fit the models. errors: dict Dictionary of the encountered exceptions (if any). winner: model Model subclass that performed best on the test set. results: pd.DataFrame Dataframe of the training results with the fraction of the training set and the model acronyms as indices. Columns can include: metric_bo: Best score achieved during the BO. time_bo: Time spent on the BO. metric_train: Metric score on the training set. metric_test: Metric score on the test set. time_fit: Time spent fitting and evaluating. mean_bagging: Mean score of the bagging's results. std_bagging: Standard deviation score of the bagging's results. time_bagging: Time spent on the bagging algorithm. time: Total time spent on the whole run.","title":"Utility attributes"},{"location":"API/training/trainsizingregressor/#plot-attributes","text":"Attributes: style: str Plotting style. See seaborn's documentation . palette: str Color palette. See seaborn's documentation . title_fontsize: int Fontsize for the plot's title. label_fontsize: int Fontsize for labels and legends. tick_fontsize: int Fontsize for the ticks along the plot's axes.","title":"Plot attributes"},{"location":"API/training/trainsizingregressor/#methods","text":"clear Remove a model from the pipeline. get_params Get parameters for this estimator. log Save information to the logger and print to stdout. run Fit and evaluate the models. save Save the instance to a pickle file. scoring Returns the scores of the models for a specific metric. set_params Set the parameters of this estimator. method clear (models=\"all\") [source] Removes all traces of a model in the pipeline (except for the errors attribute). If all models in the pipeline are removed, the metric is reset. Use this method to remove unwanted models from the pipeline or to clear memory before saving the instance. Parameters: models: str or iterable, optional (default=\"all\") Model(s) to clear from the pipeline. If \"all\", clear all models. method get_params (deep=True) [source] Get parameters for this estimator. Parameters: deep: bool, default=True If True, will return the parameters for this estimator and contained subobjects that are estimators. Returns: params: dict Dictionary of the parameter names mapped to their values. method log (msg, level=0) [source] Write a message to the logger and print it to stdout. Parameters: msg: str Message to write to the logger and print to stdout. level: int, optional (default=0) Minimum verbosity level in order to print the message. method run (*arrays) [source] Fit and evaluate the models. Parameters: *arrays: sequence of indexables Training set and test set. Allowed input formats are: train, test X_train, X_test, y_train, y_test (X_train, y_train), (X_test, y_test) method save (filename=None, save_data=True) [source] Save the instance to a pickle file. Remember that the class contains the complete dataset as property, so the file can become large for big datasets! To avoid this, use save_data=False . Parameters: filename: str or None, optional (default=None) Name to save the file with. If None or \"auto\", use the name of the class. save_data: bool, optional (default=True) Whether to save the data as an attribute of the instance. If False, remember to update the data immediately after loading the pickle using the dataset's @setter . method scoring (metric=None, dataset=\"test\") [source] Returns the scores of the models for a specific metric. If a model returns XXX , it means the metric failed for that specific model. This can happen if either the metric is unavailable for the task or if the model does not have a predict_proba method while the metric requires it. Parameters: metric: str or None, optional (default=None) Name of the metric to calculate. Choose from any of sklearn's SCORERS . If None, returns the models\" final results (ignores the dataset parameter). dataset: str, optional (default=\"test\") Data set on which to calculate the metric. Options are \"train\" or \"test\". method set_params (**params) [source] Set the parameters of this estimator. Parameters: **params: dict Estimator parameters. Returns: self: TrainSizingRegressor Estimator instance.","title":"Methods"},{"location":"API/training/trainsizingregressor/#example","text":"from atom.training import TrainSizingRegressor # Run the pipeline trainer = TrainSizingRegressor(\"RF\", n_calls=5, n_initial_points=3) trainer.run(train, test) # Analyze the results trainer.plot_learning_curve()","title":"Example"},{"location":"examples/binary_classification/binary_classification/","text":"Binary classification This example shows how we can use ATOM to perform a variety of data cleaning steps in order to prepare the data for modelling. Then, we compare the performances of two tree-based models. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow . Load the data # Import packages import pandas as pd from atom import ATOMClassifier # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 119416 Perth 10.8 20.0 0.0 2.2 9.2 N 31.0 106911 Albany 7.7 21.0 6.4 3.4 8.3 NaN NaN 7934 Cobar 9.9 23.6 0.0 5.4 NaN ENE 37.0 60207 Sale 10.3 26.0 0.0 3.2 8.5 E 31.0 141829 Uluru 8.8 11.3 0.6 NaN NaN E 35.0 Run the pipeline # Call ATOM using only 5% of the complete dataset (for explanatory purposes) atom = ATOMClassifier(X, 'RainTomorrow', n_rows=0.05, n_jobs=8, warnings=False, verbose=2, random_state=1) << ================== ATOM ================== >> Algorithm task: binary classification. Parallel processing with 8 cores. Dataset stats ================== >> Shape: (7110, 22) Missing values: 15896 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 5688 Test set size: 1422 ----------------------------------- Train set balance: No:Yes <==> 1.0:3.7 Test set balance: No:Yes <==> 1.0:4.1 ----------------------------------- Distribution of classes: | | dataset | train | test | |:----|----------:|--------:|-------:| | No | 1495 | 1215 | 280 | | Yes | 5615 | 4473 | 1142 | # Encode the target column atom.clean() Applying data cleaning... --> Label-encoding the target column. # Impute missing values atom.impute(strat_num='knn', strat_cat='drop', min_frac_rows=0.8) Imputing missing values... --> Dropping 774 rows for containing less than 80% non-missing values. --> Imputing 7 missing values using the KNN imputer in feature MinTemp. --> Imputing 5 missing values using the KNN imputer in feature MaxTemp. --> Imputing 33 missing values using the KNN imputer in feature Rainfall. --> Imputing 2315 missing values using the KNN imputer in feature Evaporation. --> Imputing 2648 missing values using the KNN imputer in feature Sunshine. --> Dropping 202 rows due to missing values in feature WindGustDir. --> Dropping 358 rows due to missing values in feature WindDir9am. --> Dropping 15 rows due to missing values in feature WindDir3pm. --> Imputing 17 missing values using the KNN imputer in feature Humidity9am. --> Imputing 54 missing values using the KNN imputer in feature Humidity3pm. --> Imputing 37 missing values using the KNN imputer in feature Pressure9am. --> Imputing 34 missing values using the KNN imputer in feature Pressure3pm. --> Imputing 1891 missing values using the KNN imputer in feature Cloud9am. --> Imputing 1979 missing values using the KNN imputer in feature Cloud3pm. --> Imputing 4 missing values using the KNN imputer in feature Temp9am. --> Imputing 33 missing values using the KNN imputer in feature Temp3pm. --> Dropping 31 rows due to missing values in feature RainToday. # Encode the categorical features atom.encode(strategy='CatBoost', max_onehot=10, frac_to_other=0.04) Fitting Encoder... Encoding categorical columns... --> CatBoost-encoding feature Location. Contains 1 unique classes. --> CatBoost-encoding feature WindGustDir. Contains 16 unique classes. --> CatBoost-encoding feature WindDir9am. Contains 16 unique classes. --> CatBoost-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. # Fit the EXtra-Trees and Random Forest to the data atom.run(models=['et', 'rf'], metric='f1', bagging=5, verbose=1) Training ===================================== >> Models: ET, RF Metric: f1 Results for Extra-Trees: Fit --------------------------------------------- Train evaluation --> f1: 1.0000 Test evaluation --> f1: 0.5568 Time elapsed: 0.188s Bagging ----------------------------------------- Evaluation --> f1: 0.5809 \u00b1 0.0211 Time elapsed: 0.738s ------------------------------------------------- Total time: 0.928s Results for Random Forest: Fit --------------------------------------------- Train evaluation --> f1: 1.0000 Test evaluation --> f1: 0.5940 Time elapsed: 0.228s Bagging ----------------------------------------- Evaluation --> f1: 0.5977 \u00b1 0.0134 Time elapsed: 1.031s ------------------------------------------------- Total time: 1.260s Final results ========================= >> Duration: 2.190s ------------------------------------------ Extra-Trees --> f1: 0.581 \u00b1 0.021 ~ Random Forest --> f1: 0.598 \u00b1 0.013 ~ ! Analyze the results # Let's have a look at the final scoring atom.scoring() # The winning model is indicated with a ! and can be accessed through the winner attribute # The ~ indicates that the model is probably overfitting. If we look at the train and test # score we see a difference of more than 20% print(f'\\n\\nAnd the winner is the {atom.winner.fullname} model!!') print('Score on the training set: ', atom.winner.metric_train) print('Score on the test set: ', atom.winner.metric_test) Results ===================== >> Extra-Trees --> f1: 0.581 \u00b1 0.021 ~ Random Forest --> f1: 0.598 \u00b1 0.013 ~ And the winner is the Random Forest model!! Score on the training set: 1.0 Score on the test set: 0.5940054495912807 We can make many plots to check the performance of the models # The probabilties plot shows the distribution of predicted # probabilities for the positive class atom.winner.plot_probabilities() # The threshold plot let us compare how different metrics # perform for different thresholds atom.winner.plot_threshold(metric=['f1', 'accuracy', 'average_precision'], steps=50, filename='thresholds.png') # The ROC and PRC curve are also typical ways of measuring performance atom.plot_roc(title=\"ROC for the LightGBM vs CatBoost model\") atom.plot_prc(title=\"PRC comparison of the models\")","title":"Binary classification"},{"location":"examples/binary_classification/binary_classification/#binary-classification","text":"This example shows how we can use ATOM to perform a variety of data cleaning steps in order to prepare the data for modelling. Then, we compare the performances of two tree-based models. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow .","title":"Binary classification"},{"location":"examples/binary_classification/binary_classification/#load-the-data","text":"# Import packages import pandas as pd from atom import ATOMClassifier # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 119416 Perth 10.8 20.0 0.0 2.2 9.2 N 31.0 106911 Albany 7.7 21.0 6.4 3.4 8.3 NaN NaN 7934 Cobar 9.9 23.6 0.0 5.4 NaN ENE 37.0 60207 Sale 10.3 26.0 0.0 3.2 8.5 E 31.0 141829 Uluru 8.8 11.3 0.6 NaN NaN E 35.0","title":"Load the data"},{"location":"examples/binary_classification/binary_classification/#run-the-pipeline","text":"# Call ATOM using only 5% of the complete dataset (for explanatory purposes) atom = ATOMClassifier(X, 'RainTomorrow', n_rows=0.05, n_jobs=8, warnings=False, verbose=2, random_state=1) << ================== ATOM ================== >> Algorithm task: binary classification. Parallel processing with 8 cores. Dataset stats ================== >> Shape: (7110, 22) Missing values: 15896 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 5688 Test set size: 1422 ----------------------------------- Train set balance: No:Yes <==> 1.0:3.7 Test set balance: No:Yes <==> 1.0:4.1 ----------------------------------- Distribution of classes: | | dataset | train | test | |:----|----------:|--------:|-------:| | No | 1495 | 1215 | 280 | | Yes | 5615 | 4473 | 1142 | # Encode the target column atom.clean() Applying data cleaning... --> Label-encoding the target column. # Impute missing values atom.impute(strat_num='knn', strat_cat='drop', min_frac_rows=0.8) Imputing missing values... --> Dropping 774 rows for containing less than 80% non-missing values. --> Imputing 7 missing values using the KNN imputer in feature MinTemp. --> Imputing 5 missing values using the KNN imputer in feature MaxTemp. --> Imputing 33 missing values using the KNN imputer in feature Rainfall. --> Imputing 2315 missing values using the KNN imputer in feature Evaporation. --> Imputing 2648 missing values using the KNN imputer in feature Sunshine. --> Dropping 202 rows due to missing values in feature WindGustDir. --> Dropping 358 rows due to missing values in feature WindDir9am. --> Dropping 15 rows due to missing values in feature WindDir3pm. --> Imputing 17 missing values using the KNN imputer in feature Humidity9am. --> Imputing 54 missing values using the KNN imputer in feature Humidity3pm. --> Imputing 37 missing values using the KNN imputer in feature Pressure9am. --> Imputing 34 missing values using the KNN imputer in feature Pressure3pm. --> Imputing 1891 missing values using the KNN imputer in feature Cloud9am. --> Imputing 1979 missing values using the KNN imputer in feature Cloud3pm. --> Imputing 4 missing values using the KNN imputer in feature Temp9am. --> Imputing 33 missing values using the KNN imputer in feature Temp3pm. --> Dropping 31 rows due to missing values in feature RainToday. # Encode the categorical features atom.encode(strategy='CatBoost', max_onehot=10, frac_to_other=0.04) Fitting Encoder... Encoding categorical columns... --> CatBoost-encoding feature Location. Contains 1 unique classes. --> CatBoost-encoding feature WindGustDir. Contains 16 unique classes. --> CatBoost-encoding feature WindDir9am. Contains 16 unique classes. --> CatBoost-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. # Fit the EXtra-Trees and Random Forest to the data atom.run(models=['et', 'rf'], metric='f1', bagging=5, verbose=1) Training ===================================== >> Models: ET, RF Metric: f1 Results for Extra-Trees: Fit --------------------------------------------- Train evaluation --> f1: 1.0000 Test evaluation --> f1: 0.5568 Time elapsed: 0.188s Bagging ----------------------------------------- Evaluation --> f1: 0.5809 \u00b1 0.0211 Time elapsed: 0.738s ------------------------------------------------- Total time: 0.928s Results for Random Forest: Fit --------------------------------------------- Train evaluation --> f1: 1.0000 Test evaluation --> f1: 0.5940 Time elapsed: 0.228s Bagging ----------------------------------------- Evaluation --> f1: 0.5977 \u00b1 0.0134 Time elapsed: 1.031s ------------------------------------------------- Total time: 1.260s Final results ========================= >> Duration: 2.190s ------------------------------------------ Extra-Trees --> f1: 0.581 \u00b1 0.021 ~ Random Forest --> f1: 0.598 \u00b1 0.013 ~ !","title":"Run the pipeline"},{"location":"examples/binary_classification/binary_classification/#analyze-the-results","text":"# Let's have a look at the final scoring atom.scoring() # The winning model is indicated with a ! and can be accessed through the winner attribute # The ~ indicates that the model is probably overfitting. If we look at the train and test # score we see a difference of more than 20% print(f'\\n\\nAnd the winner is the {atom.winner.fullname} model!!') print('Score on the training set: ', atom.winner.metric_train) print('Score on the test set: ', atom.winner.metric_test) Results ===================== >> Extra-Trees --> f1: 0.581 \u00b1 0.021 ~ Random Forest --> f1: 0.598 \u00b1 0.013 ~ And the winner is the Random Forest model!! Score on the training set: 1.0 Score on the test set: 0.5940054495912807 We can make many plots to check the performance of the models # The probabilties plot shows the distribution of predicted # probabilities for the positive class atom.winner.plot_probabilities() # The threshold plot let us compare how different metrics # perform for different thresholds atom.winner.plot_threshold(metric=['f1', 'accuracy', 'average_precision'], steps=50, filename='thresholds.png') # The ROC and PRC curve are also typical ways of measuring performance atom.plot_roc(title=\"ROC for the LightGBM vs CatBoost model\") atom.plot_prc(title=\"PRC comparison of the models\")","title":"Analyze the results"},{"location":"examples/calibration/calibration/","text":"Calibration This example shows us how to use the calibration method to calibrate a classifier. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow . Load the data # Import packages import pandas as pd from atom import ATOMClassifier # Get the dataset's features and targets X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 83031 Brisbane 15.1 24.4 0.0 7.8 8.7 ESE 31.0 129973 Launceston 14.3 27.2 0.0 NaN NaN SSE 28.0 94080 Adelaide 14.4 29.5 0.0 7.6 11.9 SSE 31.0 105091 Woomera 15.6 30.7 0.0 15.4 12.5 SSW 54.0 83682 Brisbane 20.1 28.8 0.0 5.2 5.2 NNE 24.0 Run the pipeline # Initialize the ATOM class atom = ATOMClassifier(X, 'RainTomorrow', n_rows=1e4, verbose=1, warnings='ignore', random_state=1) atom.clean() # Handle missing values and categorical columns in the dataset atom.impute(strat_num='median', strat_cat='most_frequent') atom.encode(strategy='target', max_onehot=5, frac_to_other=0.05) # Fit a linear SVM to the data atom.run('lsvm') << ================== ATOM ================== >> Algorithm task: binary classification. Dataset stats ================== >> Shape: (10000, 22) Missing values: 22613 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 8000 Test set size: 2000 Applying data cleaning... Fitting Imputer... Imputing missing values... Fitting Encoder... Encoding categorical columns... Training ===================================== >> Models: lSVM Metric: f1 Results for Linear-SVM: Fit --------------------------------------------- Train evaluation --> f1: 0.5634 Test evaluation --> f1: 0.5898 Time elapsed: 0.495s ------------------------------------------------- Total time: 0.500s Final results ========================= >> Duration: 0.502s ------------------------------------------ Linear-SVM --> f1: 0.590 Analyze the results # Check our model's calibration atom.plot_calibration() # Let's try to improve it using the calibrate method atom.calibrate(method='isotonic', cv=5) atom.plot_calibration()","title":"Calibration"},{"location":"examples/calibration/calibration/#calibration","text":"This example shows us how to use the calibration method to calibrate a classifier. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow .","title":"Calibration"},{"location":"examples/calibration/calibration/#load-the-data","text":"# Import packages import pandas as pd from atom import ATOMClassifier # Get the dataset's features and targets X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 83031 Brisbane 15.1 24.4 0.0 7.8 8.7 ESE 31.0 129973 Launceston 14.3 27.2 0.0 NaN NaN SSE 28.0 94080 Adelaide 14.4 29.5 0.0 7.6 11.9 SSE 31.0 105091 Woomera 15.6 30.7 0.0 15.4 12.5 SSW 54.0 83682 Brisbane 20.1 28.8 0.0 5.2 5.2 NNE 24.0","title":"Load the data"},{"location":"examples/calibration/calibration/#run-the-pipeline","text":"# Initialize the ATOM class atom = ATOMClassifier(X, 'RainTomorrow', n_rows=1e4, verbose=1, warnings='ignore', random_state=1) atom.clean() # Handle missing values and categorical columns in the dataset atom.impute(strat_num='median', strat_cat='most_frequent') atom.encode(strategy='target', max_onehot=5, frac_to_other=0.05) # Fit a linear SVM to the data atom.run('lsvm') << ================== ATOM ================== >> Algorithm task: binary classification. Dataset stats ================== >> Shape: (10000, 22) Missing values: 22613 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 8000 Test set size: 2000 Applying data cleaning... Fitting Imputer... Imputing missing values... Fitting Encoder... Encoding categorical columns... Training ===================================== >> Models: lSVM Metric: f1 Results for Linear-SVM: Fit --------------------------------------------- Train evaluation --> f1: 0.5634 Test evaluation --> f1: 0.5898 Time elapsed: 0.495s ------------------------------------------------- Total time: 0.500s Final results ========================= >> Duration: 0.502s ------------------------------------------ Linear-SVM --> f1: 0.590","title":"Run the pipeline"},{"location":"examples/calibration/calibration/#analyze-the-results","text":"# Check our model's calibration atom.plot_calibration() # Let's try to improve it using the calibrate method atom.calibrate(method='isotonic', cv=5) atom.plot_calibration()","title":"Analyze the results"},{"location":"examples/deep_learning/deep_learning/","text":"Deep learning This example shows how we can use ATOM to train and validate a Convolutional Neural Network implemented using Keras . Import the MNIST dataset from keras.datasets . This is a well known image dataset with handwritten digits. Load the data # Disable annoying tf warnings import logging import tensorflow as tf tf.get_logger().setLevel(logging.ERROR) # Import standard packages from atom import ATOMClassifier, ATOMModel from skopt.space.space import Integer, Categorical # Keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Flatten, Conv2D from keras.wrappers.scikit_learn import KerasClassifier # Create the convolutional neural network def neural_network(): model = Sequential() model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1))) model.add(Conv2D(64, kernel_size=3, activation=\"relu\")) model.add(Flatten()) model.add(Dense(10, activation=\"softmax\")) model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) return model # Since ATOM uses sklearn's API, use Keras' wrapper model = KerasClassifier(neural_network, epochs=1, batch_size=512, verbose=0) # Convert the model to an ATOM model model = ATOMModel(model, acronym='NN', fullname='Neural network') # Download the MNIST dataset (X_train, y_train), (X_test, y_test) = mnist.load_data() # Reshape data to fit model X_train = X_train.reshape(60000,28,28,1) X_test = X_test.reshape(10000,28,28,1) Run the pipeline atom = ATOMClassifier((X_train, y_train), (X_test, y_test), n_rows=0.1, n_jobs=4, warnings=False, verbose=2) << ================== ATOM ================== >> Algorithm task: multiclass classification. Parallel processing with 4 cores. Dataset stats ================== >> Shape: (7000, 2) Categorical columns: 1 Scaled: False ----------------------------------- Train set size: 6000 Test set size: 1000 ----------------------------------- Train set balance: 0:1:2:3:4:5:6:7:8:9 <==> 1.1:1.2:1.1:1.1:1.0:1.0:1.2:1.1:1.1:1.1 Test set balance: 0:1:2:3:4:5:6:7:8:9 <==> 1.2:1.4:1.2:1.2:1.2:1.0:1.3:1.1:1.3:1.0 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 696 | 594 | 102 | | 1 | 787 | 666 | 121 | | 2 | 680 | 581 | 99 | | 3 | 713 | 610 | 103 | | 4 | 669 | 569 | 100 | | 5 | 629 | 543 | 86 | | 6 | 737 | 630 | 107 | | 7 | 704 | 614 | 90 | | 8 | 730 | 622 | 108 | | 9 | 655 | 571 | 84 | # When the input data has more than 2 dimensions, ATOM creates a # dataset with just one column of shape (n_samples, shape_sample) print(atom.dataset.head()) print(f\"\\nEvery row in the column contains the data of one image, with shape: {atom.dataset.iloc[0, 0].shape}\") Features target 0 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 6 1 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 0 2 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 8 3 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 9 4 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 3 Every row in the column contains the data of one image, with shape: (28, 28, 1) # Like any other model, we can define custom dimensions for the bayesian optimization dim = [Integer(1, 3, name=\"epochs\"), Categorical([32, 64, 128, 256], name=\"batch_size\")] atom.run(model, metric=\"f1_weighted\", n_calls=5, bo_params={\"dimensions\": dim, \"cv\": 1, \"max_time\": 120}) Training ===================================== >> Models: NN Metric: f1_weighted Running BO for Neural network... Initial point 1 --------------------------------- Parameters --> {'epochs': 3, 'batch_size': 128} Evaluation --> f1_weighted: 0.9539 Best f1_weighted: 0.9539 Time iteration: 13.195s Total time: 13.199s Initial point 2 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 32} Evaluation --> f1_weighted: 0.9535 Best f1_weighted: 0.9539 Time iteration: 11.150s Total time: 24.353s Initial point 3 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 128} Evaluation --> f1_weighted: 0.9590 Best f1_weighted: 0.9590 Time iteration: 8.982s Total time: 33.339s Initial point 4 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 64} Evaluation --> f1_weighted: 0.9473 Best f1_weighted: 0.9590 Time iteration: 10.401s Total time: 43.744s Initial point 5 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 64} Evaluation --> f1_weighted: 0.9432 Best f1_weighted: 0.9590 Time iteration: 9.920s Total time: 53.668s Results for Neural network: Bayesian Optimization --------------------------- Best parameters --> {'epochs': 2, 'batch_size': 128} Best evaluation --> f1_weighted: 0.9590 Time elapsed: 54.993s Fit --------------------------------------------- Train evaluation --> f1_weighted: 0.9940 Test evaluation --> f1_weighted: 0.9600 Time elapsed: 12.060s ------------------------------------------------- Total time: 1m:07s Final results ========================= >> Duration: 1m:07s ------------------------------------------ Neural network --> f1_weighted: 0.960 Analyze the results # We can use the prediction methods like any other model atom.nn.predict_proba(X_train) array([[9.90808928e-08, 4.25013741e-06, 5.95212612e-07, ..., 2.84667622e-05, 5.82498506e-05, 1.52232733e-05], [9.99999523e-01, 2.81265500e-09, 2.03615670e-07, ..., 2.53215382e-09, 1.18079399e-07, 5.39132330e-08], [4.16290891e-11, 1.55575783e-08, 8.88847353e-07, ..., 5.54162568e-07, 2.57078545e-06, 1.62668046e-04], ..., [3.20704130e-10, 1.14542015e-10, 2.37003861e-10, ..., 9.98417460e-10, 1.32247393e-07, 2.14337160e-05], [3.62430466e-03, 5.39849998e-10, 3.39473763e-06, ..., 3.78650185e-07, 5.38889992e-07, 1.00487103e-08], [1.49063184e-03, 6.88490618e-05, 2.90933414e-03, ..., 1.33688780e-04, 8.61726165e-01, 1.15221173e-01]], dtype=float32) # Or make plots... atom.nn.plot_confusion_matrix()","title":"Deep learning"},{"location":"examples/deep_learning/deep_learning/#deep-learning","text":"This example shows how we can use ATOM to train and validate a Convolutional Neural Network implemented using Keras . Import the MNIST dataset from keras.datasets . This is a well known image dataset with handwritten digits.","title":"Deep learning"},{"location":"examples/deep_learning/deep_learning/#load-the-data","text":"# Disable annoying tf warnings import logging import tensorflow as tf tf.get_logger().setLevel(logging.ERROR) # Import standard packages from atom import ATOMClassifier, ATOMModel from skopt.space.space import Integer, Categorical # Keras from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Flatten, Conv2D from keras.wrappers.scikit_learn import KerasClassifier # Create the convolutional neural network def neural_network(): model = Sequential() model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(28, 28, 1))) model.add(Conv2D(64, kernel_size=3, activation=\"relu\")) model.add(Flatten()) model.add(Dense(10, activation=\"softmax\")) model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) return model # Since ATOM uses sklearn's API, use Keras' wrapper model = KerasClassifier(neural_network, epochs=1, batch_size=512, verbose=0) # Convert the model to an ATOM model model = ATOMModel(model, acronym='NN', fullname='Neural network') # Download the MNIST dataset (X_train, y_train), (X_test, y_test) = mnist.load_data() # Reshape data to fit model X_train = X_train.reshape(60000,28,28,1) X_test = X_test.reshape(10000,28,28,1)","title":"Load the data"},{"location":"examples/deep_learning/deep_learning/#run-the-pipeline","text":"atom = ATOMClassifier((X_train, y_train), (X_test, y_test), n_rows=0.1, n_jobs=4, warnings=False, verbose=2) << ================== ATOM ================== >> Algorithm task: multiclass classification. Parallel processing with 4 cores. Dataset stats ================== >> Shape: (7000, 2) Categorical columns: 1 Scaled: False ----------------------------------- Train set size: 6000 Test set size: 1000 ----------------------------------- Train set balance: 0:1:2:3:4:5:6:7:8:9 <==> 1.1:1.2:1.1:1.1:1.0:1.0:1.2:1.1:1.1:1.1 Test set balance: 0:1:2:3:4:5:6:7:8:9 <==> 1.2:1.4:1.2:1.2:1.2:1.0:1.3:1.1:1.3:1.0 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 696 | 594 | 102 | | 1 | 787 | 666 | 121 | | 2 | 680 | 581 | 99 | | 3 | 713 | 610 | 103 | | 4 | 669 | 569 | 100 | | 5 | 629 | 543 | 86 | | 6 | 737 | 630 | 107 | | 7 | 704 | 614 | 90 | | 8 | 730 | 622 | 108 | | 9 | 655 | 571 | 84 | # When the input data has more than 2 dimensions, ATOM creates a # dataset with just one column of shape (n_samples, shape_sample) print(atom.dataset.head()) print(f\"\\nEvery row in the column contains the data of one image, with shape: {atom.dataset.iloc[0, 0].shape}\") Features target 0 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 6 1 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 0 2 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 8 3 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 9 4 [[[0], [0], [0], [0], [0], [0], [0], [0], [0],... 3 Every row in the column contains the data of one image, with shape: (28, 28, 1) # Like any other model, we can define custom dimensions for the bayesian optimization dim = [Integer(1, 3, name=\"epochs\"), Categorical([32, 64, 128, 256], name=\"batch_size\")] atom.run(model, metric=\"f1_weighted\", n_calls=5, bo_params={\"dimensions\": dim, \"cv\": 1, \"max_time\": 120}) Training ===================================== >> Models: NN Metric: f1_weighted Running BO for Neural network... Initial point 1 --------------------------------- Parameters --> {'epochs': 3, 'batch_size': 128} Evaluation --> f1_weighted: 0.9539 Best f1_weighted: 0.9539 Time iteration: 13.195s Total time: 13.199s Initial point 2 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 32} Evaluation --> f1_weighted: 0.9535 Best f1_weighted: 0.9539 Time iteration: 11.150s Total time: 24.353s Initial point 3 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 128} Evaluation --> f1_weighted: 0.9590 Best f1_weighted: 0.9590 Time iteration: 8.982s Total time: 33.339s Initial point 4 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 64} Evaluation --> f1_weighted: 0.9473 Best f1_weighted: 0.9590 Time iteration: 10.401s Total time: 43.744s Initial point 5 --------------------------------- Parameters --> {'epochs': 2, 'batch_size': 64} Evaluation --> f1_weighted: 0.9432 Best f1_weighted: 0.9590 Time iteration: 9.920s Total time: 53.668s Results for Neural network: Bayesian Optimization --------------------------- Best parameters --> {'epochs': 2, 'batch_size': 128} Best evaluation --> f1_weighted: 0.9590 Time elapsed: 54.993s Fit --------------------------------------------- Train evaluation --> f1_weighted: 0.9940 Test evaluation --> f1_weighted: 0.9600 Time elapsed: 12.060s ------------------------------------------------- Total time: 1m:07s Final results ========================= >> Duration: 1m:07s ------------------------------------------ Neural network --> f1_weighted: 0.960","title":"Run the pipeline"},{"location":"examples/deep_learning/deep_learning/#analyze-the-results","text":"# We can use the prediction methods like any other model atom.nn.predict_proba(X_train) array([[9.90808928e-08, 4.25013741e-06, 5.95212612e-07, ..., 2.84667622e-05, 5.82498506e-05, 1.52232733e-05], [9.99999523e-01, 2.81265500e-09, 2.03615670e-07, ..., 2.53215382e-09, 1.18079399e-07, 5.39132330e-08], [4.16290891e-11, 1.55575783e-08, 8.88847353e-07, ..., 5.54162568e-07, 2.57078545e-06, 1.62668046e-04], ..., [3.20704130e-10, 1.14542015e-10, 2.37003861e-10, ..., 9.98417460e-10, 1.32247393e-07, 2.14337160e-05], [3.62430466e-03, 5.39849998e-10, 3.39473763e-06, ..., 3.78650185e-07, 5.38889992e-07, 1.00487103e-08], [1.49063184e-03, 6.88490618e-05, 2.90933414e-03, ..., 1.33688780e-04, 8.61726165e-01, 1.15221173e-01]], dtype=float32) # Or make plots... atom.nn.plot_confusion_matrix()","title":"Analyze the results"},{"location":"examples/early_stopping/early_stopping/","text":"Early stopping This example shows how we can use early stopping to reduce the time it takes to run the pipeline. This option is only available for models that allow in-training evaluation (XGBoost, LightGBM and CatBoost). Import the breast cancer dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict whether a patient has breast cancer or not. Load the data # Import packages from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier # Get the dataset's features and targets X, y = load_breast_cancer(return_X_y=True) Run the pipeline # Start ATOM and fit the models using early stopping # An early stopping of 0.1 means that the model will stop if it # didn't improve in the last 10% of it's iterations. atom = ATOMClassifier(X, y, n_jobs=2, verbose=2, warnings=False, random_state=1) atom.run('LGB', metric='ap', n_calls=7, n_initial_points=3, bo_params={'early_stopping': 0.1, 'cv': 1}) << ================== ATOM ================== >> Algorithm task: binary classification. Parallel processing with 2 cores. Dataset stats ================== >> Shape: (569, 31) Scaled: False ----------------------------------- Train set size: 456 Test set size: 113 ----------------------------------- Train set balance: 0:1 <==> 1.0:1.7 Test set balance: 0:1 <==> 1.0:1.5 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 212 | 167 | 45 | | 1 | 357 | 289 | 68 | Training ===================================== >> Models: LGB Metric: average_precision Running BO for LightGBM... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 499, 'learning_rate': 0.73, 'max_depth': 1, 'num_leaves': 40, 'min_child_weight': 5, 'min_child_samples': 18, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 100.0, 'reg_lambda': 10.0} Early stop at iteration 50 of 499. Evaluation --> average_precision: 0.6304 Best average_precision: 0.6304 Time iteration: 0.024s Total time: 0.045s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 170, 'learning_rate': 0.11, 'max_depth': 4, 'num_leaves': 25, 'min_child_weight': 11, 'min_child_samples': 28, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 100.0, 'reg_lambda': 10.0} Early stop at iteration 18 of 170. Evaluation --> average_precision: 0.6304 Best average_precision: 0.6304 Time iteration: 0.020s Total time: 0.069s Initial point 3 --------------------------------- Parameters --> {'n_estimators': 364, 'learning_rate': 0.4, 'max_depth': 1, 'num_leaves': 30, 'min_child_weight': 17, 'min_child_samples': 27, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.0, 'reg_lambda': 1.0} Early stop at iteration 42 of 364. Evaluation --> average_precision: 0.9774 Best average_precision: 0.9774 Time iteration: 0.020s Total time: 0.094s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 238, 'learning_rate': 0.49, 'max_depth': 2, 'num_leaves': 29, 'min_child_weight': 18, 'min_child_samples': 25, 'subsample': 0.9, 'colsample_bytree': 0.4, 'reg_alpha': 0.0, 'reg_lambda': 10.0} Early stop at iteration 30 of 238. Evaluation --> average_precision: 0.9911 Best average_precision: 0.9911 Time iteration: 0.021s Total time: 1.420s Iteration 5 ------------------------------------- Parameters --> {'n_estimators': 31, 'learning_rate': 0.07, 'max_depth': 5, 'num_leaves': 21, 'min_child_weight': 18, 'min_child_samples': 28, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0, 'reg_lambda': 100.0} Evaluation --> average_precision: 0.9920 Best average_precision: 0.9920 Time iteration: 0.021s Total time: 1.785s Iteration 6 ------------------------------------- Parameters --> {'n_estimators': 42, 'learning_rate': 0.55, 'max_depth': 3, 'num_leaves': 39, 'min_child_weight': 11, 'min_child_samples': 12, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_alpha': 0.01, 'reg_lambda': 100.0} Evaluation --> average_precision: 0.9991 Best average_precision: 0.9991 Time iteration: 0.023s Total time: 2.158s Iteration 7 ------------------------------------- Parameters --> {'n_estimators': 109, 'learning_rate': 1.0, 'max_depth': -1, 'num_leaves': 40, 'min_child_weight': 1, 'min_child_samples': 10, 'subsample': 0.8, 'colsample_bytree': 0.3, 'reg_alpha': 100.0, 'reg_lambda': 100.0} Early stop at iteration 11 of 109. Evaluation --> average_precision: 0.6304 Best average_precision: 0.9991 Time iteration: 0.020s Total time: 2.628s Results for LightGBM: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 42, 'learning_rate': 0.55, 'max_depth': 3, 'num_leaves': 39, 'min_child_weight': 11, 'min_child_samples': 12, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_alpha': 0.01, 'reg_lambda': 100.0} Best evaluation --> average_precision: 0.9991 Time elapsed: 3.118s Fit --------------------------------------------- Train evaluation --> average_precision: 0.9975 Test evaluation --> average_precision: 0.9885 Time elapsed: 0.026s ------------------------------------------------- Total time: 3.147s Final results ========================= >> Duration: 3.149s ------------------------------------------ LightGBM --> average_precision: 0.988 Analyze the results # For these models, we can plot the evaluation on the train and test set during training # Note that the metric is provided by the estimator's package, not ATOM! atom.lgb.plot_evals(title=\"LightGBM's evaluation curve\", figsize=(11, 9))","title":"Early stopping"},{"location":"examples/early_stopping/early_stopping/#early-stopping","text":"This example shows how we can use early stopping to reduce the time it takes to run the pipeline. This option is only available for models that allow in-training evaluation (XGBoost, LightGBM and CatBoost). Import the breast cancer dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict whether a patient has breast cancer or not.","title":"Early stopping"},{"location":"examples/early_stopping/early_stopping/#load-the-data","text":"# Import packages from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier # Get the dataset's features and targets X, y = load_breast_cancer(return_X_y=True)","title":"Load the data"},{"location":"examples/early_stopping/early_stopping/#run-the-pipeline","text":"# Start ATOM and fit the models using early stopping # An early stopping of 0.1 means that the model will stop if it # didn't improve in the last 10% of it's iterations. atom = ATOMClassifier(X, y, n_jobs=2, verbose=2, warnings=False, random_state=1) atom.run('LGB', metric='ap', n_calls=7, n_initial_points=3, bo_params={'early_stopping': 0.1, 'cv': 1}) << ================== ATOM ================== >> Algorithm task: binary classification. Parallel processing with 2 cores. Dataset stats ================== >> Shape: (569, 31) Scaled: False ----------------------------------- Train set size: 456 Test set size: 113 ----------------------------------- Train set balance: 0:1 <==> 1.0:1.7 Test set balance: 0:1 <==> 1.0:1.5 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 212 | 167 | 45 | | 1 | 357 | 289 | 68 | Training ===================================== >> Models: LGB Metric: average_precision Running BO for LightGBM... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 499, 'learning_rate': 0.73, 'max_depth': 1, 'num_leaves': 40, 'min_child_weight': 5, 'min_child_samples': 18, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 100.0, 'reg_lambda': 10.0} Early stop at iteration 50 of 499. Evaluation --> average_precision: 0.6304 Best average_precision: 0.6304 Time iteration: 0.024s Total time: 0.045s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 170, 'learning_rate': 0.11, 'max_depth': 4, 'num_leaves': 25, 'min_child_weight': 11, 'min_child_samples': 28, 'subsample': 0.7, 'colsample_bytree': 0.6, 'reg_alpha': 100.0, 'reg_lambda': 10.0} Early stop at iteration 18 of 170. Evaluation --> average_precision: 0.6304 Best average_precision: 0.6304 Time iteration: 0.020s Total time: 0.069s Initial point 3 --------------------------------- Parameters --> {'n_estimators': 364, 'learning_rate': 0.4, 'max_depth': 1, 'num_leaves': 30, 'min_child_weight': 17, 'min_child_samples': 27, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0.0, 'reg_lambda': 1.0} Early stop at iteration 42 of 364. Evaluation --> average_precision: 0.9774 Best average_precision: 0.9774 Time iteration: 0.020s Total time: 0.094s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 238, 'learning_rate': 0.49, 'max_depth': 2, 'num_leaves': 29, 'min_child_weight': 18, 'min_child_samples': 25, 'subsample': 0.9, 'colsample_bytree': 0.4, 'reg_alpha': 0.0, 'reg_lambda': 10.0} Early stop at iteration 30 of 238. Evaluation --> average_precision: 0.9911 Best average_precision: 0.9911 Time iteration: 0.021s Total time: 1.420s Iteration 5 ------------------------------------- Parameters --> {'n_estimators': 31, 'learning_rate': 0.07, 'max_depth': 5, 'num_leaves': 21, 'min_child_weight': 18, 'min_child_samples': 28, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0.0, 'reg_lambda': 100.0} Evaluation --> average_precision: 0.9920 Best average_precision: 0.9920 Time iteration: 0.021s Total time: 1.785s Iteration 6 ------------------------------------- Parameters --> {'n_estimators': 42, 'learning_rate': 0.55, 'max_depth': 3, 'num_leaves': 39, 'min_child_weight': 11, 'min_child_samples': 12, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_alpha': 0.01, 'reg_lambda': 100.0} Evaluation --> average_precision: 0.9991 Best average_precision: 0.9991 Time iteration: 0.023s Total time: 2.158s Iteration 7 ------------------------------------- Parameters --> {'n_estimators': 109, 'learning_rate': 1.0, 'max_depth': -1, 'num_leaves': 40, 'min_child_weight': 1, 'min_child_samples': 10, 'subsample': 0.8, 'colsample_bytree': 0.3, 'reg_alpha': 100.0, 'reg_lambda': 100.0} Early stop at iteration 11 of 109. Evaluation --> average_precision: 0.6304 Best average_precision: 0.9991 Time iteration: 0.020s Total time: 2.628s Results for LightGBM: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 42, 'learning_rate': 0.55, 'max_depth': 3, 'num_leaves': 39, 'min_child_weight': 11, 'min_child_samples': 12, 'subsample': 0.8, 'colsample_bytree': 0.4, 'reg_alpha': 0.01, 'reg_lambda': 100.0} Best evaluation --> average_precision: 0.9991 Time elapsed: 3.118s Fit --------------------------------------------- Train evaluation --> average_precision: 0.9975 Test evaluation --> average_precision: 0.9885 Time elapsed: 0.026s ------------------------------------------------- Total time: 3.147s Final results ========================= >> Duration: 3.149s ------------------------------------------ LightGBM --> average_precision: 0.988","title":"Run the pipeline"},{"location":"examples/early_stopping/early_stopping/#analyze-the-results","text":"# For these models, we can plot the evaluation on the train and test set during training # Note that the metric is provided by the estimator's package, not ATOM! atom.lgb.plot_evals(title=\"LightGBM's evaluation curve\", figsize=(11, 9))","title":"Analyze the results"},{"location":"examples/feature_engineering/feature_engineering/","text":"Feature engineering This example shows how to use automated feature generation to improve your model's performance. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow . Load the data # Import packages import pandas as pd from atom import ATOMClassifier # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 93402 Townsville 24.0 31.1 2.2 7.4 7.7 E 37.0 93848 Townsville 15.4 26.5 0.0 NaN NaN NE 30.0 119776 Perth 9.4 20.2 0.0 2.2 8.4 SSE 24.0 75276 Portland 15.9 22.0 0.0 6.4 8.2 SE 33.0 33100 SydneyAirport 14.4 25.0 0.0 7.6 11.3 W 52.0 Run the pipeline # Initiate ATOM and apply data cleaning atom = ATOMClassifier(X, n_rows=1e4, test_size=0.2, verbose=0, random_state=1) atom.clean() atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) atom.encode(max_onehot=10, frac_to_other=0.04) # Let's see how a LightGBM model performs without adding additional features atom.run('LGB', metric='auc') atom.scoring() Results ===================== >> LightGBM --> roc_auc: 0.872 # What are the most important fetaures? atom.plot_feature_importance(show=10) Now let's create some new fetaures using Deep Feature Synthesis atom.verbose = 2 # Increase verbosity to see the output # Create 100 new features using DFS atom.feature_generation(strategy='dfs', n_features=100, operators=['add', 'sub', 'log', 'sqrt']) Fitting FeatureGenerator... Creating new features... --> 100 new features were added to the dataset. divide by zero encountered in log invalid value encountered in log # The warnings warn us that some operators created missing values! # We can see the columns with missing values using the missing attribute atom.missing # We can easily turn off warnings in the future atom.warnings = False # We can use the impute method again atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) Fitting Imputer... Imputing missing values... --> Imputing 6 missing values using the KNN imputer in feature LOG(Temp9am). # 100 new features may be to much... # Let's check for multicollinearity and use RFECV to reduce the number even further atom.feature_selection(strategy='RFECV', solver='lgb', n_features=30, scoring='auc', max_correlation=0.98) Fitting FeatureSelector... Performing feature selection ... --> Feature Location was removed due to low variance. Value 0.20781403164822854 repeated in 100% of the rows. --> Feature Cloud3pm + Humidity3pm was removed due to collinearity with another feature. --> Feature Cloud3pm + RainToday_No was removed due to collinearity with another feature. --> Feature Cloud3pm + WindDir9am was removed due to collinearity with another feature. --> Feature Cloud3pm - Location was removed due to collinearity with another feature. --> Feature Cloud3pm - RainToday_No was removed due to collinearity with another feature. --> Feature Cloud9am + WindGustDir was removed due to collinearity with another feature. --> Feature Evaporation + Location was removed due to collinearity with another feature. --> Feature Evaporation + WindGustDir was removed due to collinearity with another feature. --> Feature Evaporation - WindDir3pm was removed due to collinearity with another feature. --> Feature Humidity3pm - RainToday_No was removed due to collinearity with another feature. --> Feature Humidity3pm - Sunshine was removed due to collinearity with another feature. --> Feature Humidity9am + RainToday_Yes was removed due to collinearity with another feature. --> Feature Humidity9am - RainToday_No was removed due to collinearity with another feature. --> Feature Humidity9am - Sunshine was removed due to collinearity with another feature. --> Feature LOG(MaxTemp) was removed due to collinearity with another feature. --> Feature Location + MinTemp was removed due to collinearity with another feature. --> Feature Location + RainToday_No was removed due to collinearity with another feature. --> Feature Location + WindDir3pm was removed due to collinearity with another feature. --> Feature Location + WindGustDir was removed due to collinearity with another feature. --> Feature Location + WindSpeed3pm was removed due to collinearity with another feature. --> Feature Location - RainToday_Yes was removed due to collinearity with another feature. --> Feature MaxTemp + RainToday_No was removed due to collinearity with another feature. --> Feature MaxTemp + RainToday_Yes was removed due to collinearity with another feature. --> Feature MinTemp + WindGustDir was removed due to collinearity with another feature. --> Feature Pressure3pm + RainToday_other was removed due to collinearity with another feature. --> Feature Pressure3pm - WindGustDir was removed due to collinearity with another feature. --> Feature Pressure9am - WindGustDir was removed due to collinearity with another feature. --> Feature RainToday_No + Temp9am was removed due to collinearity with another feature. --> Feature RainToday_No + WindGustDir was removed due to collinearity with another feature. --> Feature RainToday_No - WindDir9am was removed due to collinearity with another feature. --> Feature RainToday_Yes + Temp9am was removed due to collinearity with another feature. --> Feature RainToday_Yes + WindDir3pm was removed due to collinearity with another feature. --> Feature RainToday_Yes + WindDir9am was removed due to collinearity with another feature. --> Feature RainToday_Yes - WindDir9am was removed due to collinearity with another feature. --> Feature RainToday_other - Temp9am was removed due to collinearity with another feature. --> Feature RainToday_other - WindGustSpeed was removed due to collinearity with another feature. --> Feature RainToday_other - WindSpeed9am was removed due to collinearity with another feature. --> Feature Rainfall + RainToday_No was removed due to collinearity with another feature. --> Feature Rainfall + WindDir9am was removed due to collinearity with another feature. --> Feature Rainfall - WindDir3pm was removed due to collinearity with another feature. --> Feature SQRT(Cloud9am) was removed due to collinearity with another feature. --> Feature SQRT(Humidity3pm) was removed due to collinearity with another feature. --> Feature SQRT(Pressure9am) was removed due to collinearity with another feature. --> Feature Sunshine + WindDir9am was removed due to collinearity with another feature. --> Feature Temp3pm + WindDir9am was removed due to collinearity with another feature. --> Feature Temp3pm + WindGustDir was removed due to collinearity with another feature. --> Feature Temp3pm - WindDir3pm was removed due to collinearity with another feature. --> Feature Temp9am - WindDir9am was removed due to collinearity with another feature. --> Feature WindDir3pm - WindSpeed3pm was removed due to collinearity with another feature. --> Feature WindGustDir + WindGustSpeed was removed due to collinearity with another feature. --> Feature WindGustDir - WindSpeed9am was removed due to collinearity with another feature. --> The RFECV selected 42 features from the dataset. >>> Dropping feature Rainfall (rank 3). >>> Dropping feature Evaporation (rank 14). >>> Dropping feature WindGustSpeed (rank 12). >>> Dropping feature WindSpeed9am (rank 20). >>> Dropping feature WindSpeed3pm (rank 19). >>> Dropping feature Pressure9am (rank 10). >>> Dropping feature Cloud9am (rank 17). >>> Dropping feature Temp9am (rank 15). >>> Dropping feature RainToday_Yes (rank 27). >>> Dropping feature RainToday_No (rank 29). >>> Dropping feature RainToday_other (rank 16). >>> Dropping feature Cloud9am + WindSpeed9am (rank 6). >>> Dropping feature Evaporation + Rainfall (rank 7). >>> Dropping feature LOG(Cloud9am) (rank 30). >>> Dropping feature LOG(RainToday_other) (rank 28). >>> Dropping feature LOG(Sunshine) (rank 26). >>> Dropping feature LOG(Temp9am) (rank 18). >>> Dropping feature LOG(WindSpeed3pm) (rank 25). >>> Dropping feature Location - WindSpeed3pm (rank 22). >>> Dropping feature Location - WindSpeed9am (rank 21). >>> Dropping feature MaxTemp + Temp9am (rank 11). >>> Dropping feature MinTemp + Temp3pm (rank 2). >>> Dropping feature Pressure3pm - Temp9am (rank 9). >>> Dropping feature RainToday_No - Temp9am (rank 5). >>> Dropping feature RainToday_other - Sunshine (rank 13). >>> Dropping feature Rainfall + WindSpeed3pm (rank 8). >>> Dropping feature SQRT(Rainfall) (rank 23). >>> Dropping feature SQRT(WindSpeed9am) (rank 24). >>> Dropping feature WindGustSpeed + WindSpeed9am (rank 4). # The collinear attribute shows what features were removed due to multicollinearity atom.collinear .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } drop_feature correlated_feature correlation_value 0 Cloud3pm + Humidity3pm Humidity3pm 0.99578 1 Cloud3pm + RainToday_No Cloud3pm 0.98124 2 Cloud3pm + WindDir9am Cloud3pm, Cloud3pm + RainToday_No 0.99968, 0.98054 3 Cloud3pm - Location Cloud3pm, Cloud3pm + RainToday_No, Cloud3pm + ... 1.0, 0.98124, 0.99968 4 Cloud3pm - RainToday_No Cloud3pm, Cloud3pm + WindDir9am, Cloud3pm - Lo... 0.98405, 0.98409, 0.98405 5 Cloud9am + WindGustDir Cloud9am 0.99979 6 Evaporation + Location Evaporation 1.0 7 Evaporation + WindGustDir Evaporation, Evaporation + Location 0.9999, 0.9999 8 Evaporation - WindDir3pm Evaporation, Evaporation + Location, Evaporati... 0.9999, 0.9999, 0.99969 9 Humidity3pm - RainToday_No Humidity3pm, Cloud3pm + Humidity3pm 0.99983, 0.99572 10 Humidity3pm - Sunshine Humidity3pm, Cloud3pm + Humidity3pm, Humidity3... 0.99347, 0.99404, 0.99349 11 Humidity9am + RainToday_Yes Humidity9am 0.9998 12 Humidity9am - RainToday_No Humidity9am, Humidity9am + RainToday_Yes 0.9998, 0.99999 13 Humidity9am - Sunshine Humidity9am, Humidity9am + RainToday_Yes, Humi... 0.99164, 0.99183, 0.99183 14 LOG(MaxTemp) MaxTemp 0.98395 15 Location + MinTemp MinTemp 1.0 16 Location + RainToday_No RainToday_Yes, RainToday_No -0.98404, 1.0 17 Location + WindDir3pm WindDir3pm 1.0 18 Location + WindGustDir WindGustDir 1.0 19 Location + WindSpeed3pm WindSpeed3pm 1.0 20 Location - RainToday_Yes RainToday_Yes, RainToday_No, Location + RainTo... -1.0, 0.98404, 0.98404 21 MaxTemp + RainToday_No MaxTemp, LOG(MaxTemp) 0.99841, 0.9831 22 MaxTemp + RainToday_Yes MaxTemp, LOG(MaxTemp), MaxTemp + RainToday_No 0.99834, 0.98156, 0.99356 23 MinTemp + WindGustDir MinTemp, Location + MinTemp 0.99997, 0.99997 24 Pressure3pm + RainToday_other Pressure3pm 0.99995 25 Pressure3pm - WindGustDir Pressure3pm, Pressure3pm + RainToday_other 0.99998, 0.99992 26 Pressure9am - WindGustDir Pressure9am 0.99998 27 RainToday_No + Temp9am Temp9am 0.99797 28 RainToday_No + WindGustDir RainToday_No, Location + RainToday_No 0.99327, 0.99327 29 RainToday_No - WindDir9am RainToday_No, Location + RainToday_No 0.99167, 0.99167 30 RainToday_Yes + Temp9am Temp9am, RainToday_No + Temp9am, RainToday_No ... 0.99795, 0.99191, -0.99993 31 RainToday_Yes + WindDir3pm RainToday_Yes, Location - RainToday_Yes 0.99331, -0.99331 32 RainToday_Yes + WindDir9am RainToday_Yes, Location - RainToday_Yes, RainT... 0.99152, -0.99152, -0.98471, 0.98989 33 RainToday_Yes - WindDir9am RainToday_Yes, Location - RainToday_Yes 0.99107, -0.99107 34 RainToday_other - Temp9am Temp9am, RainToday_No + Temp9am, RainToday_No ... -0.99993, -0.998, 0.99775, -0.99792 35 RainToday_other - WindGustSpeed WindGustSpeed, Cloud9am - WindGustSpeed -0.99998, 0.98438 36 RainToday_other - WindSpeed9am WindSpeed9am, Location - WindSpeed9am -0.99997, 0.99997 37 Rainfall + RainToday_No Rainfall 0.99907 38 Rainfall + WindDir9am Rainfall, Rainfall + RainToday_No 0.99998, 0.99902 39 Rainfall - WindDir3pm Rainfall, Rainfall + RainToday_No, Rainfall + ... 0.99998, 0.99907, 0.99995 40 SQRT(Cloud9am) LOG(Cloud9am) 0.987 41 SQRT(Humidity3pm) Humidity3pm, Cloud3pm + Humidity3pm, Humidity3... 0.98722, 0.98193, 0.98675 42 SQRT(Pressure9am) Pressure9am, Pressure9am - WindGustDir 1.0, 0.99998 43 Sunshine + WindDir9am Sunshine, RainToday_other - Sunshine 0.99982, -0.99948 44 Temp3pm + WindDir9am Temp3pm 0.99997 45 Temp3pm + WindGustDir Temp3pm, Temp3pm + WindDir9am 0.99998, 0.99997 46 Temp3pm - WindDir3pm Temp3pm, Temp3pm + WindDir9am, Temp3pm + WindG... 0.99998, 0.99993, 0.99993 47 Temp9am - WindDir9am Temp9am, RainToday_No + Temp9am, RainToday_No ... 0.99996, 0.99798, -0.99783, 0.99787, -0.9999 48 WindDir3pm - WindSpeed3pm WindSpeed3pm, Location + WindSpeed3pm, Locatio... -0.99998, -0.99998, 0.99998 49 WindGustDir + WindGustSpeed WindGustSpeed, Cloud9am - WindGustSpeed, RainT... 0.99999, -0.9843, -0.99998 50 WindGustDir - WindSpeed9am WindSpeed9am, Location - WindSpeed9am, RainTod... -0.99999, 0.99999, 0.99995 # After applying RFECV, we can plot the score per number of features atom.plot_rfecv() # Let's see how the model performs now atom.run('LGB') Training ===================================== >> Models: LGB Metric: roc_auc Results for LightGBM: Fit --------------------------------------------- Train evaluation --> roc_auc: 0.9960 Test evaluation --> roc_auc: 0.8787 Time elapsed: 0.593s ------------------------------------------------- Total time: 0.600s Final results ========================= >> Duration: 0.602s ------------------------------------------ LightGBM --> roc_auc: 0.879 # Did the feature importance change? atom.plot_feature_importance(show=10) Lets try the same using Genetic Feature Generation atom = ATOMClassifier(X, n_rows=1e4, test_size=0.2, verbose=0, warnings=False, random_state=1) atom.clean() atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) atom.encode(max_onehot=10, frac_to_other=0.04) # Change verbosity to print extended info atom.verbose = 2 # Create new features using Genetic Programming atom.feature_generation(strategy='genetic', n_features=20, generations=10, population=2000) Fitting FeatureGenerator... | Population Average | Best Individual | ---- ------------------------- ------------------------------------------ ---------- Gen Length Fitness Length Fitness OOB Fitness Time Left 0 3.17 0.127544 3 0.504266 N/A 9.62s 1 3.10 0.33852 5 0.536639 N/A 9.04s 2 3.50 0.443648 9 0.541754 N/A 7.65s 3 4.48 0.476799 7 0.544984 N/A 6.96s 4 6.25 0.51219 13 0.546135 N/A 5.70s 5 7.45 0.508814 9 0.550855 N/A 4.75s 6 7.66 0.501224 11 0.55326 N/A 3.56s 7 8.05 0.498132 11 0.553417 N/A 2.32s 8 9.52 0.497282 13 0.554988 N/A 1.23s 9 10.82 0.492465 11 0.553417 N/A 0.00s Creating new features... --> 5 new features were added to the dataset. # We can see the feature's fitness and description through the genetic_features attribute atom.genetic_features .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name description fitness 0 Feature 24 mul(mul(sub(sub(sub(Humidity3pm, Sunshine), Su... 0.542417 1 Feature 25 mul(sub(sub(sub(Humidity3pm, Sunshine), Sunshi... 0.542417 2 Feature 26 mul(Humidity3pm, mul(sub(sub(sub(Humidity3pm, ... 0.542417 3 Feature 27 mul(sub(sub(Humidity3pm, Sunshine), Sunshine),... 0.542260 4 Feature 28 mul(mul(sub(Humidity3pm, Sunshine), WindGustSp... 0.542260 # And fit the model again atom.run('LGB', metric='auc') Training ===================================== >> Models: LGB Metric: roc_auc Results for LightGBM: Fit --------------------------------------------- Train evaluation --> roc_auc: 0.9894 Test evaluation --> roc_auc: 0.8771 Time elapsed: 0.296s ------------------------------------------------- Total time: 0.301s Final results ========================= >> Duration: 0.303s ------------------------------------------ LightGBM --> roc_auc: 0.877 atom.plot_feature_importance(show=10) # We can check the feature importance with other plots as well atom.plot_permutation_importance(show=10) atom.dependence_plot()","title":"Feature engineering"},{"location":"examples/feature_engineering/feature_engineering/#feature-engineering","text":"This example shows how to use automated feature generation to improve your model's performance. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow .","title":"Feature engineering"},{"location":"examples/feature_engineering/feature_engineering/#load-the-data","text":"# Import packages import pandas as pd from atom import ATOMClassifier # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 93402 Townsville 24.0 31.1 2.2 7.4 7.7 E 37.0 93848 Townsville 15.4 26.5 0.0 NaN NaN NE 30.0 119776 Perth 9.4 20.2 0.0 2.2 8.4 SSE 24.0 75276 Portland 15.9 22.0 0.0 6.4 8.2 SE 33.0 33100 SydneyAirport 14.4 25.0 0.0 7.6 11.3 W 52.0","title":"Load the data"},{"location":"examples/feature_engineering/feature_engineering/#run-the-pipeline","text":"# Initiate ATOM and apply data cleaning atom = ATOMClassifier(X, n_rows=1e4, test_size=0.2, verbose=0, random_state=1) atom.clean() atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) atom.encode(max_onehot=10, frac_to_other=0.04) # Let's see how a LightGBM model performs without adding additional features atom.run('LGB', metric='auc') atom.scoring() Results ===================== >> LightGBM --> roc_auc: 0.872 # What are the most important fetaures? atom.plot_feature_importance(show=10) Now let's create some new fetaures using Deep Feature Synthesis atom.verbose = 2 # Increase verbosity to see the output # Create 100 new features using DFS atom.feature_generation(strategy='dfs', n_features=100, operators=['add', 'sub', 'log', 'sqrt']) Fitting FeatureGenerator... Creating new features... --> 100 new features were added to the dataset. divide by zero encountered in log invalid value encountered in log # The warnings warn us that some operators created missing values! # We can see the columns with missing values using the missing attribute atom.missing # We can easily turn off warnings in the future atom.warnings = False # We can use the impute method again atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) Fitting Imputer... Imputing missing values... --> Imputing 6 missing values using the KNN imputer in feature LOG(Temp9am). # 100 new features may be to much... # Let's check for multicollinearity and use RFECV to reduce the number even further atom.feature_selection(strategy='RFECV', solver='lgb', n_features=30, scoring='auc', max_correlation=0.98) Fitting FeatureSelector... Performing feature selection ... --> Feature Location was removed due to low variance. Value 0.20781403164822854 repeated in 100% of the rows. --> Feature Cloud3pm + Humidity3pm was removed due to collinearity with another feature. --> Feature Cloud3pm + RainToday_No was removed due to collinearity with another feature. --> Feature Cloud3pm + WindDir9am was removed due to collinearity with another feature. --> Feature Cloud3pm - Location was removed due to collinearity with another feature. --> Feature Cloud3pm - RainToday_No was removed due to collinearity with another feature. --> Feature Cloud9am + WindGustDir was removed due to collinearity with another feature. --> Feature Evaporation + Location was removed due to collinearity with another feature. --> Feature Evaporation + WindGustDir was removed due to collinearity with another feature. --> Feature Evaporation - WindDir3pm was removed due to collinearity with another feature. --> Feature Humidity3pm - RainToday_No was removed due to collinearity with another feature. --> Feature Humidity3pm - Sunshine was removed due to collinearity with another feature. --> Feature Humidity9am + RainToday_Yes was removed due to collinearity with another feature. --> Feature Humidity9am - RainToday_No was removed due to collinearity with another feature. --> Feature Humidity9am - Sunshine was removed due to collinearity with another feature. --> Feature LOG(MaxTemp) was removed due to collinearity with another feature. --> Feature Location + MinTemp was removed due to collinearity with another feature. --> Feature Location + RainToday_No was removed due to collinearity with another feature. --> Feature Location + WindDir3pm was removed due to collinearity with another feature. --> Feature Location + WindGustDir was removed due to collinearity with another feature. --> Feature Location + WindSpeed3pm was removed due to collinearity with another feature. --> Feature Location - RainToday_Yes was removed due to collinearity with another feature. --> Feature MaxTemp + RainToday_No was removed due to collinearity with another feature. --> Feature MaxTemp + RainToday_Yes was removed due to collinearity with another feature. --> Feature MinTemp + WindGustDir was removed due to collinearity with another feature. --> Feature Pressure3pm + RainToday_other was removed due to collinearity with another feature. --> Feature Pressure3pm - WindGustDir was removed due to collinearity with another feature. --> Feature Pressure9am - WindGustDir was removed due to collinearity with another feature. --> Feature RainToday_No + Temp9am was removed due to collinearity with another feature. --> Feature RainToday_No + WindGustDir was removed due to collinearity with another feature. --> Feature RainToday_No - WindDir9am was removed due to collinearity with another feature. --> Feature RainToday_Yes + Temp9am was removed due to collinearity with another feature. --> Feature RainToday_Yes + WindDir3pm was removed due to collinearity with another feature. --> Feature RainToday_Yes + WindDir9am was removed due to collinearity with another feature. --> Feature RainToday_Yes - WindDir9am was removed due to collinearity with another feature. --> Feature RainToday_other - Temp9am was removed due to collinearity with another feature. --> Feature RainToday_other - WindGustSpeed was removed due to collinearity with another feature. --> Feature RainToday_other - WindSpeed9am was removed due to collinearity with another feature. --> Feature Rainfall + RainToday_No was removed due to collinearity with another feature. --> Feature Rainfall + WindDir9am was removed due to collinearity with another feature. --> Feature Rainfall - WindDir3pm was removed due to collinearity with another feature. --> Feature SQRT(Cloud9am) was removed due to collinearity with another feature. --> Feature SQRT(Humidity3pm) was removed due to collinearity with another feature. --> Feature SQRT(Pressure9am) was removed due to collinearity with another feature. --> Feature Sunshine + WindDir9am was removed due to collinearity with another feature. --> Feature Temp3pm + WindDir9am was removed due to collinearity with another feature. --> Feature Temp3pm + WindGustDir was removed due to collinearity with another feature. --> Feature Temp3pm - WindDir3pm was removed due to collinearity with another feature. --> Feature Temp9am - WindDir9am was removed due to collinearity with another feature. --> Feature WindDir3pm - WindSpeed3pm was removed due to collinearity with another feature. --> Feature WindGustDir + WindGustSpeed was removed due to collinearity with another feature. --> Feature WindGustDir - WindSpeed9am was removed due to collinearity with another feature. --> The RFECV selected 42 features from the dataset. >>> Dropping feature Rainfall (rank 3). >>> Dropping feature Evaporation (rank 14). >>> Dropping feature WindGustSpeed (rank 12). >>> Dropping feature WindSpeed9am (rank 20). >>> Dropping feature WindSpeed3pm (rank 19). >>> Dropping feature Pressure9am (rank 10). >>> Dropping feature Cloud9am (rank 17). >>> Dropping feature Temp9am (rank 15). >>> Dropping feature RainToday_Yes (rank 27). >>> Dropping feature RainToday_No (rank 29). >>> Dropping feature RainToday_other (rank 16). >>> Dropping feature Cloud9am + WindSpeed9am (rank 6). >>> Dropping feature Evaporation + Rainfall (rank 7). >>> Dropping feature LOG(Cloud9am) (rank 30). >>> Dropping feature LOG(RainToday_other) (rank 28). >>> Dropping feature LOG(Sunshine) (rank 26). >>> Dropping feature LOG(Temp9am) (rank 18). >>> Dropping feature LOG(WindSpeed3pm) (rank 25). >>> Dropping feature Location - WindSpeed3pm (rank 22). >>> Dropping feature Location - WindSpeed9am (rank 21). >>> Dropping feature MaxTemp + Temp9am (rank 11). >>> Dropping feature MinTemp + Temp3pm (rank 2). >>> Dropping feature Pressure3pm - Temp9am (rank 9). >>> Dropping feature RainToday_No - Temp9am (rank 5). >>> Dropping feature RainToday_other - Sunshine (rank 13). >>> Dropping feature Rainfall + WindSpeed3pm (rank 8). >>> Dropping feature SQRT(Rainfall) (rank 23). >>> Dropping feature SQRT(WindSpeed9am) (rank 24). >>> Dropping feature WindGustSpeed + WindSpeed9am (rank 4). # The collinear attribute shows what features were removed due to multicollinearity atom.collinear .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } drop_feature correlated_feature correlation_value 0 Cloud3pm + Humidity3pm Humidity3pm 0.99578 1 Cloud3pm + RainToday_No Cloud3pm 0.98124 2 Cloud3pm + WindDir9am Cloud3pm, Cloud3pm + RainToday_No 0.99968, 0.98054 3 Cloud3pm - Location Cloud3pm, Cloud3pm + RainToday_No, Cloud3pm + ... 1.0, 0.98124, 0.99968 4 Cloud3pm - RainToday_No Cloud3pm, Cloud3pm + WindDir9am, Cloud3pm - Lo... 0.98405, 0.98409, 0.98405 5 Cloud9am + WindGustDir Cloud9am 0.99979 6 Evaporation + Location Evaporation 1.0 7 Evaporation + WindGustDir Evaporation, Evaporation + Location 0.9999, 0.9999 8 Evaporation - WindDir3pm Evaporation, Evaporation + Location, Evaporati... 0.9999, 0.9999, 0.99969 9 Humidity3pm - RainToday_No Humidity3pm, Cloud3pm + Humidity3pm 0.99983, 0.99572 10 Humidity3pm - Sunshine Humidity3pm, Cloud3pm + Humidity3pm, Humidity3... 0.99347, 0.99404, 0.99349 11 Humidity9am + RainToday_Yes Humidity9am 0.9998 12 Humidity9am - RainToday_No Humidity9am, Humidity9am + RainToday_Yes 0.9998, 0.99999 13 Humidity9am - Sunshine Humidity9am, Humidity9am + RainToday_Yes, Humi... 0.99164, 0.99183, 0.99183 14 LOG(MaxTemp) MaxTemp 0.98395 15 Location + MinTemp MinTemp 1.0 16 Location + RainToday_No RainToday_Yes, RainToday_No -0.98404, 1.0 17 Location + WindDir3pm WindDir3pm 1.0 18 Location + WindGustDir WindGustDir 1.0 19 Location + WindSpeed3pm WindSpeed3pm 1.0 20 Location - RainToday_Yes RainToday_Yes, RainToday_No, Location + RainTo... -1.0, 0.98404, 0.98404 21 MaxTemp + RainToday_No MaxTemp, LOG(MaxTemp) 0.99841, 0.9831 22 MaxTemp + RainToday_Yes MaxTemp, LOG(MaxTemp), MaxTemp + RainToday_No 0.99834, 0.98156, 0.99356 23 MinTemp + WindGustDir MinTemp, Location + MinTemp 0.99997, 0.99997 24 Pressure3pm + RainToday_other Pressure3pm 0.99995 25 Pressure3pm - WindGustDir Pressure3pm, Pressure3pm + RainToday_other 0.99998, 0.99992 26 Pressure9am - WindGustDir Pressure9am 0.99998 27 RainToday_No + Temp9am Temp9am 0.99797 28 RainToday_No + WindGustDir RainToday_No, Location + RainToday_No 0.99327, 0.99327 29 RainToday_No - WindDir9am RainToday_No, Location + RainToday_No 0.99167, 0.99167 30 RainToday_Yes + Temp9am Temp9am, RainToday_No + Temp9am, RainToday_No ... 0.99795, 0.99191, -0.99993 31 RainToday_Yes + WindDir3pm RainToday_Yes, Location - RainToday_Yes 0.99331, -0.99331 32 RainToday_Yes + WindDir9am RainToday_Yes, Location - RainToday_Yes, RainT... 0.99152, -0.99152, -0.98471, 0.98989 33 RainToday_Yes - WindDir9am RainToday_Yes, Location - RainToday_Yes 0.99107, -0.99107 34 RainToday_other - Temp9am Temp9am, RainToday_No + Temp9am, RainToday_No ... -0.99993, -0.998, 0.99775, -0.99792 35 RainToday_other - WindGustSpeed WindGustSpeed, Cloud9am - WindGustSpeed -0.99998, 0.98438 36 RainToday_other - WindSpeed9am WindSpeed9am, Location - WindSpeed9am -0.99997, 0.99997 37 Rainfall + RainToday_No Rainfall 0.99907 38 Rainfall + WindDir9am Rainfall, Rainfall + RainToday_No 0.99998, 0.99902 39 Rainfall - WindDir3pm Rainfall, Rainfall + RainToday_No, Rainfall + ... 0.99998, 0.99907, 0.99995 40 SQRT(Cloud9am) LOG(Cloud9am) 0.987 41 SQRT(Humidity3pm) Humidity3pm, Cloud3pm + Humidity3pm, Humidity3... 0.98722, 0.98193, 0.98675 42 SQRT(Pressure9am) Pressure9am, Pressure9am - WindGustDir 1.0, 0.99998 43 Sunshine + WindDir9am Sunshine, RainToday_other - Sunshine 0.99982, -0.99948 44 Temp3pm + WindDir9am Temp3pm 0.99997 45 Temp3pm + WindGustDir Temp3pm, Temp3pm + WindDir9am 0.99998, 0.99997 46 Temp3pm - WindDir3pm Temp3pm, Temp3pm + WindDir9am, Temp3pm + WindG... 0.99998, 0.99993, 0.99993 47 Temp9am - WindDir9am Temp9am, RainToday_No + Temp9am, RainToday_No ... 0.99996, 0.99798, -0.99783, 0.99787, -0.9999 48 WindDir3pm - WindSpeed3pm WindSpeed3pm, Location + WindSpeed3pm, Locatio... -0.99998, -0.99998, 0.99998 49 WindGustDir + WindGustSpeed WindGustSpeed, Cloud9am - WindGustSpeed, RainT... 0.99999, -0.9843, -0.99998 50 WindGustDir - WindSpeed9am WindSpeed9am, Location - WindSpeed9am, RainTod... -0.99999, 0.99999, 0.99995 # After applying RFECV, we can plot the score per number of features atom.plot_rfecv() # Let's see how the model performs now atom.run('LGB') Training ===================================== >> Models: LGB Metric: roc_auc Results for LightGBM: Fit --------------------------------------------- Train evaluation --> roc_auc: 0.9960 Test evaluation --> roc_auc: 0.8787 Time elapsed: 0.593s ------------------------------------------------- Total time: 0.600s Final results ========================= >> Duration: 0.602s ------------------------------------------ LightGBM --> roc_auc: 0.879 # Did the feature importance change? atom.plot_feature_importance(show=10) Lets try the same using Genetic Feature Generation atom = ATOMClassifier(X, n_rows=1e4, test_size=0.2, verbose=0, warnings=False, random_state=1) atom.clean() atom.impute(strat_num='knn', strat_cat='remove', min_frac_rows=0.8) atom.encode(max_onehot=10, frac_to_other=0.04) # Change verbosity to print extended info atom.verbose = 2 # Create new features using Genetic Programming atom.feature_generation(strategy='genetic', n_features=20, generations=10, population=2000) Fitting FeatureGenerator... | Population Average | Best Individual | ---- ------------------------- ------------------------------------------ ---------- Gen Length Fitness Length Fitness OOB Fitness Time Left 0 3.17 0.127544 3 0.504266 N/A 9.62s 1 3.10 0.33852 5 0.536639 N/A 9.04s 2 3.50 0.443648 9 0.541754 N/A 7.65s 3 4.48 0.476799 7 0.544984 N/A 6.96s 4 6.25 0.51219 13 0.546135 N/A 5.70s 5 7.45 0.508814 9 0.550855 N/A 4.75s 6 7.66 0.501224 11 0.55326 N/A 3.56s 7 8.05 0.498132 11 0.553417 N/A 2.32s 8 9.52 0.497282 13 0.554988 N/A 1.23s 9 10.82 0.492465 11 0.553417 N/A 0.00s Creating new features... --> 5 new features were added to the dataset. # We can see the feature's fitness and description through the genetic_features attribute atom.genetic_features .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } name description fitness 0 Feature 24 mul(mul(sub(sub(sub(Humidity3pm, Sunshine), Su... 0.542417 1 Feature 25 mul(sub(sub(sub(Humidity3pm, Sunshine), Sunshi... 0.542417 2 Feature 26 mul(Humidity3pm, mul(sub(sub(sub(Humidity3pm, ... 0.542417 3 Feature 27 mul(sub(sub(Humidity3pm, Sunshine), Sunshine),... 0.542260 4 Feature 28 mul(mul(sub(Humidity3pm, Sunshine), WindGustSp... 0.542260 # And fit the model again atom.run('LGB', metric='auc') Training ===================================== >> Models: LGB Metric: roc_auc Results for LightGBM: Fit --------------------------------------------- Train evaluation --> roc_auc: 0.9894 Test evaluation --> roc_auc: 0.8771 Time elapsed: 0.296s ------------------------------------------------- Total time: 0.301s Final results ========================= >> Duration: 0.303s ------------------------------------------ LightGBM --> roc_auc: 0.877 atom.plot_feature_importance(show=10) # We can check the feature importance with other plots as well atom.plot_permutation_importance(show=10) atom.dependence_plot()","title":"Run the pipeline"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/","text":"Imbalanced datasets This example shows the different approaches we can take to handle imbalanced datasets. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow . Load the data # Import packages import pandas as pd from atom import ATOMClassifier # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 116787 PerthAirport 15.1 39.2 0.0 11.6 13.2 E 48.0 124452 Walpole 9.1 22.7 0.0 NaN NaN NNE 41.0 5086 BadgerysCreek 12.5 28.4 0.0 NaN NaN ESE 30.0 77899 Watsonia 16.5 26.3 0.0 10.6 12.4 WSW 43.0 124901 Walpole 13.1 22.9 0.0 NaN NaN SSE 39.0 Run the pipeline # Initialize ATOM with the created dataset atom = ATOMClassifier(X, n_rows=0.3, test_size=0.3, verbose=2, random_state=1) atom.clean() atom.impute() atom.encode() << ================== ATOM ================== >> Algorithm task: binary classification. Dataset stats ================== >> Shape: (42658, 22) Missing values: 95216 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 29861 Test set size: 12797 ----------------------------------- Train set balance: No:Yes <==> 3.5:1.0 Test set balance: No:Yes <==> 3.4:1.0 ----------------------------------- Distribution of classes: | | dataset | train | test | |:----|----------:|--------:|-------:| | No | 33139 | 23247 | 9892 | | Yes | 9519 | 6614 | 2905 | Applying data cleaning... --> Label-encoding the target column. Fitting Imputer... Imputing missing values... --> Dropping 352 rows for containing less than 50% non-missing values. --> Dropping 92 rows due to missing values in feature MinTemp. --> Dropping 56 rows due to missing values in feature MaxTemp. --> Dropping 350 rows due to missing values in feature Rainfall. --> Dropping 17551 rows due to missing values in feature Evaporation. --> Dropping 3229 rows due to missing values in feature Sunshine. --> Dropping 1258 rows due to missing values in feature WindGustDir. --> Dropping 655 rows due to missing values in feature WindDir9am. --> Dropping 69 rows due to missing values in feature WindDir3pm. --> Dropping 73 rows due to missing values in feature Humidity9am. --> Dropping 20 rows due to missing values in feature Humidity3pm. --> Dropping 18 rows due to missing values in feature Pressure9am. --> Dropping 5 rows due to missing values in feature Pressure3pm. --> Dropping 1609 rows due to missing values in feature Cloud9am. --> Dropping 426 rows due to missing values in feature Cloud3pm. Fitting Encoder... Encoding categorical columns... --> LeaveOneOut-encoding feature Location. Contains 26 unique classes. --> LeaveOneOut-encoding feature WindGustDir. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir9am. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. # First, we fit a logistic regression model directly on the imbalanced data atom.run(\"LR\", metric=\"f1\", bagging=5) Training ===================================== >> Models: LR Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.6174 Test evaluation --> f1: 0.6096 Time elapsed: 0.078s Bagging ----------------------------------------- Evaluation --> f1: 0.6078 \u00b1 0.0048 Time elapsed: 0.342s ------------------------------------------------- Total time: 0.430s Final results ========================= >> Duration: 0.432s ------------------------------------------ Logistic Regression --> f1: 0.608 \u00b1 0.005 Use weighted classes # Add the class weights through the est_params parameter atom.run(\"LR_cw\", est_params={\"class_weight\": atom.get_class_weight()}, bagging=5) Training ===================================== >> Models: LR_cw Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.6174 Test evaluation --> f1: 0.6096 Time elapsed: 0.078s Bagging ----------------------------------------- Evaluation --> f1: 0.6078 \u00b1 0.0048 Time elapsed: 0.338s ------------------------------------------------- Total time: 0.422s Final results ========================= >> Duration: 0.422s ------------------------------------------ Logistic Regression --> f1: 0.608 \u00b1 0.005 Use sample weights # Remember to add \"_fit\" to the est_params key to add the parameter to the fit method atom.run(\"LR_sw\", est_params={\"sample_weight_fit\": atom.get_sample_weight()}, bagging=5) Training ===================================== >> Models: LR_sw Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.6174 Test evaluation --> f1: 0.6096 Time elapsed: 0.076s Bagging ----------------------------------------- Evaluation --> f1: 0.6078 \u00b1 0.0048 Time elapsed: 0.343s ------------------------------------------------- Total time: 0.426s Final results ========================= >> Duration: 0.427s ------------------------------------------ Logistic Regression --> f1: 0.608 \u00b1 0.005 Use oversampling # Perform oversampling of the minority class atom.balance(strategy='smote', sampling_strategy=0.9) Oversampling with SMOTE... --> Adding 5830 rows to class: Yes. atom.classes # Note the balanced training set! .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset train test 0 13189 9317 3872 1 9536 8385 1151 atom.run(\"LR_os\", bagging=5) Training ===================================== >> Models: LR_os Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.7918 Test evaluation --> f1: 0.6505 Time elapsed: 0.093s Bagging ----------------------------------------- Evaluation --> f1: 0.6489 \u00b1 0.0031 Time elapsed: 0.400s ------------------------------------------------- Total time: 0.504s Final results ========================= >> Duration: 0.505s ------------------------------------------ Logistic Regression --> f1: 0.649 \u00b1 0.003 Analyze results # Clearly, oversampling proves to be the best way to handle this imbalanced dataset atom.plot_bagging()","title":"Imbalanced datasets"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/#imbalanced-datasets","text":"This example shows the different approaches we can take to handle imbalanced datasets. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow .","title":"Imbalanced datasets"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/#load-the-data","text":"# Import packages import pandas as pd from atom import ATOMClassifier # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 116787 PerthAirport 15.1 39.2 0.0 11.6 13.2 E 48.0 124452 Walpole 9.1 22.7 0.0 NaN NaN NNE 41.0 5086 BadgerysCreek 12.5 28.4 0.0 NaN NaN ESE 30.0 77899 Watsonia 16.5 26.3 0.0 10.6 12.4 WSW 43.0 124901 Walpole 13.1 22.9 0.0 NaN NaN SSE 39.0","title":"Load the data"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/#run-the-pipeline","text":"# Initialize ATOM with the created dataset atom = ATOMClassifier(X, n_rows=0.3, test_size=0.3, verbose=2, random_state=1) atom.clean() atom.impute() atom.encode() << ================== ATOM ================== >> Algorithm task: binary classification. Dataset stats ================== >> Shape: (42658, 22) Missing values: 95216 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 29861 Test set size: 12797 ----------------------------------- Train set balance: No:Yes <==> 3.5:1.0 Test set balance: No:Yes <==> 3.4:1.0 ----------------------------------- Distribution of classes: | | dataset | train | test | |:----|----------:|--------:|-------:| | No | 33139 | 23247 | 9892 | | Yes | 9519 | 6614 | 2905 | Applying data cleaning... --> Label-encoding the target column. Fitting Imputer... Imputing missing values... --> Dropping 352 rows for containing less than 50% non-missing values. --> Dropping 92 rows due to missing values in feature MinTemp. --> Dropping 56 rows due to missing values in feature MaxTemp. --> Dropping 350 rows due to missing values in feature Rainfall. --> Dropping 17551 rows due to missing values in feature Evaporation. --> Dropping 3229 rows due to missing values in feature Sunshine. --> Dropping 1258 rows due to missing values in feature WindGustDir. --> Dropping 655 rows due to missing values in feature WindDir9am. --> Dropping 69 rows due to missing values in feature WindDir3pm. --> Dropping 73 rows due to missing values in feature Humidity9am. --> Dropping 20 rows due to missing values in feature Humidity3pm. --> Dropping 18 rows due to missing values in feature Pressure9am. --> Dropping 5 rows due to missing values in feature Pressure3pm. --> Dropping 1609 rows due to missing values in feature Cloud9am. --> Dropping 426 rows due to missing values in feature Cloud3pm. Fitting Encoder... Encoding categorical columns... --> LeaveOneOut-encoding feature Location. Contains 26 unique classes. --> LeaveOneOut-encoding feature WindGustDir. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir9am. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. # First, we fit a logistic regression model directly on the imbalanced data atom.run(\"LR\", metric=\"f1\", bagging=5) Training ===================================== >> Models: LR Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.6174 Test evaluation --> f1: 0.6096 Time elapsed: 0.078s Bagging ----------------------------------------- Evaluation --> f1: 0.6078 \u00b1 0.0048 Time elapsed: 0.342s ------------------------------------------------- Total time: 0.430s Final results ========================= >> Duration: 0.432s ------------------------------------------ Logistic Regression --> f1: 0.608 \u00b1 0.005","title":"Run the pipeline"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/#use-weighted-classes","text":"# Add the class weights through the est_params parameter atom.run(\"LR_cw\", est_params={\"class_weight\": atom.get_class_weight()}, bagging=5) Training ===================================== >> Models: LR_cw Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.6174 Test evaluation --> f1: 0.6096 Time elapsed: 0.078s Bagging ----------------------------------------- Evaluation --> f1: 0.6078 \u00b1 0.0048 Time elapsed: 0.338s ------------------------------------------------- Total time: 0.422s Final results ========================= >> Duration: 0.422s ------------------------------------------ Logistic Regression --> f1: 0.608 \u00b1 0.005","title":"Use weighted classes"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/#use-sample-weights","text":"# Remember to add \"_fit\" to the est_params key to add the parameter to the fit method atom.run(\"LR_sw\", est_params={\"sample_weight_fit\": atom.get_sample_weight()}, bagging=5) Training ===================================== >> Models: LR_sw Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.6174 Test evaluation --> f1: 0.6096 Time elapsed: 0.076s Bagging ----------------------------------------- Evaluation --> f1: 0.6078 \u00b1 0.0048 Time elapsed: 0.343s ------------------------------------------------- Total time: 0.426s Final results ========================= >> Duration: 0.427s ------------------------------------------ Logistic Regression --> f1: 0.608 \u00b1 0.005","title":"Use sample weights"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/#use-oversampling","text":"# Perform oversampling of the minority class atom.balance(strategy='smote', sampling_strategy=0.9) Oversampling with SMOTE... --> Adding 5830 rows to class: Yes. atom.classes # Note the balanced training set! .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } dataset train test 0 13189 9317 3872 1 9536 8385 1151 atom.run(\"LR_os\", bagging=5) Training ===================================== >> Models: LR_os Metric: f1 Results for Logistic Regression: Fit --------------------------------------------- Train evaluation --> f1: 0.7918 Test evaluation --> f1: 0.6505 Time elapsed: 0.093s Bagging ----------------------------------------- Evaluation --> f1: 0.6489 \u00b1 0.0031 Time elapsed: 0.400s ------------------------------------------------- Total time: 0.504s Final results ========================= >> Duration: 0.505s ------------------------------------------ Logistic Regression --> f1: 0.649 \u00b1 0.003","title":"Use oversampling"},{"location":"examples/imbalanced_datasets/imbalanced_datasets/#analyze-results","text":"# Clearly, oversampling proves to be the best way to handle this imbalanced dataset atom.plot_bagging()","title":"Analyze results"},{"location":"examples/multi_metric/multi_metric/","text":"Multi-metric This example shows how we can evaluate an ATOM pipeline on multiple metrics. Import the breast cancer dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict whether a patient has breast cancer or not. Load the data # Import packages from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier # Get the dataset's features and targets X, y = load_breast_cancer(return_X_y=True) Run the pipeline # Call ATOM and run the pipeline using multipe metrics # Note that for every step of the BO, both metrics are calculated, but only the first is used for optimization! atom = ATOMClassifier(X, y, n_jobs=2, verbose=2, warnings=False, random_state=1) atom.run(['MNB', 'QDA'], metric=('f1', 'recall'), n_calls=3, n_initial_points=1, bagging=4) << ================== ATOM ================== >> Algorithm task: binary classification. Parallel processing with 2 cores. Dataset stats ================== >> Shape: (569, 31) Scaled: False ----------------------------------- Train set size: 456 Test set size: 113 ----------------------------------- Train set balance: 0:1 <==> 1.0:1.7 Test set balance: 0:1 <==> 1.0:1.5 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 212 | 167 | 45 | | 1 | 357 | 289 | 68 | Training ===================================== >> Models: MNB, QDA Metric: f1, recall Running BO for Multinomial Naive Bayes... Initial point 1 --------------------------------- Parameters --> {'alpha': 1.0, 'fit_prior': True} Evaluation --> f1: 0.9260 Best f1: 0.9260 recall: 0.9722 Best recall: 0.9722 Time iteration: 3.553s Total time: 3.559s Iteration 2 ------------------------------------- Parameters --> {'alpha': 9.744, 'fit_prior': True} Evaluation --> f1: 0.9225 Best f1: 0.9260 recall: 0.9688 Best recall: 0.9722 Time iteration: 0.031s Total time: 3.595s Iteration 3 ------------------------------------- Parameters --> {'alpha': 0.66, 'fit_prior': False} Evaluation --> f1: 0.9223 Best f1: 0.9260 recall: 0.9655 Best recall: 0.9722 Time iteration: 0.031s Total time: 3.758s Results for Multinomial Naive Bayes: Bayesian Optimization --------------------------- Best parameters --> {'alpha': 1.0, 'fit_prior': True} Best evaluation --> f1: 0.9260 recall: 0.9722 Time elapsed: 3.879s Fit --------------------------------------------- Train evaluation --> f1: 0.9243 recall: 0.9723 Test evaluation --> f1: 0.9103 recall: 0.9706 Time elapsed: 0.012s Bagging ----------------------------------------- Evaluation --> f1: 0.9100 \u00b1 0.0005 recall: 0.9669 \u00b1 0.0064 Time elapsed: 0.028s ------------------------------------------------- Total time: 3.921s Running BO for Quadratic Discriminant Analysis... Initial point 1 --------------------------------- Parameters --> {'reg_param': 0} Evaluation --> f1: 0.9654 Best f1: 0.9654 recall: 0.9619 Best recall: 0.9619 Time iteration: 0.039s Total time: 0.042s Iteration 2 ------------------------------------- Parameters --> {'reg_param': 1.0} Evaluation --> f1: 0.9245 Best f1: 0.9654 recall: 0.9897 Best recall: 0.9897 Time iteration: 0.034s Total time: 0.080s Iteration 3 ------------------------------------- Parameters --> {'reg_param': 0.0} Evaluation --> f1: 0.9633 Best f1: 0.9654 recall: 0.9549 Best recall: 0.9897 Time iteration: 0.034s Total time: 0.211s Results for Quadratic Discriminant Analysis: Bayesian Optimization --------------------------- Best parameters --> {'reg_param': 0} Best evaluation --> f1: 0.9654 recall: 0.9619 Time elapsed: 0.315s Fit --------------------------------------------- Train evaluation --> f1: 0.9828 recall: 0.9896 Test evaluation --> f1: 0.9710 recall: 0.9853 Time elapsed: 0.014s Bagging ----------------------------------------- Evaluation --> f1: 0.9606 \u00b1 0.0081 recall: 0.9853 \u00b1 0.0104 Time elapsed: 0.033s ------------------------------------------------- Total time: 0.363s Final results ========================= >> Duration: 4.286s ------------------------------------------ Multinomial Naive Bayes --> f1: 0.910 \u00b1 0.001 recall: 0.967 \u00b1 0.006 Quadratic Discriminant Analysis --> f1: 0.961 \u00b1 0.008 recall: 0.985 \u00b1 0.010 ! Analyze the results # Note that some columns in the results dataframe now contain a list of scores, # one for each metric, in the same order as you called them atom.results[['metric_bo', 'metric_train', 'metric_test']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_bo metric_train metric_test model MNB [0.9259597646215939, 0.9722323049001815] [0.924342105263158, 0.972318339100346] [0.9103448275862068, 0.9705882352941176] QDA [0.965402611638704, 0.9618874773139746] [0.9828178694158075, 0.9896193771626297] [0.9710144927536232, 0.9852941176470589] # Some plots allow us to choose the metric we want to show atom.plot_bagging(metric='recall')","title":"Multi-metric runs"},{"location":"examples/multi_metric/multi_metric/#multi-metric","text":"This example shows how we can evaluate an ATOM pipeline on multiple metrics. Import the breast cancer dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict whether a patient has breast cancer or not.","title":"Multi-metric"},{"location":"examples/multi_metric/multi_metric/#load-the-data","text":"# Import packages from sklearn.datasets import load_breast_cancer from atom import ATOMClassifier # Get the dataset's features and targets X, y = load_breast_cancer(return_X_y=True)","title":"Load the data"},{"location":"examples/multi_metric/multi_metric/#run-the-pipeline","text":"# Call ATOM and run the pipeline using multipe metrics # Note that for every step of the BO, both metrics are calculated, but only the first is used for optimization! atom = ATOMClassifier(X, y, n_jobs=2, verbose=2, warnings=False, random_state=1) atom.run(['MNB', 'QDA'], metric=('f1', 'recall'), n_calls=3, n_initial_points=1, bagging=4) << ================== ATOM ================== >> Algorithm task: binary classification. Parallel processing with 2 cores. Dataset stats ================== >> Shape: (569, 31) Scaled: False ----------------------------------- Train set size: 456 Test set size: 113 ----------------------------------- Train set balance: 0:1 <==> 1.0:1.7 Test set balance: 0:1 <==> 1.0:1.5 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 212 | 167 | 45 | | 1 | 357 | 289 | 68 | Training ===================================== >> Models: MNB, QDA Metric: f1, recall Running BO for Multinomial Naive Bayes... Initial point 1 --------------------------------- Parameters --> {'alpha': 1.0, 'fit_prior': True} Evaluation --> f1: 0.9260 Best f1: 0.9260 recall: 0.9722 Best recall: 0.9722 Time iteration: 3.553s Total time: 3.559s Iteration 2 ------------------------------------- Parameters --> {'alpha': 9.744, 'fit_prior': True} Evaluation --> f1: 0.9225 Best f1: 0.9260 recall: 0.9688 Best recall: 0.9722 Time iteration: 0.031s Total time: 3.595s Iteration 3 ------------------------------------- Parameters --> {'alpha': 0.66, 'fit_prior': False} Evaluation --> f1: 0.9223 Best f1: 0.9260 recall: 0.9655 Best recall: 0.9722 Time iteration: 0.031s Total time: 3.758s Results for Multinomial Naive Bayes: Bayesian Optimization --------------------------- Best parameters --> {'alpha': 1.0, 'fit_prior': True} Best evaluation --> f1: 0.9260 recall: 0.9722 Time elapsed: 3.879s Fit --------------------------------------------- Train evaluation --> f1: 0.9243 recall: 0.9723 Test evaluation --> f1: 0.9103 recall: 0.9706 Time elapsed: 0.012s Bagging ----------------------------------------- Evaluation --> f1: 0.9100 \u00b1 0.0005 recall: 0.9669 \u00b1 0.0064 Time elapsed: 0.028s ------------------------------------------------- Total time: 3.921s Running BO for Quadratic Discriminant Analysis... Initial point 1 --------------------------------- Parameters --> {'reg_param': 0} Evaluation --> f1: 0.9654 Best f1: 0.9654 recall: 0.9619 Best recall: 0.9619 Time iteration: 0.039s Total time: 0.042s Iteration 2 ------------------------------------- Parameters --> {'reg_param': 1.0} Evaluation --> f1: 0.9245 Best f1: 0.9654 recall: 0.9897 Best recall: 0.9897 Time iteration: 0.034s Total time: 0.080s Iteration 3 ------------------------------------- Parameters --> {'reg_param': 0.0} Evaluation --> f1: 0.9633 Best f1: 0.9654 recall: 0.9549 Best recall: 0.9897 Time iteration: 0.034s Total time: 0.211s Results for Quadratic Discriminant Analysis: Bayesian Optimization --------------------------- Best parameters --> {'reg_param': 0} Best evaluation --> f1: 0.9654 recall: 0.9619 Time elapsed: 0.315s Fit --------------------------------------------- Train evaluation --> f1: 0.9828 recall: 0.9896 Test evaluation --> f1: 0.9710 recall: 0.9853 Time elapsed: 0.014s Bagging ----------------------------------------- Evaluation --> f1: 0.9606 \u00b1 0.0081 recall: 0.9853 \u00b1 0.0104 Time elapsed: 0.033s ------------------------------------------------- Total time: 0.363s Final results ========================= >> Duration: 4.286s ------------------------------------------ Multinomial Naive Bayes --> f1: 0.910 \u00b1 0.001 recall: 0.967 \u00b1 0.006 Quadratic Discriminant Analysis --> f1: 0.961 \u00b1 0.008 recall: 0.985 \u00b1 0.010 !","title":"Run the pipeline"},{"location":"examples/multi_metric/multi_metric/#analyze-the-results","text":"# Note that some columns in the results dataframe now contain a list of scores, # one for each metric, in the same order as you called them atom.results[['metric_bo', 'metric_train', 'metric_test']] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_bo metric_train metric_test model MNB [0.9259597646215939, 0.9722323049001815] [0.924342105263158, 0.972318339100346] [0.9103448275862068, 0.9705882352941176] QDA [0.965402611638704, 0.9618874773139746] [0.9828178694158075, 0.9896193771626297] [0.9710144927536232, 0.9852941176470589] # Some plots allow us to choose the metric we want to show atom.plot_bagging(metric='recall')","title":"Analyze the results"},{"location":"examples/multiclass_classification/multiclass_classification/","text":"Multiclass classification This example shows how to compare the performance of three models on a multiclass classification task. Import the wine dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict wines into three groups (which cultivator it's from) using features based on the results of chemical analysis. Load the data # Import packages from sklearn.datasets import load_wine from atom import ATOMClassifier # Load the dataset's features and targets X, y = load_wine(return_X_y=True, as_frame=True) # Let's have a look at a subsample of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } alcohol malic_acid ash alcalinity_of_ash magnesium total_phenols flavanoids nonflavanoid_phenols 134 12.51 1.24 2.25 17.5 85.0 2.00 0.58 0.60 70 12.29 1.61 2.21 20.4 103.0 1.10 1.02 0.37 95 12.47 1.52 2.20 19.0 162.0 2.50 2.27 0.32 59 12.37 0.94 1.36 10.6 88.0 1.98 0.57 0.28 115 11.03 1.51 2.20 21.5 85.0 2.46 2.17 0.52 Run the pipeline atom = ATOMClassifier(X, y, n_jobs=-1, warnings='ignore', verbose=2, random_state=1) # Fit the pipeline with the selected models atom.run( models=['LR','LDA', 'RF'], metric='roc_auc_ovr', n_calls=4, n_initial_points=3, bo_params={'base_estimator': 'rf', 'max_time': 100}, bagging=5 ) << ================== ATOM ================== >> Algorithm task: multiclass classification. Parallel processing with 16 cores. Dataset stats ================== >> Shape: (178, 14) Scaled: False ----------------------------------- Train set size: 143 Test set size: 35 ----------------------------------- Train set balance: 0:1:2 <==> 1.4:1.7:1.0 Test set balance: 0:1:2 <==> 1.0:1.4:1.4 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 59 | 50 | 9 | | 1 | 71 | 58 | 13 | | 2 | 48 | 35 | 13 | Training ===================================== >> Models: LR, LDA, RF Metric: roc_auc_ovr Running BO for Logistic Regression... Initial point 1 --------------------------------- Parameters --> {'penalty': 'l2', 'C': 46.003, 'solver': 'lbfgs', 'max_iter': 745} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 3.985s Total time: 4.078s Initial point 2 --------------------------------- Parameters --> {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 490} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 3.537s Total time: 7.620s Initial point 3 --------------------------------- Parameters --> {'penalty': 'l2', 'C': 0.037, 'solver': 'liblinear', 'max_iter': 352} Evaluation --> roc_auc_ovr: 0.9993 Best roc_auc_ovr: 1.0000 Time iteration: 3.675s Total time: 11.302s Iteration 4 ------------------------------------- Parameters --> {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 378} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 3.007s Total time: 14.545s Results for Logistic Regression: Bayesian Optimization --------------------------- Best parameters --> {'penalty': 'l2', 'C': 46.003, 'solver': 'lbfgs', 'max_iter': 745} Best evaluation --> roc_auc_ovr: 1.0000 Time elapsed: 14.760s Fit --------------------------------------------- Train evaluation --> roc_auc_ovr: 1.0000 Test evaluation --> roc_auc_ovr: 0.9965 Time elapsed: 0.025s Bagging ----------------------------------------- Evaluation --> roc_auc_ovr: 0.9942 \u00b1 0.0026 Time elapsed: 0.097s ------------------------------------------------- Total time: 14.886s Running BO for Linear Discriminant Analysis... Initial point 1 --------------------------------- Parameters --> {'solver': 'eigen', 'shrinkage': 1.0} Evaluation --> roc_auc_ovr: 0.8975 Best roc_auc_ovr: 0.8975 Time iteration: 0.030s Total time: 0.032s Initial point 2 --------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 0.030s Total time: 0.066s Initial point 3 --------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 0.028s Total time: 0.099s Iteration 4 ------------------------------------- Parameters --> {'solver': 'lsqr', 'shrinkage': 0.7} Evaluation --> roc_auc_ovr: 0.8996 Best roc_auc_ovr: 1.0000 Time iteration: 0.024s Total time: 0.309s Results for Linear Discriminant Analysis: Bayesian Optimization --------------------------- Best parameters --> {'solver': 'svd'} Best evaluation --> roc_auc_ovr: 1.0000 Time elapsed: 0.502s Fit --------------------------------------------- Train evaluation --> roc_auc_ovr: 1.0000 Test evaluation --> roc_auc_ovr: 1.0000 Time elapsed: 0.077s Bagging ----------------------------------------- Evaluation --> roc_auc_ovr: 0.9998 \u00b1 0.0005 Time elapsed: 0.037s ------------------------------------------------- Total time: 0.617s Running BO for Random Forest... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 245, 'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': None, 'bootstrap': True, 'ccp_alpha': 0.007, 'max_samples': 0.6} Evaluation --> roc_auc_ovr: 0.9921 Best roc_auc_ovr: 0.9921 Time iteration: 0.441s Total time: 0.449s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': 0.7, 'bootstrap': True, 'ccp_alpha': 0.008, 'max_samples': 0.7} Evaluation --> roc_auc_ovr: 0.9927 Best roc_auc_ovr: 0.9927 Time iteration: 0.648s Total time: 1.102s Initial point 3 --------------------------------- Parameters --> {'n_estimators': 78, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 14, 'max_features': 0.8, 'bootstrap': False, 'ccp_alpha': 0.003} Evaluation --> roc_auc_ovr: 0.9851 Best roc_auc_ovr: 0.9927 Time iteration: 0.129s Total time: 1.236s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 394, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 14, 'max_features': 0.8, 'bootstrap': False, 'ccp_alpha': 0.015} Evaluation --> roc_auc_ovr: 0.9897 Best roc_auc_ovr: 0.9927 Time iteration: 0.497s Total time: 2.036s Results for Random Forest: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': 0.7, 'bootstrap': True, 'ccp_alpha': 0.008, 'max_samples': 0.7} Best evaluation --> roc_auc_ovr: 0.9927 Time elapsed: 2.333s Fit --------------------------------------------- Train evaluation --> roc_auc_ovr: 0.9997 Test evaluation --> roc_auc_ovr: 0.9802 Time elapsed: 0.605s Bagging ----------------------------------------- Evaluation --> roc_auc_ovr: 0.9740 \u00b1 0.0074 Time elapsed: 2.643s ------------------------------------------------- Total time: 5.583s Final results ========================= >> Duration: 21.088s ------------------------------------------ Logistic Regression --> roc_auc_ovr: 0.994 \u00b1 0.003 Linear Discriminant Analysis --> roc_auc_ovr: 1.000 \u00b1 0.000 ! Random Forest --> roc_auc_ovr: 0.974 \u00b1 0.007 Analyze the results # We can access the pipeline's results via the results attribute atom.results .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_bo time_bo metric_train metric_test time_fit mean_bagging std_bagging time_bagging time model LR 1 14.760s 1 0.996503 0.025s 0.994172 0.00255349 0.097s 14.886s LDA 1 0.502s 1 1 0.077s 0.999767 0.0004662 0.037s 0.617s RF 0.992716 2.333s 0.999654 0.980186 0.605s 0.974022 0.00735105 2.643s 5.583s # Show the scoring for a different metric than the one we trained on atom.scoring('precision_macro') Results ===================== >> Logistic Regression --> precision_macro: 0.949 Linear Discriminant Analysis --> precision_macro: 1.0 Random Forest --> precision_macro: 0.919 Let's have a closer look at the Random Forest # Get the results on some other metrics print('Jaccard score:', atom.rf.scoring('jaccard_weighted')) print('Recall score:', atom.rf.scoring('recall_macro')) Jaccard score: 0.8428571428571429 Recall score: 0.923076923076923 # Plot the confusion matrix atom.RF.plot_confusion_matrix(figsize=(9, 9)) # Save the estimator as a pickle file atom.RF.save_estimator('Random_Forest_model') Random Forest estimator saved successfully!","title":"Multiclass classification"},{"location":"examples/multiclass_classification/multiclass_classification/#multiclass-classification","text":"This example shows how to compare the performance of three models on a multiclass classification task. Import the wine dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict wines into three groups (which cultivator it's from) using features based on the results of chemical analysis.","title":"Multiclass classification"},{"location":"examples/multiclass_classification/multiclass_classification/#load-the-data","text":"# Import packages from sklearn.datasets import load_wine from atom import ATOMClassifier # Load the dataset's features and targets X, y = load_wine(return_X_y=True, as_frame=True) # Let's have a look at a subsample of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } alcohol malic_acid ash alcalinity_of_ash magnesium total_phenols flavanoids nonflavanoid_phenols 134 12.51 1.24 2.25 17.5 85.0 2.00 0.58 0.60 70 12.29 1.61 2.21 20.4 103.0 1.10 1.02 0.37 95 12.47 1.52 2.20 19.0 162.0 2.50 2.27 0.32 59 12.37 0.94 1.36 10.6 88.0 1.98 0.57 0.28 115 11.03 1.51 2.20 21.5 85.0 2.46 2.17 0.52","title":"Load the data"},{"location":"examples/multiclass_classification/multiclass_classification/#run-the-pipeline","text":"atom = ATOMClassifier(X, y, n_jobs=-1, warnings='ignore', verbose=2, random_state=1) # Fit the pipeline with the selected models atom.run( models=['LR','LDA', 'RF'], metric='roc_auc_ovr', n_calls=4, n_initial_points=3, bo_params={'base_estimator': 'rf', 'max_time': 100}, bagging=5 ) << ================== ATOM ================== >> Algorithm task: multiclass classification. Parallel processing with 16 cores. Dataset stats ================== >> Shape: (178, 14) Scaled: False ----------------------------------- Train set size: 143 Test set size: 35 ----------------------------------- Train set balance: 0:1:2 <==> 1.4:1.7:1.0 Test set balance: 0:1:2 <==> 1.0:1.4:1.4 ----------------------------------- Distribution of classes: | | dataset | train | test | |---:|----------:|--------:|-------:| | 0 | 59 | 50 | 9 | | 1 | 71 | 58 | 13 | | 2 | 48 | 35 | 13 | Training ===================================== >> Models: LR, LDA, RF Metric: roc_auc_ovr Running BO for Logistic Regression... Initial point 1 --------------------------------- Parameters --> {'penalty': 'l2', 'C': 46.003, 'solver': 'lbfgs', 'max_iter': 745} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 3.985s Total time: 4.078s Initial point 2 --------------------------------- Parameters --> {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 490} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 3.537s Total time: 7.620s Initial point 3 --------------------------------- Parameters --> {'penalty': 'l2', 'C': 0.037, 'solver': 'liblinear', 'max_iter': 352} Evaluation --> roc_auc_ovr: 0.9993 Best roc_auc_ovr: 1.0000 Time iteration: 3.675s Total time: 11.302s Iteration 4 ------------------------------------- Parameters --> {'penalty': 'none', 'solver': 'newton-cg', 'max_iter': 378} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 3.007s Total time: 14.545s Results for Logistic Regression: Bayesian Optimization --------------------------- Best parameters --> {'penalty': 'l2', 'C': 46.003, 'solver': 'lbfgs', 'max_iter': 745} Best evaluation --> roc_auc_ovr: 1.0000 Time elapsed: 14.760s Fit --------------------------------------------- Train evaluation --> roc_auc_ovr: 1.0000 Test evaluation --> roc_auc_ovr: 0.9965 Time elapsed: 0.025s Bagging ----------------------------------------- Evaluation --> roc_auc_ovr: 0.9942 \u00b1 0.0026 Time elapsed: 0.097s ------------------------------------------------- Total time: 14.886s Running BO for Linear Discriminant Analysis... Initial point 1 --------------------------------- Parameters --> {'solver': 'eigen', 'shrinkage': 1.0} Evaluation --> roc_auc_ovr: 0.8975 Best roc_auc_ovr: 0.8975 Time iteration: 0.030s Total time: 0.032s Initial point 2 --------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 0.030s Total time: 0.066s Initial point 3 --------------------------------- Parameters --> {'solver': 'svd'} Evaluation --> roc_auc_ovr: 1.0000 Best roc_auc_ovr: 1.0000 Time iteration: 0.028s Total time: 0.099s Iteration 4 ------------------------------------- Parameters --> {'solver': 'lsqr', 'shrinkage': 0.7} Evaluation --> roc_auc_ovr: 0.8996 Best roc_auc_ovr: 1.0000 Time iteration: 0.024s Total time: 0.309s Results for Linear Discriminant Analysis: Bayesian Optimization --------------------------- Best parameters --> {'solver': 'svd'} Best evaluation --> roc_auc_ovr: 1.0000 Time elapsed: 0.502s Fit --------------------------------------------- Train evaluation --> roc_auc_ovr: 1.0000 Test evaluation --> roc_auc_ovr: 1.0000 Time elapsed: 0.077s Bagging ----------------------------------------- Evaluation --> roc_auc_ovr: 0.9998 \u00b1 0.0005 Time elapsed: 0.037s ------------------------------------------------- Total time: 0.617s Running BO for Random Forest... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 245, 'criterion': 'entropy', 'max_depth': None, 'min_samples_split': 13, 'min_samples_leaf': 6, 'max_features': None, 'bootstrap': True, 'ccp_alpha': 0.007, 'max_samples': 0.6} Evaluation --> roc_auc_ovr: 0.9921 Best roc_auc_ovr: 0.9921 Time iteration: 0.441s Total time: 0.449s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': 0.7, 'bootstrap': True, 'ccp_alpha': 0.008, 'max_samples': 0.7} Evaluation --> roc_auc_ovr: 0.9927 Best roc_auc_ovr: 0.9927 Time iteration: 0.648s Total time: 1.102s Initial point 3 --------------------------------- Parameters --> {'n_estimators': 78, 'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 14, 'max_features': 0.8, 'bootstrap': False, 'ccp_alpha': 0.003} Evaluation --> roc_auc_ovr: 0.9851 Best roc_auc_ovr: 0.9927 Time iteration: 0.129s Total time: 1.236s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 394, 'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 14, 'max_features': 0.8, 'bootstrap': False, 'ccp_alpha': 0.015} Evaluation --> roc_auc_ovr: 0.9897 Best roc_auc_ovr: 0.9927 Time iteration: 0.497s Total time: 2.036s Results for Random Forest: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 400, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': 0.7, 'bootstrap': True, 'ccp_alpha': 0.008, 'max_samples': 0.7} Best evaluation --> roc_auc_ovr: 0.9927 Time elapsed: 2.333s Fit --------------------------------------------- Train evaluation --> roc_auc_ovr: 0.9997 Test evaluation --> roc_auc_ovr: 0.9802 Time elapsed: 0.605s Bagging ----------------------------------------- Evaluation --> roc_auc_ovr: 0.9740 \u00b1 0.0074 Time elapsed: 2.643s ------------------------------------------------- Total time: 5.583s Final results ========================= >> Duration: 21.088s ------------------------------------------ Logistic Regression --> roc_auc_ovr: 0.994 \u00b1 0.003 Linear Discriminant Analysis --> roc_auc_ovr: 1.000 \u00b1 0.000 ! Random Forest --> roc_auc_ovr: 0.974 \u00b1 0.007","title":"Run the pipeline"},{"location":"examples/multiclass_classification/multiclass_classification/#analyze-the-results","text":"# We can access the pipeline's results via the results attribute atom.results .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_bo time_bo metric_train metric_test time_fit mean_bagging std_bagging time_bagging time model LR 1 14.760s 1 0.996503 0.025s 0.994172 0.00255349 0.097s 14.886s LDA 1 0.502s 1 1 0.077s 0.999767 0.0004662 0.037s 0.617s RF 0.992716 2.333s 0.999654 0.980186 0.605s 0.974022 0.00735105 2.643s 5.583s # Show the scoring for a different metric than the one we trained on atom.scoring('precision_macro') Results ===================== >> Logistic Regression --> precision_macro: 0.949 Linear Discriminant Analysis --> precision_macro: 1.0 Random Forest --> precision_macro: 0.919 Let's have a closer look at the Random Forest # Get the results on some other metrics print('Jaccard score:', atom.rf.scoring('jaccard_weighted')) print('Recall score:', atom.rf.scoring('recall_macro')) Jaccard score: 0.8428571428571429 Recall score: 0.923076923076923 # Plot the confusion matrix atom.RF.plot_confusion_matrix(figsize=(9, 9)) # Save the estimator as a pickle file atom.RF.save_estimator('Random_Forest_model') Random Forest estimator saved successfully!","title":"Analyze the results"},{"location":"examples/regression/regression/","text":"Regression This example shows how to use ATOM to apply PCA on the data and run a regression pipeline. Download the abalone dataset from https://archive.ics.uci.edu/ml/datasets/Abalone . The goal of this dataset is to predict the rings (age) of abalone shells from physical measurements. Load the data # Import packages import pandas as pd from atom import ATOMRegressor # Load the abalone dataset X = pd.read_csv('./datasets/abalone.csv') # Let's have a look at the data X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex Length Diameter Height Whole weight Shucked weight Viscera weight Shell weight Rings 0 M 0.455 0.365 0.095 0.5140 0.2245 0.1010 0.150 15 1 M 0.350 0.265 0.090 0.2255 0.0995 0.0485 0.070 7 2 F 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9 3 M 0.440 0.365 0.125 0.5160 0.2155 0.1140 0.155 10 4 I 0.330 0.255 0.080 0.2050 0.0895 0.0395 0.055 7 # Initialize ATOM for regression tasks and encode the categorical features atom = ATOMRegressor(X, \"Rings\", verbose=2, random_state=42) atom.encode() << ================== ATOM ================== >> Algorithm task: regression. Dataset stats ================== >> Shape: (4177, 9) Categorical columns: 1 Scaled: False ----------------------------------- Train set size: 3342 Test set size: 835 Fitting Encoder... Encoding categorical columns... --> OneHot-encoding feature Sex. Contains 3 unique classes. # Plot the dataset's correlation matrix atom.plot_correlation() # Apply PCA for dimensionality reduction atom.feature_selection(strategy=\"pca\", n_features=6) Fitting FeatureSelector... Performing feature selection ... --> Applying Principal Component Analysis... >>> Scaling features... >>> Total explained variance: 0.976 # Use the plotting methods to see the retained variance ratio atom.plot_pca() atom.plot_components(figsize=(8, 6), filename='atom_PCA_plot') Run the pipeline atom.run( models=['Tree', 'Bag', 'ET'], metric='MSE', n_calls=5, n_initial_points=2, bo_params={'base_estimator': 'GBRT', 'cv': 1}, bagging=5 ) Training ===================================== >> Models: Tree, Bag, ET Metric: neg_mean_squared_error Running BO for Decision Tree... Initial point 1 --------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 19, 'max_features': None, 'ccp_alpha': 0.016} Evaluation --> neg_mean_squared_error: -8.3677 Best neg_mean_squared_error: -8.3677 Time iteration: 0.043s Total time: 0.049s Initial point 2 --------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 12, 'max_features': 0.9, 'ccp_alpha': 0.0} Evaluation --> neg_mean_squared_error: -8.2055 Best neg_mean_squared_error: -8.2055 Time iteration: 0.186s Total time: 0.240s Iteration 3 ------------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 0.9, 'ccp_alpha': 0.005} Evaluation --> neg_mean_squared_error: -6.1540 Best neg_mean_squared_error: -6.1540 Time iteration: 0.172s Total time: 0.619s Iteration 4 ------------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 0.7, 'ccp_alpha': 0.018} Evaluation --> neg_mean_squared_error: -7.9567 Best neg_mean_squared_error: -6.1540 Time iteration: 0.070s Total time: 0.797s Iteration 5 ------------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_features': 0.9, 'ccp_alpha': 0.009} Evaluation --> neg_mean_squared_error: -7.1330 Best neg_mean_squared_error: -6.1540 Time iteration: 0.171s Total time: 1.079s Results for Decision Tree: Bayesian Optimization --------------------------- Best parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 0.9, 'ccp_alpha': 0.005} Best evaluation --> neg_mean_squared_error: -6.1540 Time elapsed: 1.187s Fit --------------------------------------------- Train evaluation --> neg_mean_squared_error: -6.3073 Test evaluation --> neg_mean_squared_error: -5.5317 Time elapsed: 0.262s Bagging ----------------------------------------- Evaluation --> neg_mean_squared_error: -5.6780 \u00b1 0.2464 Time elapsed: 1.056s ------------------------------------------------- Total time: 2.507s Running BO for Bagging Regressor... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 112, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': False, 'bootstrap_features': False} Evaluation --> neg_mean_squared_error: -5.7680 Best neg_mean_squared_error: -5.7680 Time iteration: 0.887s Total time: 0.891s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 131, 'max_samples': 0.5, 'max_features': 0.5, 'bootstrap': False, 'bootstrap_features': False} Evaluation --> neg_mean_squared_error: -6.8254 Best neg_mean_squared_error: -5.7680 Time iteration: 0.598s Total time: 1.495s Iteration 3 ------------------------------------- Parameters --> {'n_estimators': 50, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': False, 'bootstrap_features': True} Evaluation --> neg_mean_squared_error: -5.4895 Best neg_mean_squared_error: -5.4895 Time iteration: 0.392s Total time: 1.980s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 74, 'max_samples': 0.5, 'max_features': 0.5, 'bootstrap': False, 'bootstrap_features': True} Evaluation --> neg_mean_squared_error: -6.0363 Best neg_mean_squared_error: -5.4895 Time iteration: 0.335s Total time: 2.413s Iteration 5 ------------------------------------- Parameters --> {'n_estimators': 36, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': True, 'bootstrap_features': False} Evaluation --> neg_mean_squared_error: -6.0037 Best neg_mean_squared_error: -5.4895 Time iteration: 0.193s Total time: 2.696s Results for Bagging Regressor: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 50, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': False, 'bootstrap_features': True} Best evaluation --> neg_mean_squared_error: -5.4895 Time elapsed: 2.793s Fit --------------------------------------------- Train evaluation --> neg_mean_squared_error: -0.0867 Test evaluation --> neg_mean_squared_error: -4.9533 Time elapsed: 0.515s Bagging ----------------------------------------- Evaluation --> neg_mean_squared_error: -5.2363 \u00b1 0.1099 Time elapsed: 2.156s ------------------------------------------------- Total time: 5.465s Running BO for Extra-Trees... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 112, 'criterion': 'mae', 'max_depth': 1, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 0.6, 'bootstrap': True, 'ccp_alpha': 0.016, 'max_samples': 0.6} Evaluation --> neg_mean_squared_error: -10.2607 Best neg_mean_squared_error: -10.2607 Time iteration: 0.366s Total time: 0.373s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 369, 'criterion': 'mae', 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 12, 'max_features': 0.9, 'bootstrap': True, 'ccp_alpha': 0.035, 'max_samples': 0.8} Evaluation --> neg_mean_squared_error: -9.4727 Best neg_mean_squared_error: -9.4727 Time iteration: 4.781s Total time: 5.159s Iteration 3 ------------------------------------- Parameters --> {'n_estimators': 385, 'criterion': 'mse', 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 18, 'max_features': 0.9, 'bootstrap': False, 'ccp_alpha': 0.02} Evaluation --> neg_mean_squared_error: -5.5174 Best neg_mean_squared_error: -5.5174 Time iteration: 0.508s Total time: 5.793s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 425, 'criterion': 'mse', 'max_depth': 1, 'min_samples_split': 20, 'min_samples_leaf': 19, 'max_features': 0.7, 'bootstrap': False, 'ccp_alpha': 0.016} Evaluation --> neg_mean_squared_error: -9.1980 Best neg_mean_squared_error: -5.5174 Time iteration: 0.314s Total time: 6.231s Iteration 5 ------------------------------------- Parameters --> {'n_estimators': 445, 'criterion': 'mse', 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': 0.6, 'bootstrap': False, 'ccp_alpha': 0.004} Evaluation --> neg_mean_squared_error: -6.9959 Best neg_mean_squared_error: -5.5174 Time iteration: 0.428s Total time: 6.782s Results for Extra-Trees: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 385, 'criterion': 'mse', 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 18, 'max_features': 0.9, 'bootstrap': False, 'ccp_alpha': 0.02} Best evaluation --> neg_mean_squared_error: -5.5174 Time elapsed: 6.909s Fit --------------------------------------------- Train evaluation --> neg_mean_squared_error: -6.1021 Test evaluation --> neg_mean_squared_error: -5.0002 Time elapsed: 0.656s Bagging ----------------------------------------- Evaluation --> neg_mean_squared_error: -4.9204 \u00b1 0.0591 Time elapsed: 3.082s ------------------------------------------------- Total time: 10.647s Final results ========================= >> Duration: 18.623s ------------------------------------------ Decision Tree --> neg_mean_squared_error: -5.678 \u00b1 0.246 ~ Bagging Regressor --> neg_mean_squared_error: -5.236 \u00b1 0.110 ~ Extra-Trees --> neg_mean_squared_error: -4.920 \u00b1 0.059 ~ ! Analyze the results # For regression tasks, use the errors or residuals plots to check the model performances atom.plot_residuals() # Use the partial dependence plot to analyze the relation between the target response and the features atom.n_jobs = 8 # The method can be slow... atom.ET.plot_partial_dependence(features=(0, 1, (2, 3)), figsize=(12, 8))","title":"Regression"},{"location":"examples/regression/regression/#regression","text":"This example shows how to use ATOM to apply PCA on the data and run a regression pipeline. Download the abalone dataset from https://archive.ics.uci.edu/ml/datasets/Abalone . The goal of this dataset is to predict the rings (age) of abalone shells from physical measurements.","title":"Regression"},{"location":"examples/regression/regression/#load-the-data","text":"# Import packages import pandas as pd from atom import ATOMRegressor # Load the abalone dataset X = pd.read_csv('./datasets/abalone.csv') # Let's have a look at the data X.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Sex Length Diameter Height Whole weight Shucked weight Viscera weight Shell weight Rings 0 M 0.455 0.365 0.095 0.5140 0.2245 0.1010 0.150 15 1 M 0.350 0.265 0.090 0.2255 0.0995 0.0485 0.070 7 2 F 0.530 0.420 0.135 0.6770 0.2565 0.1415 0.210 9 3 M 0.440 0.365 0.125 0.5160 0.2155 0.1140 0.155 10 4 I 0.330 0.255 0.080 0.2050 0.0895 0.0395 0.055 7 # Initialize ATOM for regression tasks and encode the categorical features atom = ATOMRegressor(X, \"Rings\", verbose=2, random_state=42) atom.encode() << ================== ATOM ================== >> Algorithm task: regression. Dataset stats ================== >> Shape: (4177, 9) Categorical columns: 1 Scaled: False ----------------------------------- Train set size: 3342 Test set size: 835 Fitting Encoder... Encoding categorical columns... --> OneHot-encoding feature Sex. Contains 3 unique classes. # Plot the dataset's correlation matrix atom.plot_correlation() # Apply PCA for dimensionality reduction atom.feature_selection(strategy=\"pca\", n_features=6) Fitting FeatureSelector... Performing feature selection ... --> Applying Principal Component Analysis... >>> Scaling features... >>> Total explained variance: 0.976 # Use the plotting methods to see the retained variance ratio atom.plot_pca() atom.plot_components(figsize=(8, 6), filename='atom_PCA_plot')","title":"Load the data"},{"location":"examples/regression/regression/#run-the-pipeline","text":"atom.run( models=['Tree', 'Bag', 'ET'], metric='MSE', n_calls=5, n_initial_points=2, bo_params={'base_estimator': 'GBRT', 'cv': 1}, bagging=5 ) Training ===================================== >> Models: Tree, Bag, ET Metric: neg_mean_squared_error Running BO for Decision Tree... Initial point 1 --------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 19, 'max_features': None, 'ccp_alpha': 0.016} Evaluation --> neg_mean_squared_error: -8.3677 Best neg_mean_squared_error: -8.3677 Time iteration: 0.043s Total time: 0.049s Initial point 2 --------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 12, 'max_features': 0.9, 'ccp_alpha': 0.0} Evaluation --> neg_mean_squared_error: -8.2055 Best neg_mean_squared_error: -8.2055 Time iteration: 0.186s Total time: 0.240s Iteration 3 ------------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 0.9, 'ccp_alpha': 0.005} Evaluation --> neg_mean_squared_error: -6.1540 Best neg_mean_squared_error: -6.1540 Time iteration: 0.172s Total time: 0.619s Iteration 4 ------------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'random', 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 4, 'max_features': 0.7, 'ccp_alpha': 0.018} Evaluation --> neg_mean_squared_error: -7.9567 Best neg_mean_squared_error: -6.1540 Time iteration: 0.070s Total time: 0.797s Iteration 5 ------------------------------------- Parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 5, 'max_features': 0.9, 'ccp_alpha': 0.009} Evaluation --> neg_mean_squared_error: -7.1330 Best neg_mean_squared_error: -6.1540 Time iteration: 0.171s Total time: 1.079s Results for Decision Tree: Bayesian Optimization --------------------------- Best parameters --> {'criterion': 'mae', 'splitter': 'best', 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 9, 'max_features': 0.9, 'ccp_alpha': 0.005} Best evaluation --> neg_mean_squared_error: -6.1540 Time elapsed: 1.187s Fit --------------------------------------------- Train evaluation --> neg_mean_squared_error: -6.3073 Test evaluation --> neg_mean_squared_error: -5.5317 Time elapsed: 0.262s Bagging ----------------------------------------- Evaluation --> neg_mean_squared_error: -5.6780 \u00b1 0.2464 Time elapsed: 1.056s ------------------------------------------------- Total time: 2.507s Running BO for Bagging Regressor... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 112, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': False, 'bootstrap_features': False} Evaluation --> neg_mean_squared_error: -5.7680 Best neg_mean_squared_error: -5.7680 Time iteration: 0.887s Total time: 0.891s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 131, 'max_samples': 0.5, 'max_features': 0.5, 'bootstrap': False, 'bootstrap_features': False} Evaluation --> neg_mean_squared_error: -6.8254 Best neg_mean_squared_error: -5.7680 Time iteration: 0.598s Total time: 1.495s Iteration 3 ------------------------------------- Parameters --> {'n_estimators': 50, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': False, 'bootstrap_features': True} Evaluation --> neg_mean_squared_error: -5.4895 Best neg_mean_squared_error: -5.4895 Time iteration: 0.392s Total time: 1.980s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 74, 'max_samples': 0.5, 'max_features': 0.5, 'bootstrap': False, 'bootstrap_features': True} Evaluation --> neg_mean_squared_error: -6.0363 Best neg_mean_squared_error: -5.4895 Time iteration: 0.335s Total time: 2.413s Iteration 5 ------------------------------------- Parameters --> {'n_estimators': 36, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': True, 'bootstrap_features': False} Evaluation --> neg_mean_squared_error: -6.0037 Best neg_mean_squared_error: -5.4895 Time iteration: 0.193s Total time: 2.696s Results for Bagging Regressor: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 50, 'max_samples': 0.9, 'max_features': 0.6, 'bootstrap': False, 'bootstrap_features': True} Best evaluation --> neg_mean_squared_error: -5.4895 Time elapsed: 2.793s Fit --------------------------------------------- Train evaluation --> neg_mean_squared_error: -0.0867 Test evaluation --> neg_mean_squared_error: -4.9533 Time elapsed: 0.515s Bagging ----------------------------------------- Evaluation --> neg_mean_squared_error: -5.2363 \u00b1 0.1099 Time elapsed: 2.156s ------------------------------------------------- Total time: 5.465s Running BO for Extra-Trees... Initial point 1 --------------------------------- Parameters --> {'n_estimators': 112, 'criterion': 'mae', 'max_depth': 1, 'min_samples_split': 9, 'min_samples_leaf': 7, 'max_features': 0.6, 'bootstrap': True, 'ccp_alpha': 0.016, 'max_samples': 0.6} Evaluation --> neg_mean_squared_error: -10.2607 Best neg_mean_squared_error: -10.2607 Time iteration: 0.366s Total time: 0.373s Initial point 2 --------------------------------- Parameters --> {'n_estimators': 369, 'criterion': 'mae', 'max_depth': None, 'min_samples_split': 3, 'min_samples_leaf': 12, 'max_features': 0.9, 'bootstrap': True, 'ccp_alpha': 0.035, 'max_samples': 0.8} Evaluation --> neg_mean_squared_error: -9.4727 Best neg_mean_squared_error: -9.4727 Time iteration: 4.781s Total time: 5.159s Iteration 3 ------------------------------------- Parameters --> {'n_estimators': 385, 'criterion': 'mse', 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 18, 'max_features': 0.9, 'bootstrap': False, 'ccp_alpha': 0.02} Evaluation --> neg_mean_squared_error: -5.5174 Best neg_mean_squared_error: -5.5174 Time iteration: 0.508s Total time: 5.793s Iteration 4 ------------------------------------- Parameters --> {'n_estimators': 425, 'criterion': 'mse', 'max_depth': 1, 'min_samples_split': 20, 'min_samples_leaf': 19, 'max_features': 0.7, 'bootstrap': False, 'ccp_alpha': 0.016} Evaluation --> neg_mean_squared_error: -9.1980 Best neg_mean_squared_error: -5.5174 Time iteration: 0.314s Total time: 6.231s Iteration 5 ------------------------------------- Parameters --> {'n_estimators': 445, 'criterion': 'mse', 'max_depth': None, 'min_samples_split': 7, 'min_samples_leaf': 20, 'max_features': 0.6, 'bootstrap': False, 'ccp_alpha': 0.004} Evaluation --> neg_mean_squared_error: -6.9959 Best neg_mean_squared_error: -5.5174 Time iteration: 0.428s Total time: 6.782s Results for Extra-Trees: Bayesian Optimization --------------------------- Best parameters --> {'n_estimators': 385, 'criterion': 'mse', 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 18, 'max_features': 0.9, 'bootstrap': False, 'ccp_alpha': 0.02} Best evaluation --> neg_mean_squared_error: -5.5174 Time elapsed: 6.909s Fit --------------------------------------------- Train evaluation --> neg_mean_squared_error: -6.1021 Test evaluation --> neg_mean_squared_error: -5.0002 Time elapsed: 0.656s Bagging ----------------------------------------- Evaluation --> neg_mean_squared_error: -4.9204 \u00b1 0.0591 Time elapsed: 3.082s ------------------------------------------------- Total time: 10.647s Final results ========================= >> Duration: 18.623s ------------------------------------------ Decision Tree --> neg_mean_squared_error: -5.678 \u00b1 0.246 ~ Bagging Regressor --> neg_mean_squared_error: -5.236 \u00b1 0.110 ~ Extra-Trees --> neg_mean_squared_error: -4.920 \u00b1 0.059 ~ !","title":"Run the pipeline"},{"location":"examples/regression/regression/#analyze-the-results","text":"# For regression tasks, use the errors or residuals plots to check the model performances atom.plot_residuals() # Use the partial dependence plot to analyze the relation between the target response and the features atom.n_jobs = 8 # The method can be slow... atom.ET.plot_partial_dependence(features=(0, 1, (2, 3)), figsize=(12, 8))","title":"Analyze the results"},{"location":"examples/successive_halving/successive_halving/","text":"Successive halving This example shows how to compare multiple tree-based models using successive halving. Import the boston dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict house prices. Load the data # Import packages from sklearn.datasets import load_boston from atom import ATOMRegressor # Load the dataset's features and targets X, y = load_boston(return_X_y=True) Run the pipeline atom = ATOMRegressor(X, y, verbose=1, random_state=1) << ================== ATOM ================== >> Algorithm task: regression. Dataset stats ================== >> Shape: (506, 14) Scaled: False ----------------------------------- Train set size: 405 Test set size: 101 # We can compare tree-based models via successive halving atom.successive_halving( models=['tree', 'bag', 'et', 'rf', 'lgb', 'catb'], metric='mae', bagging=5 ) Training ===================================== >> Metric: neg_mean_absolute_error Run: 0 ================================ >> Models: Tree, Bag, ET, RF, LGB, CatB Size of training set: 67 (17%) Size of test set: 101 Results for Decision Tree: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0000 Test evaluation --> neg_mean_absolute_error: -3.3257 Time elapsed: 0.007s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -4.3307 \u00b1 0.5250 Time elapsed: 0.022s ------------------------------------------------- Total time: 0.029s Results for Bagging Regressor: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -1.3054 Test evaluation --> neg_mean_absolute_error: -2.6950 Time elapsed: 0.020s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -3.0957 \u00b1 0.2677 Time elapsed: 0.082s ------------------------------------------------- Total time: 0.104s Results for Extra-Trees: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0000 Test evaluation --> neg_mean_absolute_error: -2.1541 Time elapsed: 0.086s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.5554 \u00b1 0.1708 Time elapsed: 0.360s ------------------------------------------------- Total time: 0.446s Results for Random Forest: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -1.1509 Test evaluation --> neg_mean_absolute_error: -2.4143 Time elapsed: 0.109s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.9574 \u00b1 0.2253 Time elapsed: 0.506s ------------------------------------------------- Total time: 0.615s Results for LightGBM: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -3.4205 Test evaluation --> neg_mean_absolute_error: -4.5600 Time elapsed: 0.027s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -4.8393 \u00b1 0.2682 Time elapsed: 0.074s ------------------------------------------------- Total time: 0.103s Results for CatBoost: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0806 Test evaluation --> neg_mean_absolute_error: -2.3984 Time elapsed: 1.333s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.9165 \u00b1 0.2564 Time elapsed: 4.065s ------------------------------------------------- Total time: 5.399s Final results ========================= >> Duration: 6.699s ------------------------------------------ Decision Tree --> neg_mean_absolute_error: -4.331 \u00b1 0.525 ~ Bagging Regressor --> neg_mean_absolute_error: -3.096 \u00b1 0.268 ~ Extra-Trees --> neg_mean_absolute_error: -2.555 \u00b1 0.171 ~ ! Random Forest --> neg_mean_absolute_error: -2.957 \u00b1 0.225 ~ LightGBM --> neg_mean_absolute_error: -4.839 \u00b1 0.268 ~ CatBoost --> neg_mean_absolute_error: -2.916 \u00b1 0.256 ~ Run: 1 ================================ >> Models: ET, CatB, RF Size of training set: 135 (33%) Size of test set: 101 Results for Extra-Trees: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0000 Test evaluation --> neg_mean_absolute_error: -2.2361 Time elapsed: 0.099s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.6016 \u00b1 0.2890 Time elapsed: 0.418s ------------------------------------------------- Total time: 0.517s Results for CatBoost: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.2835 Test evaluation --> neg_mean_absolute_error: -2.4196 Time elapsed: 1.847s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.5681 \u00b1 0.2119 Time elapsed: 6.494s ------------------------------------------------- Total time: 8.343s Results for Random Forest: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.9820 Test evaluation --> neg_mean_absolute_error: -2.5055 Time elapsed: 0.131s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.6144 \u00b1 0.1188 Time elapsed: 0.662s ------------------------------------------------- Total time: 0.793s Final results ========================= >> Duration: 9.655s ------------------------------------------ Extra-Trees --> neg_mean_absolute_error: -2.602 \u00b1 0.289 ~ CatBoost --> neg_mean_absolute_error: -2.568 \u00b1 0.212 ~ ! Random Forest --> neg_mean_absolute_error: -2.614 \u00b1 0.119 ~ Run: 2 ================================ >> Models: CatB Size of training set: 405 (100%) Size of test set: 101 Results for CatBoost: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.3978 Test evaluation --> neg_mean_absolute_error: -1.8772 Time elapsed: 3.348s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.0501 \u00b1 0.0892 Time elapsed: 14.871s ------------------------------------------------- Total time: 18.221s Final results ========================= >> Duration: 18.223s ------------------------------------------ CatBoost --> neg_mean_absolute_error: -2.050 \u00b1 0.089 ~ Analyze results # Note that the results dataframe now is multi-index atom.results .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_train metric_test time_fit mean_bagging std_bagging time_bagging time n_models model 1 CatB -0.397799 -1.87721 3.348s -2.05012 0.0891846 14.871s 18.221s 3 ET -2.31519e-14 -2.23608 0.099s -2.60165 0.289034 0.418s 0.517s RF -0.981978 -2.50547 0.131s -2.61442 0.118758 0.662s 0.793s CatB -0.28355 -2.41962 1.847s -2.56808 0.211868 6.494s 8.343s 6 Tree -0 -3.32574 0.007s -4.33069 0.525026 0.022s 0.029s Bag -1.30537 -2.69505 0.020s -3.09566 0.267668 0.082s 0.104s ET -2.25624e-14 -2.15409 0.086s -2.55543 0.170823 0.360s 0.446s RF -1.15087 -2.4143 0.109s -2.9574 0.225311 0.506s 0.615s LGB -3.42052 -4.55996 0.027s -4.83931 0.268167 0.074s 0.103s CatB -0.080555 -2.39843 1.333s -2.91647 0.256428 4.065s 5.399s # Plot the successive halving's results atom.plot_successive_halving()","title":"Successive halving"},{"location":"examples/successive_halving/successive_halving/#successive-halving","text":"This example shows how to compare multiple tree-based models using successive halving. Import the boston dataset from sklearn.datasets . This is a small and easy to train dataset whose goal is to predict house prices.","title":"Successive halving"},{"location":"examples/successive_halving/successive_halving/#load-the-data","text":"# Import packages from sklearn.datasets import load_boston from atom import ATOMRegressor # Load the dataset's features and targets X, y = load_boston(return_X_y=True)","title":"Load the data"},{"location":"examples/successive_halving/successive_halving/#run-the-pipeline","text":"atom = ATOMRegressor(X, y, verbose=1, random_state=1) << ================== ATOM ================== >> Algorithm task: regression. Dataset stats ================== >> Shape: (506, 14) Scaled: False ----------------------------------- Train set size: 405 Test set size: 101 # We can compare tree-based models via successive halving atom.successive_halving( models=['tree', 'bag', 'et', 'rf', 'lgb', 'catb'], metric='mae', bagging=5 ) Training ===================================== >> Metric: neg_mean_absolute_error Run: 0 ================================ >> Models: Tree, Bag, ET, RF, LGB, CatB Size of training set: 67 (17%) Size of test set: 101 Results for Decision Tree: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0000 Test evaluation --> neg_mean_absolute_error: -3.3257 Time elapsed: 0.007s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -4.3307 \u00b1 0.5250 Time elapsed: 0.022s ------------------------------------------------- Total time: 0.029s Results for Bagging Regressor: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -1.3054 Test evaluation --> neg_mean_absolute_error: -2.6950 Time elapsed: 0.020s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -3.0957 \u00b1 0.2677 Time elapsed: 0.082s ------------------------------------------------- Total time: 0.104s Results for Extra-Trees: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0000 Test evaluation --> neg_mean_absolute_error: -2.1541 Time elapsed: 0.086s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.5554 \u00b1 0.1708 Time elapsed: 0.360s ------------------------------------------------- Total time: 0.446s Results for Random Forest: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -1.1509 Test evaluation --> neg_mean_absolute_error: -2.4143 Time elapsed: 0.109s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.9574 \u00b1 0.2253 Time elapsed: 0.506s ------------------------------------------------- Total time: 0.615s Results for LightGBM: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -3.4205 Test evaluation --> neg_mean_absolute_error: -4.5600 Time elapsed: 0.027s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -4.8393 \u00b1 0.2682 Time elapsed: 0.074s ------------------------------------------------- Total time: 0.103s Results for CatBoost: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0806 Test evaluation --> neg_mean_absolute_error: -2.3984 Time elapsed: 1.333s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.9165 \u00b1 0.2564 Time elapsed: 4.065s ------------------------------------------------- Total time: 5.399s Final results ========================= >> Duration: 6.699s ------------------------------------------ Decision Tree --> neg_mean_absolute_error: -4.331 \u00b1 0.525 ~ Bagging Regressor --> neg_mean_absolute_error: -3.096 \u00b1 0.268 ~ Extra-Trees --> neg_mean_absolute_error: -2.555 \u00b1 0.171 ~ ! Random Forest --> neg_mean_absolute_error: -2.957 \u00b1 0.225 ~ LightGBM --> neg_mean_absolute_error: -4.839 \u00b1 0.268 ~ CatBoost --> neg_mean_absolute_error: -2.916 \u00b1 0.256 ~ Run: 1 ================================ >> Models: ET, CatB, RF Size of training set: 135 (33%) Size of test set: 101 Results for Extra-Trees: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.0000 Test evaluation --> neg_mean_absolute_error: -2.2361 Time elapsed: 0.099s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.6016 \u00b1 0.2890 Time elapsed: 0.418s ------------------------------------------------- Total time: 0.517s Results for CatBoost: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.2835 Test evaluation --> neg_mean_absolute_error: -2.4196 Time elapsed: 1.847s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.5681 \u00b1 0.2119 Time elapsed: 6.494s ------------------------------------------------- Total time: 8.343s Results for Random Forest: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.9820 Test evaluation --> neg_mean_absolute_error: -2.5055 Time elapsed: 0.131s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.6144 \u00b1 0.1188 Time elapsed: 0.662s ------------------------------------------------- Total time: 0.793s Final results ========================= >> Duration: 9.655s ------------------------------------------ Extra-Trees --> neg_mean_absolute_error: -2.602 \u00b1 0.289 ~ CatBoost --> neg_mean_absolute_error: -2.568 \u00b1 0.212 ~ ! Random Forest --> neg_mean_absolute_error: -2.614 \u00b1 0.119 ~ Run: 2 ================================ >> Models: CatB Size of training set: 405 (100%) Size of test set: 101 Results for CatBoost: Fit --------------------------------------------- Train evaluation --> neg_mean_absolute_error: -0.3978 Test evaluation --> neg_mean_absolute_error: -1.8772 Time elapsed: 3.348s Bagging ----------------------------------------- Evaluation --> neg_mean_absolute_error: -2.0501 \u00b1 0.0892 Time elapsed: 14.871s ------------------------------------------------- Total time: 18.221s Final results ========================= >> Duration: 18.223s ------------------------------------------ CatBoost --> neg_mean_absolute_error: -2.050 \u00b1 0.089 ~","title":"Run the pipeline"},{"location":"examples/successive_halving/successive_halving/#analyze-results","text":"# Note that the results dataframe now is multi-index atom.results .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_train metric_test time_fit mean_bagging std_bagging time_bagging time n_models model 1 CatB -0.397799 -1.87721 3.348s -2.05012 0.0891846 14.871s 18.221s 3 ET -2.31519e-14 -2.23608 0.099s -2.60165 0.289034 0.418s 0.517s RF -0.981978 -2.50547 0.131s -2.61442 0.118758 0.662s 0.793s CatB -0.28355 -2.41962 1.847s -2.56808 0.211868 6.494s 8.343s 6 Tree -0 -3.32574 0.007s -4.33069 0.525026 0.022s 0.029s Bag -1.30537 -2.69505 0.020s -3.09566 0.267668 0.082s 0.104s ET -2.25624e-14 -2.15409 0.086s -2.55543 0.170823 0.360s 0.446s RF -1.15087 -2.4143 0.109s -2.9574 0.225311 0.506s 0.615s LGB -3.42052 -4.55996 0.027s -4.83931 0.268167 0.074s 0.103s CatB -0.080555 -2.39843 1.333s -2.91647 0.256428 4.065s 5.399s # Plot the successive halving's results atom.plot_successive_halving()","title":"Analyze results"},{"location":"examples/train_sizing/train_sizing/","text":"Train sizing This example shows how to asses a model's performance based on the size of the training set. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package. The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow. Load the data # Import packages import numpy as np import pandas as pd from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 10829 CoffsHarbour 2.1 17.7 0.0 NaN NaN NaN NaN 15108 Newcastle 20.2 29.7 0.0 NaN NaN NaN NaN 117467 PerthAirport 11.7 20.5 0.4 6.0 8.4 WSW 57.0 80685 Dartmoor -0.8 15.3 0.0 1.8 7.2 WSW 24.0 122490 SalmonGums 8.6 21.2 0.0 NaN NaN NW 67.0 Run the pipeline # Initialize ATOM and prepare the data atom = ATOMClassifier(X, verbose=2, random_state=1) atom.clean() atom.impute(strat_num='median', strat_cat='most_frequent', min_frac_rows=0.8) atom.encode() << ================== ATOM ================== >> Algorithm task: binary classification. Dataset stats ================== >> Shape: (142193, 22) Missing values: 316559 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 113755 Test set size: 28438 ----------------------------------- Dataset balance: No:Yes <==> 3.5:1.0 ----------------------------------- Distribution of classes: | | dataset | train | test | |:----|----------:|--------:|-------:| | No | 110316 | 88263 | 22053 | | Yes | 31877 | 25492 | 6385 | Applying data cleaning... --> Label-encoding the target column. Fitting Imputer... Imputing missing values... --> Dropping 15182 rows for containing less than 80% non-missing values. --> Imputing 100 missing values with median in feature MinTemp. --> Imputing 57 missing values with median in feature MaxTemp. --> Imputing 640 missing values with median in feature Rainfall. --> Imputing 46535 missing values with median in feature Evaporation. --> Imputing 53034 missing values with median in feature Sunshine. --> Imputing 4381 missing values with most_frequent in feature WindGustDir. --> Imputing 4359 missing values with median in feature WindGustSpeed. --> Imputing 6624 missing values with most_frequent in feature WindDir9am. --> Imputing 612 missing values with most_frequent in feature WindDir3pm. --> Imputing 80 missing values with median in feature WindSpeed9am. --> Imputing 49 missing values with median in feature WindSpeed3pm. --> Imputing 532 missing values with median in feature Humidity9am. --> Imputing 1168 missing values with median in feature Humidity3pm. --> Imputing 1028 missing values with median in feature Pressure9am. --> Imputing 972 missing values with median in feature Pressure3pm. --> Imputing 42172 missing values with median in feature Cloud9am. --> Imputing 44251 missing values with median in feature Cloud3pm. --> Imputing 98 missing values with median in feature Temp9am. --> Imputing 702 missing values with median in feature Temp3pm. --> Imputing 640 missing values with most_frequent in feature RainToday. Fitting Encoder... Encoding categorical columns... --> LeaveOneOut-encoding feature Location. Contains 45 unique classes. --> LeaveOneOut-encoding feature WindGustDir. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir9am. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. # We can analyze the impact of the training set's size on a LightGBM model atom.train_sizing('lgb', train_sizes=np.linspace(0.1, 1, 9), bagging=4) Training ===================================== >> Models: LGB Metric: f1 Run: 0 ================================ >> Size of training set: 10164 (10%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.8175 Test evaluation --> f1: 0.6109 Time elapsed: 0.715s Bagging ----------------------------------------- Evaluation --> f1: 0.5928 \u00b1 0.0033 Time elapsed: 1.566s ------------------------------------------------- Total time: 2.291s Final results ========================= >> Duration: 2.293s ------------------------------------------ LightGBM --> f1: 0.593 \u00b1 0.003 ~ Run: 1 ================================ >> Size of training set: 21599 (21%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.7398 Test evaluation --> f1: 0.6248 Time elapsed: 0.950s Bagging ----------------------------------------- Evaluation --> f1: 0.6159 \u00b1 0.0042 Time elapsed: 2.027s ------------------------------------------------- Total time: 2.979s Final results ========================= >> Duration: 2.981s ------------------------------------------ LightGBM --> f1: 0.616 \u00b1 0.004 Run: 2 ================================ >> Size of training set: 33034 (32%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.7035 Test evaluation --> f1: 0.6314 Time elapsed: 1.166s Bagging ----------------------------------------- Evaluation --> f1: 0.6208 \u00b1 0.0028 Time elapsed: 2.432s ------------------------------------------------- Total time: 3.599s Final results ========================= >> Duration: 3.601s ------------------------------------------ LightGBM --> f1: 0.621 \u00b1 0.003 Run: 3 ================================ >> Size of training set: 44469 (44%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6862 Test evaluation --> f1: 0.6313 Time elapsed: 1.304s Bagging ----------------------------------------- Evaluation --> f1: 0.6277 \u00b1 0.0047 Time elapsed: 3.011s ------------------------------------------------- Total time: 4.316s Final results ========================= >> Duration: 4.319s ------------------------------------------ LightGBM --> f1: 0.628 \u00b1 0.005 Run: 4 ================================ >> Size of training set: 55904 (55%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6803 Test evaluation --> f1: 0.6396 Time elapsed: 1.643s Bagging ----------------------------------------- Evaluation --> f1: 0.6277 \u00b1 0.0044 Time elapsed: 3.521s ------------------------------------------------- Total time: 5.165s Final results ========================= >> Duration: 5.167s ------------------------------------------ LightGBM --> f1: 0.628 \u00b1 0.004 Run: 5 ================================ >> Size of training set: 67339 (66%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6770 Test evaluation --> f1: 0.6382 Time elapsed: 1.928s Bagging ----------------------------------------- Evaluation --> f1: 0.6365 \u00b1 0.0018 Time elapsed: 4.042s ------------------------------------------------- Total time: 5.970s Final results ========================= >> Duration: 5.973s ------------------------------------------ LightGBM --> f1: 0.637 \u00b1 0.002 Run: 6 ================================ >> Size of training set: 78774 (77%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6752 Test evaluation --> f1: 0.6398 Time elapsed: 2.085s Bagging ----------------------------------------- Evaluation --> f1: 0.6330 \u00b1 0.0034 Time elapsed: 4.610s ------------------------------------------------- Total time: 6.697s Final results ========================= >> Duration: 6.700s ------------------------------------------ LightGBM --> f1: 0.633 \u00b1 0.003 Run: 7 ================================ >> Size of training set: 90209 (89%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6693 Test evaluation --> f1: 0.6395 Time elapsed: 2.356s Bagging ----------------------------------------- Evaluation --> f1: 0.6348 \u00b1 0.0033 Time elapsed: 5.087s ------------------------------------------------- Total time: 7.444s Final results ========================= >> Duration: 7.446s ------------------------------------------ LightGBM --> f1: 0.635 \u00b1 0.003 Run: 8 ================================ >> Size of training set: 101645 (100%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6642 Test evaluation --> f1: 0.6396 Time elapsed: 2.552s Bagging ----------------------------------------- Evaluation --> f1: 0.6383 \u00b1 0.0011 Time elapsed: 5.604s ------------------------------------------------- Total time: 8.158s Final results ========================= >> Duration: 8.161s ------------------------------------------ LightGBM --> f1: 0.638 \u00b1 0.001 Analyze the results # Note that the results dataframe now is multi-index atom.results .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_train metric_test time_fit mean_bagging std_bagging time_bagging time frac model 0.100 LGB 0.817545 0.610896 0.715s 0.592843 0.00326925 1.566s 2.291s 0.213 LGB 0.739836 0.624805 0.950s 0.615899 0.00419954 2.027s 2.979s 0.325 LGB 0.703472 0.631394 1.166s 0.620782 0.00276679 2.432s 3.599s 0.438 LGB 0.686179 0.631308 1.304s 0.627692 0.00471833 3.011s 4.316s 0.550 LGB 0.680266 0.639622 1.643s 0.6277 0.00435635 3.521s 5.165s 0.662 LGB 0.677 0.638232 1.928s 0.636536 0.00181403 4.042s 5.970s 0.775 LGB 0.675226 0.639803 2.085s 0.63298 0.00338554 4.610s 6.697s 0.888 LGB 0.66932 0.639532 2.356s 0.634824 0.00334286 5.087s 7.444s 1.000 LGB 0.664209 0.639555 2.552s 0.638334 0.00110171 5.604s 8.158s # Plot the train sizing's results atom.plot_learning_curve()","title":"Train sizing"},{"location":"examples/train_sizing/train_sizing/#train-sizing","text":"This example shows how to asses a model's performance based on the size of the training set. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package. The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow.","title":"Train sizing"},{"location":"examples/train_sizing/train_sizing/#load-the-data","text":"# Import packages import numpy as np import pandas as pd from atom import ATOMClassifier # Load the Australian weather dataset X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 10829 CoffsHarbour 2.1 17.7 0.0 NaN NaN NaN NaN 15108 Newcastle 20.2 29.7 0.0 NaN NaN NaN NaN 117467 PerthAirport 11.7 20.5 0.4 6.0 8.4 WSW 57.0 80685 Dartmoor -0.8 15.3 0.0 1.8 7.2 WSW 24.0 122490 SalmonGums 8.6 21.2 0.0 NaN NaN NW 67.0","title":"Load the data"},{"location":"examples/train_sizing/train_sizing/#run-the-pipeline","text":"# Initialize ATOM and prepare the data atom = ATOMClassifier(X, verbose=2, random_state=1) atom.clean() atom.impute(strat_num='median', strat_cat='most_frequent', min_frac_rows=0.8) atom.encode() << ================== ATOM ================== >> Algorithm task: binary classification. Dataset stats ================== >> Shape: (142193, 22) Missing values: 316559 Categorical columns: 5 Scaled: False ----------------------------------- Train set size: 113755 Test set size: 28438 ----------------------------------- Dataset balance: No:Yes <==> 3.5:1.0 ----------------------------------- Distribution of classes: | | dataset | train | test | |:----|----------:|--------:|-------:| | No | 110316 | 88263 | 22053 | | Yes | 31877 | 25492 | 6385 | Applying data cleaning... --> Label-encoding the target column. Fitting Imputer... Imputing missing values... --> Dropping 15182 rows for containing less than 80% non-missing values. --> Imputing 100 missing values with median in feature MinTemp. --> Imputing 57 missing values with median in feature MaxTemp. --> Imputing 640 missing values with median in feature Rainfall. --> Imputing 46535 missing values with median in feature Evaporation. --> Imputing 53034 missing values with median in feature Sunshine. --> Imputing 4381 missing values with most_frequent in feature WindGustDir. --> Imputing 4359 missing values with median in feature WindGustSpeed. --> Imputing 6624 missing values with most_frequent in feature WindDir9am. --> Imputing 612 missing values with most_frequent in feature WindDir3pm. --> Imputing 80 missing values with median in feature WindSpeed9am. --> Imputing 49 missing values with median in feature WindSpeed3pm. --> Imputing 532 missing values with median in feature Humidity9am. --> Imputing 1168 missing values with median in feature Humidity3pm. --> Imputing 1028 missing values with median in feature Pressure9am. --> Imputing 972 missing values with median in feature Pressure3pm. --> Imputing 42172 missing values with median in feature Cloud9am. --> Imputing 44251 missing values with median in feature Cloud3pm. --> Imputing 98 missing values with median in feature Temp9am. --> Imputing 702 missing values with median in feature Temp3pm. --> Imputing 640 missing values with most_frequent in feature RainToday. Fitting Encoder... Encoding categorical columns... --> LeaveOneOut-encoding feature Location. Contains 45 unique classes. --> LeaveOneOut-encoding feature WindGustDir. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir9am. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. # We can analyze the impact of the training set's size on a LightGBM model atom.train_sizing('lgb', train_sizes=np.linspace(0.1, 1, 9), bagging=4) Training ===================================== >> Models: LGB Metric: f1 Run: 0 ================================ >> Size of training set: 10164 (10%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.8175 Test evaluation --> f1: 0.6109 Time elapsed: 0.715s Bagging ----------------------------------------- Evaluation --> f1: 0.5928 \u00b1 0.0033 Time elapsed: 1.566s ------------------------------------------------- Total time: 2.291s Final results ========================= >> Duration: 2.293s ------------------------------------------ LightGBM --> f1: 0.593 \u00b1 0.003 ~ Run: 1 ================================ >> Size of training set: 21599 (21%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.7398 Test evaluation --> f1: 0.6248 Time elapsed: 0.950s Bagging ----------------------------------------- Evaluation --> f1: 0.6159 \u00b1 0.0042 Time elapsed: 2.027s ------------------------------------------------- Total time: 2.979s Final results ========================= >> Duration: 2.981s ------------------------------------------ LightGBM --> f1: 0.616 \u00b1 0.004 Run: 2 ================================ >> Size of training set: 33034 (32%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.7035 Test evaluation --> f1: 0.6314 Time elapsed: 1.166s Bagging ----------------------------------------- Evaluation --> f1: 0.6208 \u00b1 0.0028 Time elapsed: 2.432s ------------------------------------------------- Total time: 3.599s Final results ========================= >> Duration: 3.601s ------------------------------------------ LightGBM --> f1: 0.621 \u00b1 0.003 Run: 3 ================================ >> Size of training set: 44469 (44%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6862 Test evaluation --> f1: 0.6313 Time elapsed: 1.304s Bagging ----------------------------------------- Evaluation --> f1: 0.6277 \u00b1 0.0047 Time elapsed: 3.011s ------------------------------------------------- Total time: 4.316s Final results ========================= >> Duration: 4.319s ------------------------------------------ LightGBM --> f1: 0.628 \u00b1 0.005 Run: 4 ================================ >> Size of training set: 55904 (55%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6803 Test evaluation --> f1: 0.6396 Time elapsed: 1.643s Bagging ----------------------------------------- Evaluation --> f1: 0.6277 \u00b1 0.0044 Time elapsed: 3.521s ------------------------------------------------- Total time: 5.165s Final results ========================= >> Duration: 5.167s ------------------------------------------ LightGBM --> f1: 0.628 \u00b1 0.004 Run: 5 ================================ >> Size of training set: 67339 (66%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6770 Test evaluation --> f1: 0.6382 Time elapsed: 1.928s Bagging ----------------------------------------- Evaluation --> f1: 0.6365 \u00b1 0.0018 Time elapsed: 4.042s ------------------------------------------------- Total time: 5.970s Final results ========================= >> Duration: 5.973s ------------------------------------------ LightGBM --> f1: 0.637 \u00b1 0.002 Run: 6 ================================ >> Size of training set: 78774 (77%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6752 Test evaluation --> f1: 0.6398 Time elapsed: 2.085s Bagging ----------------------------------------- Evaluation --> f1: 0.6330 \u00b1 0.0034 Time elapsed: 4.610s ------------------------------------------------- Total time: 6.697s Final results ========================= >> Duration: 6.700s ------------------------------------------ LightGBM --> f1: 0.633 \u00b1 0.003 Run: 7 ================================ >> Size of training set: 90209 (89%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6693 Test evaluation --> f1: 0.6395 Time elapsed: 2.356s Bagging ----------------------------------------- Evaluation --> f1: 0.6348 \u00b1 0.0033 Time elapsed: 5.087s ------------------------------------------------- Total time: 7.444s Final results ========================= >> Duration: 7.446s ------------------------------------------ LightGBM --> f1: 0.635 \u00b1 0.003 Run: 8 ================================ >> Size of training set: 101645 (100%) Size of test set: 25366 Results for LightGBM: Fit --------------------------------------------- Train evaluation --> f1: 0.6642 Test evaluation --> f1: 0.6396 Time elapsed: 2.552s Bagging ----------------------------------------- Evaluation --> f1: 0.6383 \u00b1 0.0011 Time elapsed: 5.604s ------------------------------------------------- Total time: 8.158s Final results ========================= >> Duration: 8.161s ------------------------------------------ LightGBM --> f1: 0.638 \u00b1 0.001","title":"Run the pipeline"},{"location":"examples/train_sizing/train_sizing/#analyze-the-results","text":"# Note that the results dataframe now is multi-index atom.results .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } metric_train metric_test time_fit mean_bagging std_bagging time_bagging time frac model 0.100 LGB 0.817545 0.610896 0.715s 0.592843 0.00326925 1.566s 2.291s 0.213 LGB 0.739836 0.624805 0.950s 0.615899 0.00419954 2.027s 2.979s 0.325 LGB 0.703472 0.631394 1.166s 0.620782 0.00276679 2.432s 3.599s 0.438 LGB 0.686179 0.631308 1.304s 0.627692 0.00471833 3.011s 4.316s 0.550 LGB 0.680266 0.639622 1.643s 0.6277 0.00435635 3.521s 5.165s 0.662 LGB 0.677 0.638232 1.928s 0.636536 0.00181403 4.042s 5.970s 0.775 LGB 0.675226 0.639803 2.085s 0.63298 0.00338554 4.610s 6.697s 0.888 LGB 0.66932 0.639532 2.356s 0.634824 0.00334286 5.087s 7.444s 1.000 LGB 0.664209 0.639555 2.552s 0.638334 0.00110171 5.604s 8.158s # Plot the train sizing's results atom.plot_learning_curve()","title":"Analyze the results"},{"location":"examples/utilities/utilities/","text":"Utilities This example shows various useful utilities that can be used to improve your pipelines. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow . Load the data # Import packages import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier, ATOMLoader # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 85350 Cairns 21.1 30.6 0.0 6.4 11.0 ENE 30.0 84762 Brisbane 23.2 27.9 3.8 5.6 0.2 ENE 20.0 131267 Launceston 13.3 28.0 0.2 NaN NaN SSE 28.0 107223 Albany 8.5 19.3 5.4 1.8 9.5 NaN NaN 33917 SydneyAirport 21.3 24.9 0.0 7.8 NaN SSW 48.0 Use the utility attributes atom = ATOMClassifier(X, warnings=False, random_state=1) atom.clean() # We can quickly check what columns have missing values print(\"Columns with missing values:\\n\", atom.missing) # Or what columns are categorical print(\"\\nCategorical columns:\", atom.categorical) # Or if the dataset is scaled print(\"\\nIs the dataset scaled?\", atom.scaled) Columns with missing values: MinTemp 637 MaxTemp 322 Rainfall 1406 Evaporation 60843 Sunshine 67816 WindGustDir 9330 WindGustSpeed 9270 WindDir9am 10013 WindDir3pm 3778 WindSpeed9am 1348 WindSpeed3pm 2630 Humidity9am 1774 Humidity3pm 3610 Pressure9am 14014 Pressure3pm 13981 Cloud9am 53657 Cloud3pm 57094 Temp9am 904 Temp3pm 2726 RainToday 1406 dtype: int64 Categorical columns: ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'] Is the dataset scaled? False Use the stats method to check changes in the dataset # Note the number of missing values and categorical columns atom.stats() # Now, let's impute and encode the dataset... atom.impute() atom.encode() # ... and the values are gone atom.stats() Dataset stats ================= >> Shape: (142193, 22) Missing values: 316559 Categorical columns: 5 Scaled: False ---------------------------------- Train set size: 113755 Test set size: 28438 ---------------------------------- Dataset balance: No:Yes <==> 3.5:1.0 ---------------------------------- Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 110316 | 88263 | 22053 | | 1: Yes | 31877 | 25492 | 6385 | Dataset stats ================= >> Shape: (56420, 22) Scaled: False ---------------------------------- Train set size: 45136 Test set size: 11284 ---------------------------------- Dataset balance: No:Yes <==> 3.5:1.0 ---------------------------------- Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 43993 | 35199 | 8794 | | 1: Yes | 12427 | 9937 | 2490 | Change the data mid-pipeline # We can change atom's data mid-pipeline, adding a column for example # Note that we can only replace a dataframe with a new dataframe! atom.X = atom.X.assign(AvgTemp=(atom.X['MaxTemp'] + atom.X['MinTemp'])/2) # This will automatically update all other data attributes assert 'AvgTemp' in atom.dataset Visualize the pipeline # We can easily visualize the pipeline in two ways print(atom) # Directly in the notebook atom.plot_pipeline() # Using a plot ATOMClassifier --> Cleaner >>> prohibited_types: ['datetime64', 'datetime64[ns]', 'timedelta[ns]'] >>> strip_categorical: True >>> maximum_cardinality: True >>> minimum_cardinality: True >>> missing_target: True >>> map_target: True --> Imputer >>> strat_num: drop >>> strat_cat: drop >>> min_frac_rows: 0.5 >>> min_frac_cols: 0.5 >>> missing: {'', inf, -inf, 'NA', 'nan', 'None', 'inf', '?'} --> Encoder >>> strategy: LeaveOneOut >>> max_onehot: 10 >>> frac_to_other: None >>> kwargs: {} Use a custom metric atom.verbose = 1 # Define a custom metric def f2_score(y_true, y_pred): return fbeta_score(y_true, y_pred, beta=2) # Remember to use the greater_is_better, needs_proba and needs_threshold parameters if necessary! atom.run(models='lr', metric=f2_score) Training ===================================== >> Models: LR Metric: f2_score Results for Logistic Regression: Fit --------------------------------------------- Score on the train set --> f2_score: 0.5678 Score on the test set --> f2_score: 0.5682 Time elapsed: 0.209s ------------------------------------------------- Total time: 0.234s Final results ========================= >> Duration: 0.236s ------------------------------------------ Logistic Regression --> f2_score: 0.568 Customize the estimator's parameters # You can use the est_params parameter to customize the estimator # Let's run AdaBoost using LR instead of a decision tree as base estimator atom.run('AdaB', est_params={'base_estimator': atom.lr.estimator}) Training ===================================== >> Models: AdaB Metric: f2_score Results for AdaBoost: Fit --------------------------------------------- Score on the train set --> f2_score: 0.5565 Score on the test set --> f2_score: 0.5482 Time elapsed: 2.094s ------------------------------------------------- Total time: 2.098s Final results ========================= >> Duration: 2.100s ------------------------------------------ AdaBoost --> f2_score: 0.548 atom.adab.estimator AdaBoostClassifier(base_estimator=LogisticRegression(n_jobs=1, random_state=1), random_state=1) # Note that parameters specified by est_params are not optimized in the BO # (also, we can change the verbosity per method) atom.run('tree', n_calls=3, n_initial_points=1, est_params={'max_depth': 2}, verbose=2) Training ===================================== >> Models: Tree Metric: f2_score Running BO for Decision Tree... Initial point 1 --------------------------------- Parameters --> {'criterion': 'gini', 'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'ccp_alpha': 0} Evaluation --> f2_score: 0.4936 Best f2_score: 0.4936 Time iteration: 0.383s Total time: 0.396s Iteration 2 ------------------------------------- Parameters --> {'criterion': 'gini', 'splitter': 'random', 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': 0.5, 'ccp_alpha': 0.014} Evaluation --> f2_score: 0.4441 Best f2_score: 0.4936 Time iteration: 0.137s Total time: 0.537s Iteration 3 ------------------------------------- Parameters --> {'criterion': 'entropy', 'splitter': 'random', 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 0.5, 'ccp_alpha': 0.0} Evaluation --> f2_score: 0.3050 Best f2_score: 0.4936 Time iteration: 0.140s Total time: 0.927s Results for Decision Tree: Bayesian Optimization --------------------------- Best parameters --> {'criterion': 'gini', 'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'ccp_alpha': 0} Best evaluation --> f2_score: 0.4936 Time elapsed: 1.229s Fit --------------------------------------------- Score on the train set --> f2_score: 0.4937 Score on the test set --> f2_score: 0.4878 Time elapsed: 0.105s ------------------------------------------------- Total time: 1.344s Final results ========================= >> Duration: 1.346s ------------------------------------------ Decision Tree --> f2_score: 0.488 Save & load # Save the atom instance as a pickle with the save method # Remember that the instance contains the data, use save_datad to save the instance without the data atom.save('atom', save_data=False) ATOMClassifier saved successfully! # Load the instance again with ATOMLoader # No need to store the transformed data, providing the original dataset to the loader # will automatically transform it throigh all the steps in atom's pipeline atom_2 = ATOMLoader('atom', X, verbose=2) # Remember to also add the extra column! atom_2.X = atom_2.X.assign(AvgTemp=(atom_2.X['MaxTemp'] + atom_2.X['MinTemp'])/2) Applying data cleaning... --> Label-encoding the target column. Imputing missing values... --> Dropping 1116 rows for containing less than 50% non-missing values. --> Dropping 295 rows due to missing values in feature MinTemp. --> Dropping 176 rows due to missing values in feature MaxTemp. --> Dropping 1161 rows due to missing values in feature Rainfall. --> Dropping 58505 rows due to missing values in feature Evaporation. --> Dropping 10826 rows due to missing values in feature Sunshine. --> Dropping 4153 rows due to missing values in feature WindGustDir. --> Dropping 2199 rows due to missing values in feature WindDir9am. --> Dropping 208 rows due to missing values in feature WindDir3pm. --> Dropping 258 rows due to missing values in feature Humidity9am. --> Dropping 56 rows due to missing values in feature Humidity3pm. --> Dropping 53 rows due to missing values in feature Pressure9am. --> Dropping 20 rows due to missing values in feature Pressure3pm. --> Dropping 5361 rows due to missing values in feature Cloud9am. --> Dropping 1386 rows due to missing values in feature Cloud3pm. Encoding categorical columns... --> LeaveOneOut-encoding feature Location. Contains 26 unique classes. --> LeaveOneOut-encoding feature WindGustDir. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir9am. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. ATOMClassifier loaded successfully! Customize the plot aesthetics # Use the plotting attributes to further customize your plots! atom_2.palette= 'Blues' atom_2.style = 'white' atom_2.plot_roc()","title":"Utilities"},{"location":"examples/utilities/utilities/#utilities","text":"This example shows various useful utilities that can be used to improve your pipelines. The data used is a variation on the Australian weather dataset from https://www.kaggle.com/jsphyg/weather-dataset-rattle-package . The goal of this dataset is to predict whether or not it will rain tomorrow training a binay classifier on target RainTomorrow .","title":"Utilities"},{"location":"examples/utilities/utilities/#load-the-data","text":"# Import packages import pandas as pd from sklearn.metrics import fbeta_score from atom import ATOMClassifier, ATOMLoader # Load data X = pd.read_csv('./datasets/weatherAUS.csv') # Let's have a look at a subset of the data X.sample(frac=1).iloc[:5, :8] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Location MinTemp MaxTemp Rainfall Evaporation Sunshine WindGustDir WindGustSpeed 85350 Cairns 21.1 30.6 0.0 6.4 11.0 ENE 30.0 84762 Brisbane 23.2 27.9 3.8 5.6 0.2 ENE 20.0 131267 Launceston 13.3 28.0 0.2 NaN NaN SSE 28.0 107223 Albany 8.5 19.3 5.4 1.8 9.5 NaN NaN 33917 SydneyAirport 21.3 24.9 0.0 7.8 NaN SSW 48.0","title":"Load the data"},{"location":"examples/utilities/utilities/#use-the-utility-attributes","text":"atom = ATOMClassifier(X, warnings=False, random_state=1) atom.clean() # We can quickly check what columns have missing values print(\"Columns with missing values:\\n\", atom.missing) # Or what columns are categorical print(\"\\nCategorical columns:\", atom.categorical) # Or if the dataset is scaled print(\"\\nIs the dataset scaled?\", atom.scaled) Columns with missing values: MinTemp 637 MaxTemp 322 Rainfall 1406 Evaporation 60843 Sunshine 67816 WindGustDir 9330 WindGustSpeed 9270 WindDir9am 10013 WindDir3pm 3778 WindSpeed9am 1348 WindSpeed3pm 2630 Humidity9am 1774 Humidity3pm 3610 Pressure9am 14014 Pressure3pm 13981 Cloud9am 53657 Cloud3pm 57094 Temp9am 904 Temp3pm 2726 RainToday 1406 dtype: int64 Categorical columns: ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday'] Is the dataset scaled? False","title":"Use the utility attributes"},{"location":"examples/utilities/utilities/#use-the-stats-method-to-check-changes-in-the-dataset","text":"# Note the number of missing values and categorical columns atom.stats() # Now, let's impute and encode the dataset... atom.impute() atom.encode() # ... and the values are gone atom.stats() Dataset stats ================= >> Shape: (142193, 22) Missing values: 316559 Categorical columns: 5 Scaled: False ---------------------------------- Train set size: 113755 Test set size: 28438 ---------------------------------- Dataset balance: No:Yes <==> 3.5:1.0 ---------------------------------- Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 110316 | 88263 | 22053 | | 1: Yes | 31877 | 25492 | 6385 | Dataset stats ================= >> Shape: (56420, 22) Scaled: False ---------------------------------- Train set size: 45136 Test set size: 11284 ---------------------------------- Dataset balance: No:Yes <==> 3.5:1.0 ---------------------------------- Instances in RainTomorrow per class: | | total | train_set | test_set | |:-------|---------:|-------------:|------------:| | 0: No | 43993 | 35199 | 8794 | | 1: Yes | 12427 | 9937 | 2490 |","title":"Use the stats method to check changes in the dataset"},{"location":"examples/utilities/utilities/#change-the-data-mid-pipeline","text":"# We can change atom's data mid-pipeline, adding a column for example # Note that we can only replace a dataframe with a new dataframe! atom.X = atom.X.assign(AvgTemp=(atom.X['MaxTemp'] + atom.X['MinTemp'])/2) # This will automatically update all other data attributes assert 'AvgTemp' in atom.dataset","title":"Change the data mid-pipeline"},{"location":"examples/utilities/utilities/#visualize-the-pipeline","text":"# We can easily visualize the pipeline in two ways print(atom) # Directly in the notebook atom.plot_pipeline() # Using a plot ATOMClassifier --> Cleaner >>> prohibited_types: ['datetime64', 'datetime64[ns]', 'timedelta[ns]'] >>> strip_categorical: True >>> maximum_cardinality: True >>> minimum_cardinality: True >>> missing_target: True >>> map_target: True --> Imputer >>> strat_num: drop >>> strat_cat: drop >>> min_frac_rows: 0.5 >>> min_frac_cols: 0.5 >>> missing: {'', inf, -inf, 'NA', 'nan', 'None', 'inf', '?'} --> Encoder >>> strategy: LeaveOneOut >>> max_onehot: 10 >>> frac_to_other: None >>> kwargs: {}","title":"Visualize the pipeline"},{"location":"examples/utilities/utilities/#use-a-custom-metric","text":"atom.verbose = 1 # Define a custom metric def f2_score(y_true, y_pred): return fbeta_score(y_true, y_pred, beta=2) # Remember to use the greater_is_better, needs_proba and needs_threshold parameters if necessary! atom.run(models='lr', metric=f2_score) Training ===================================== >> Models: LR Metric: f2_score Results for Logistic Regression: Fit --------------------------------------------- Score on the train set --> f2_score: 0.5678 Score on the test set --> f2_score: 0.5682 Time elapsed: 0.209s ------------------------------------------------- Total time: 0.234s Final results ========================= >> Duration: 0.236s ------------------------------------------ Logistic Regression --> f2_score: 0.568","title":"Use a custom metric"},{"location":"examples/utilities/utilities/#customize-the-estimators-parameters","text":"# You can use the est_params parameter to customize the estimator # Let's run AdaBoost using LR instead of a decision tree as base estimator atom.run('AdaB', est_params={'base_estimator': atom.lr.estimator}) Training ===================================== >> Models: AdaB Metric: f2_score Results for AdaBoost: Fit --------------------------------------------- Score on the train set --> f2_score: 0.5565 Score on the test set --> f2_score: 0.5482 Time elapsed: 2.094s ------------------------------------------------- Total time: 2.098s Final results ========================= >> Duration: 2.100s ------------------------------------------ AdaBoost --> f2_score: 0.548 atom.adab.estimator AdaBoostClassifier(base_estimator=LogisticRegression(n_jobs=1, random_state=1), random_state=1) # Note that parameters specified by est_params are not optimized in the BO # (also, we can change the verbosity per method) atom.run('tree', n_calls=3, n_initial_points=1, est_params={'max_depth': 2}, verbose=2) Training ===================================== >> Models: Tree Metric: f2_score Running BO for Decision Tree... Initial point 1 --------------------------------- Parameters --> {'criterion': 'gini', 'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'ccp_alpha': 0} Evaluation --> f2_score: 0.4936 Best f2_score: 0.4936 Time iteration: 0.383s Total time: 0.396s Iteration 2 ------------------------------------- Parameters --> {'criterion': 'gini', 'splitter': 'random', 'min_samples_split': 4, 'min_samples_leaf': 20, 'max_features': 0.5, 'ccp_alpha': 0.014} Evaluation --> f2_score: 0.4441 Best f2_score: 0.4936 Time iteration: 0.137s Total time: 0.537s Iteration 3 ------------------------------------- Parameters --> {'criterion': 'entropy', 'splitter': 'random', 'min_samples_split': 2, 'min_samples_leaf': 6, 'max_features': 0.5, 'ccp_alpha': 0.0} Evaluation --> f2_score: 0.3050 Best f2_score: 0.4936 Time iteration: 0.140s Total time: 0.927s Results for Decision Tree: Bayesian Optimization --------------------------- Best parameters --> {'criterion': 'gini', 'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'ccp_alpha': 0} Best evaluation --> f2_score: 0.4936 Time elapsed: 1.229s Fit --------------------------------------------- Score on the train set --> f2_score: 0.4937 Score on the test set --> f2_score: 0.4878 Time elapsed: 0.105s ------------------------------------------------- Total time: 1.344s Final results ========================= >> Duration: 1.346s ------------------------------------------ Decision Tree --> f2_score: 0.488","title":"Customize the estimator's parameters"},{"location":"examples/utilities/utilities/#save-load","text":"# Save the atom instance as a pickle with the save method # Remember that the instance contains the data, use save_datad to save the instance without the data atom.save('atom', save_data=False) ATOMClassifier saved successfully! # Load the instance again with ATOMLoader # No need to store the transformed data, providing the original dataset to the loader # will automatically transform it throigh all the steps in atom's pipeline atom_2 = ATOMLoader('atom', X, verbose=2) # Remember to also add the extra column! atom_2.X = atom_2.X.assign(AvgTemp=(atom_2.X['MaxTemp'] + atom_2.X['MinTemp'])/2) Applying data cleaning... --> Label-encoding the target column. Imputing missing values... --> Dropping 1116 rows for containing less than 50% non-missing values. --> Dropping 295 rows due to missing values in feature MinTemp. --> Dropping 176 rows due to missing values in feature MaxTemp. --> Dropping 1161 rows due to missing values in feature Rainfall. --> Dropping 58505 rows due to missing values in feature Evaporation. --> Dropping 10826 rows due to missing values in feature Sunshine. --> Dropping 4153 rows due to missing values in feature WindGustDir. --> Dropping 2199 rows due to missing values in feature WindDir9am. --> Dropping 208 rows due to missing values in feature WindDir3pm. --> Dropping 258 rows due to missing values in feature Humidity9am. --> Dropping 56 rows due to missing values in feature Humidity3pm. --> Dropping 53 rows due to missing values in feature Pressure9am. --> Dropping 20 rows due to missing values in feature Pressure3pm. --> Dropping 5361 rows due to missing values in feature Cloud9am. --> Dropping 1386 rows due to missing values in feature Cloud3pm. Encoding categorical columns... --> LeaveOneOut-encoding feature Location. Contains 26 unique classes. --> LeaveOneOut-encoding feature WindGustDir. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir9am. Contains 16 unique classes. --> LeaveOneOut-encoding feature WindDir3pm. Contains 16 unique classes. --> Label-encoding feature RainToday. Contains 2 unique classes. ATOMClassifier loaded successfully!","title":"Save &amp; load"},{"location":"examples/utilities/utilities/#customize-the-plot-aesthetics","text":"# Use the plotting attributes to further customize your plots! atom_2.palette= 'Blues' atom_2.style = 'white' atom_2.plot_roc()","title":"Customize the plot aesthetics"}]}